<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Gallon</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://gallonhu.github.io/"/>
  <updated>2020-02-11T02:46:50.234Z</updated>
  <id>http://gallonhu.github.io/</id>
  
  <author>
    <name>gallon</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>archlinuxa安装配置</title>
    <link href="http://gallonhu.github.io/posts/918ab41d/"/>
    <id>http://gallonhu.github.io/posts/918ab41d/</id>
    <published>2020-02-11T02:07:07.000Z</published>
    <updated>2020-02-11T02:46:50.234Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://wiki.archlinux.org/index.php/Installation_guide" target="_blank" rel="noopener">参考官方文档</a></p><a id="more"></a><h2 id="安装前的准备"><a href="#安装前的准备" class="headerlink" title="安装前的准备"></a>安装前的准备</h2><h3 id="设置字体"><a href="#设置字体" class="headerlink" title="设置字体"></a>设置字体</h3><p>刚进入系统，默认的字体特别小，用一下命令设置字体</p><figure class="highlight shell hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">setfont /usr/share/kbd/consolefonts/LatGrkCyr-12x12.psfu.gz</span><br></pre></td></tr></table></figure><h3 id="验证启动模式"><a href="#验证启动模式" class="headerlink" title="验证启动模式"></a>验证启动模式</h3><p>输入以下命令查看启动模式</p><figure class="highlight shell hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ls /sys/firmware/efi/efivars</span><br></pre></td></tr></table></figure><p>若有输出，则为 <code>UEFI</code>，否则为<code>BOIS</code></p><h3 id="连接网络"><a href="#连接网络" class="headerlink" title="连接网络"></a>连接网络</h3><h4 id="有线"><a href="#有线" class="headerlink" title="有线"></a>有线</h4><figure class="highlight shell hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dhcpcd</span><br></pre></td></tr></table></figure><h4 id="无线"><a href="#无线" class="headerlink" title="无线"></a>无线</h4><figure class="highlight shell hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">wifi-menu</span><br></pre></td></tr></table></figure><p>或者到<a href="https://wiki.archlinux.org/index.php/Wireless_network_configuration" target="_blank" rel="noopener">官方网络配置页面</a>查找解决方式</p><h3 id="更新系统时间"><a href="#更新系统时间" class="headerlink" title="更新系统时间"></a>更新系统时间</h3><figure class="highlight shell hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">timedatectl set-ntp true</span><br></pre></td></tr></table></figure><h3 id="分区与格式化"><a href="#分区与格式化" class="headerlink" title="分区与格式化"></a>分区与格式化</h3><p>查看目前分区情况</p><figure class="highlight shell hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">fdisk -l</span><br></pre></td></tr></table></figure><h4 id="引导分区"><a href="#引导分区" class="headerlink" title="引导分区"></a>引导分区</h4><ul><li>如果你是BIOS/MBR方式引导，无需创建引导分区。</li><li>如果你是EFI/GPT方式引导，并且同时安装了其他系统，那么你应该可以在分区列表中发现一个较小的并且类型为 EFI 的分区（注意查看硬盘的大小，这个<code>EFI</code>分区有可能是你U盘中的，需要排除），这是你的引导分区，请记下它的路径（/dev/sdxY)备用，创建引导分区的步骤。</li><li>如果你是EFI/GPT方式引导，但是没有这个较小的并且类型为EFI的引导分区（这种情况一般只会出现在新的硬盘），那么你需要先创建引导分区。</li></ul><h4 id="分区创建"><a href="#分区创建" class="headerlink" title="分区创建"></a>分区创建</h4><figure class="highlight shell hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">fdisk /dev/sdx # sdx 为你要操作的磁盘</span><br><span class="line"></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> 输入 m 查看帮助</span></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> 具体参数看帮助内容</span></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> 创建引导分区需要更改文件格式为 efi</span></span><br></pre></td></tr></table></figure><h4 id="格式化分区"><a href="#格式化分区" class="headerlink" title="格式化分区"></a>格式化分区</h4><ul><li><p>格式化引导分区</p><figure class="highlight shell hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mkfs.fat -F32 /dev/sdxx # sdxx 为你刚刚创建的引导分区</span><br></pre></td></tr></table></figure></li><li><p>格式化 <code>swap</code> 分区</p><figure class="highlight shell hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mkswap /dev/sdxy # sdxy 为你刚刚分区的 swap 分区</span><br><span class="line">swapon /dev/sdxy</span><br></pre></td></tr></table></figure></li><li><p>格式化其他分区为 <code>ext4</code></p><figure class="highlight shell hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mkfs.ext4 /dev/sdxz # sdxz 为你要格式化的分区，如 /，/home 等等</span><br></pre></td></tr></table></figure></li></ul><h4 id="挂载分区"><a href="#挂载分区" class="headerlink" title="挂载分区"></a>挂载分区</h4><ul><li><p>挂载根分区</p><figure class="highlight shell hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mount /dev/sdxz /mnt # sdxz 为根分区</span><br></pre></td></tr></table></figure></li><li><p>挂载引导分区（如果有引导分区）</p><figure class="highlight shell hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mkdir /mnt/boot</span><br><span class="line">mount /dev/sdxx /mnt/boot # sdxx 为引导分区</span><br></pre></td></tr></table></figure></li><li><p>其他分区</p><figure class="highlight shell hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mkdir /mnt/home # 以 home 分区为例，其他类似</span><br><span class="line">mount /dev/sdxz /mnt/home # sdxz 为 home 分区</span><br></pre></td></tr></table></figure></li></ul><h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><h3 id="选择镜像源"><a href="#选择镜像源" class="headerlink" title="选择镜像源"></a>选择镜像源</h3><p>编辑 <code>/etc/pacman.d/mirrorlist</code> 文件，将所有国内源剪切到文件开头。</p><p>同时可以编辑 <code>etc/pacman.conf</code> 文件，将 <code>Color</code> 取消注释，可以让 <code>pacman</code> 安装输出彩色。</p><h3 id="安装基本包"><a href="#安装基本包" class="headerlink" title="安装基本包"></a>安装基本包</h3><p>安装基本的软件包到磁盘上，需要联网</p><figure class="highlight shell hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pacstrap /mnt base base-devel linux linux-firmware dhcpcd</span><br></pre></td></tr></table></figure><h3 id="配置-Fstab"><a href="#配置-Fstab" class="headerlink" title="配置 Fstab"></a>配置 Fstab</h3><p>生成自动挂载分区的 <code>fstab</code> 文件</p><figure class="highlight shell hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">genfstab -L /mnt &gt;&gt; /mnt/etc/fstab</span><br></pre></td></tr></table></figure><h3 id="Chroot"><a href="#Chroot" class="headerlink" title="Chroot"></a>Chroot</h3><p><code>Chroot</code> 意为 <code>Change root</code>，相当于把操纵权交给我们新安装（或已经存在）的<code>Linux</code>系统，执行了这步以后，我们的操作都相当于在磁盘上新装的系统中进行。</p><figure class="highlight shell hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">arch-chroot /mnt</span><br></pre></td></tr></table></figure><h4 id="设置时区"><a href="#设置时区" class="headerlink" title="设置时区"></a>设置时区</h4><figure class="highlight shell hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ln -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime</span><br><span class="line">hwclock --systohc</span><br></pre></td></tr></table></figure><h4 id="提前安装必须软件"><a href="#提前安装必须软件" class="headerlink" title="提前安装必须软件"></a>提前安装必须软件</h4><figure class="highlight shell hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pacman -S neovim dialog wpa_supplicant ntfs-3g networkmanager</span><br></pre></td></tr></table></figure><h4 id="设置-Local"><a href="#设置-Local" class="headerlink" title="设置 Local"></a>设置 Local</h4><p>编辑<code>/etc/locale.gen</code>文件，在文件中找到<code>zh_CN.UTF-8 UTF-8</code> 、 <code>en_US.UTF-8 UTF-8</code>这两行，去掉行首的#号，保存并退出。</p><p>然后执行</p><figure class="highlight shell hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">locale-gen</span><br></pre></td></tr></table></figure><p>创建 并编辑 <code>/etc/locale.conf</code> 文件</p><figure class="highlight shell hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">nvim /etc/locale.conf</span><br><span class="line"></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> 在第一行写入并保存</span></span><br><span class="line">LANG=en_US.UTF-8</span><br></pre></td></tr></table></figure><h4 id="设置主机名"><a href="#设置主机名" class="headerlink" title="设置主机名"></a>设置主机名</h4><figure class="highlight shell hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">nvim /etc/hostname</span><br><span class="line"></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> 在文件的第一行输入你自己设定的一个myhostname</span></span><br><span class="line">arch</span><br></pre></td></tr></table></figure><figure class="highlight shell hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">nvim /etc/hosts</span><br><span class="line"></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> 在文件末尾写入</span></span><br><span class="line">127.0.0.1localhost</span><br><span class="line">::1localhost</span><br><span class="line">127.0.1.1arch.localdomainarch</span><br></pre></td></tr></table></figure><h4 id="设置-Root-密码"><a href="#设置-Root-密码" class="headerlink" title="设置 Root 密码"></a>设置 Root 密码</h4><figure class="highlight shell hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">passwd</span><br><span class="line"></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> 按提示设置并确认就可以了</span></span><br></pre></td></tr></table></figure><h4 id="引导配置"><a href="#引导配置" class="headerlink" title="引导配置"></a>引导配置</h4><ul><li>安装软件</li></ul><figure class="highlight shell hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pacman -S intel-ucode os-prober ntfs-3g grub efibootmgr</span><br></pre></td></tr></table></figure><ul><li>部署 <code>grub</code></li></ul><figure class="highlight shell hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">grub-install --target=x86_64-efi --efi-directory=/boot --bootloader-id=grub</span><br></pre></td></tr></table></figure><ul><li>生成配置文件</li></ul><figure class="highlight shell hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">grub-mkconfig -o /boot/grub/grub.cfg</span><br></pre></td></tr></table></figure><h3 id="重启"><a href="#重启" class="headerlink" title="重启"></a>重启</h3><figure class="highlight shell hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> 退出</span></span><br><span class="line">exit</span><br><span class="line"></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> 前面挂载的分区全部卸载</span></span><br><span class="line">umount /mnt/boot</span><br><span class="line">umount /mnt/home</span><br><span class="line">umount /mnt</span><br><span class="line"></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> 重启</span></span><br><span class="line">reboot</span><br></pre></td></tr></table></figure><h2 id="安装后"><a href="#安装后" class="headerlink" title="安装后"></a>安装后</h2><p>这一部分主要讲安装完裸 <code>archlinux</code> 后配置桌面环境等内容。</p><p>我主要是使用窗口管理器，所以没有安装桌面环境，有需要的请自行安装。</p><h3 id="网络"><a href="#网络" class="headerlink" title="网络"></a>网络</h3><figure class="highlight shell hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"> systemctl enable dhcpcd</span><br><span class="line">systemctl start dhcpcd</span><br></pre></td></tr></table></figure><h3 id="新建用户"><a href="#新建用户" class="headerlink" title="新建用户"></a>新建用户</h3><figure class="highlight shell hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">useradd -m -G wheel username # username 换成你自己的 </span><br><span class="line">passwd username</span><br><span class="line"></span><br><span class="line">ln -sf /usr/bin/nvim /usr/bin/vi</span><br><span class="line">visudo</span><br><span class="line"></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> 找到 <span class="hljs-comment"># %wheel ALL=(ALL)ALL，取消注释</span></span></span><br><span class="line"></span><br><span class="line">reboot</span><br></pre></td></tr></table></figure><h3 id="图形化界面"><a href="#图形化界面" class="headerlink" title="图形化界面"></a>图形化界面</h3><ul><li>xorg</li></ul><figure class="highlight shell hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo pacman -S xf86-video-intel xorg xorg-xinit</span><br></pre></td></tr></table></figure><ul><li>dwm &amp; menu &amp; st</li></ul><figure class="highlight shell hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">git clone https://github.com/GallonHu/dwm.git</span><br><span class="line">git clone https://github.com/GallonHu/st.git</span><br><span class="line">git clone https://git.suckless.org/dmenu</span><br><span class="line"></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> 分别进入三个文件夹</span></span><br><span class="line">sudo make clean install</span><br></pre></td></tr></table></figure><ul><li><a href="https://github.com/Jguer/yay" target="_blank" rel="noopener">yay</a></li></ul><figure class="highlight shell hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">git clone https://aur.archlinux.org/yay.git</span><br><span class="line">cd yay</span><br><span class="line">makepkg -si</span><br></pre></td></tr></table></figure><ul><li>字体 &amp; 表情 &amp; 图标 &amp; 主题</li></ul><figure class="highlight shell hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">yay -S ttf-linux-libertine ttf-inconsolata ttf-joypixels ttf-twemoji-color noto-fonts-emoji ttf-liberation ttf-droid</span><br><span class="line">yay -S wqy-bitmapfont wqy-microhei wqy-microhei-lite wqy-zenhei adobe-source-han-mono-cn-fonts adobe-source-han-sans-cn-fonts adobe-source-han-serif-cn-fonts</span><br></pre></td></tr></table></figure><p><a href="https://github.com/ryanoasis/nerd-fonts" target="_blank" rel="noopener">nerd-fonts</a></p><p><a href="https://github.com/stark/siji" target="_blank" rel="noopener">siji</a></p><ul><li>软件包</li></ul><figure class="highlight shell hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yay -S acpi acpitool adapta-gtk-theme alsa-utils feh google-chrome htop gnome-screenshot lxappearance nerd-fonts-source-code-pro network-manager-applet picom simplescreenrecorder screenkey thunar trayer tlp unzip vlc w3m xfce4-power-manager xfce4-volumed-pulse zip zsh lazygit ranger fzf</span><br></pre></td></tr></table></figure><p><a style="background-color:black;color:white;text-decoration:none;padding:4px 6px;font-family:-apple-system, BlinkMacSystemFont, &quot;San Francisco&quot;, &quot;Helvetica Neue&quot;, Helvetica, Ubuntu, Roboto, Noto, &quot;Segoe UI&quot;, Arial, sans-serif;font-size:12px;font-weight:bold;line-height:1.2;display:inline-block;border-radius:3px" href="https://unsplash.com/@rodlong?utm_medium=referral&amp;utm_campaign=photographer-credit&amp;utm_content=creditBadge" target="_blank" rel="noopener noreferrer" title="Download free do whatever you want high-resolution photos from Rod Long"><span style="display:inline-block;padding:2px 3px"><svg xmlns="http://www.w3.org/2000/svg" style="height:12px;width:auto;position:relative;vertical-align:middle;top:-2px;fill:white" viewbox="0 0 32 32"><title>unsplash-logo</title><path d="M10 9V0h12v9H10zm12 5h10v18H0V14h10v9h12v-9z"/></svg></span><span style="display:inline-block;padding:2px 3px">Rod Long</span></a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;a href=&quot;https://wiki.archlinux.org/index.php/Installation_guide&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;参考官方文档&lt;/a&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="Linux" scheme="http://gallonhu.github.io/categories/Linux/"/>
    
    
      <category term="Archlinux" scheme="http://gallonhu.github.io/tags/Archlinux/"/>
    
  </entry>
  
  <entry>
    <title>软件工具篇</title>
    <link href="http://gallonhu.github.io/posts/fbcc746f/"/>
    <id>http://gallonhu.github.io/posts/fbcc746f/</id>
    <published>2019-12-26T02:00:14.000Z</published>
    <updated>2020-01-16T10:46:29.165Z</updated>
    
    <summary type="html">
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>终端利器之tmux篇</title>
    <link href="http://gallonhu.github.io/posts/7309d80/"/>
    <id>http://gallonhu.github.io/posts/7309d80/</id>
    <published>2019-12-26T01:59:04.000Z</published>
    <updated>2020-01-16T10:46:29.164Z</updated>
    
    <summary type="html">
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>终端利器之vim篇</title>
    <link href="http://gallonhu.github.io/posts/848c0324/"/>
    <id>http://gallonhu.github.io/posts/848c0324/</id>
    <published>2019-12-17T11:14:34.000Z</published>
    <updated>2020-01-23T02:48:24.443Z</updated>
    
    <content type="html"><![CDATA[<p>基本上，只要你使用过终端，多多少少应该都接触过 vim，但对大多数的新手来说，vim 的体验感绝对算不上好，甚至可以用糟糕来形容。但事实上，大部分人都没能体会到 vim 的牛逼之处就早早的放弃了，所以我们接<a href="https://gallonhu.github.io/posts/848c0324/">上一篇</a>，这次好好讲一讲 <code>vim</code> 的使用。</p><p>首先，vim 是什么？本质上来讲，vim 只是一个编译器，只不过以下的几个特性让它变得不可思议：</p><ol><li>几乎在所有平台、ide 都内置</li><li>高度可定制化（包括大量的插件）</li><li>支持所有的编程语言</li></ol><p>老规矩，文章分为三部分：安装、配置和插件。</p><p>先放效果图</p><img src="https://cdn.jsdelivr.net/gh/GallonHu/pic@master/screenshot/Screen-Shot-2020-01-19-at-10.34.45-AM.png" style="zoom:80%;"><h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><p>对于几乎所有的 <code>Linux</code> 或者 <code>Unix</code> 系统，都内置安装了 vim，这里就不过多的介绍 vim 了，我们主要来介绍基于 vim 开发的另外一个东西——<a href="https://github.com/neovim/neovim" target="_blank" rel="noopener">neovim</a>，至于我为什么使用 neovim，主要是以下几点</p><h3 id="全面并发"><a href="#全面并发" class="headerlink" title="全面并发"></a>全面并发</h3><p>虽说 vim 8 也开始支持了，但这当初应该是被 neovim 倒逼出来的。</p><h3 id="默认配置更加友好"><a href="#默认配置更加友好" class="headerlink" title="默认配置更加友好"></a>默认配置更加友好</h3><p>说起来 vim 的一些过时默认配置会让你大吃一惊，比如它默认的 encoding 至今依然是 <code>latin1</code> ！neovim 当然早改用 <code>utf-8</code> 了。还有<a href="https://neovim.io/doc/user/vim_diff.html#nvim-defaults" target="_blank" rel="noopener">一些不合时宜的默认 setting 也纷纷得到了修改</a>，免去用户手动配置之苦，我就在迁移原 <code>.vimrc</code> 时删去了 25 行多，净化完毕，更加极简！</p><h3 id="充分遵循-XDG-规范"><a href="#充分遵循-XDG-规范" class="headerlink" title="充分遵循 XDG 规范"></a>充分遵循 XDG 规范</h3><p>vim 默认的 <code>.vimrc</code> 和 <code>.vim</code> 均一般在 <code>$HOME</code> 下，neovim 则全挪为 <code>$XDG_CONFIG_HOME/nvim/init.vim</code> 和 <code>$XDG_CONFIG_HOME/nvim</code>.</p><p>vim 编辑文件时，可以有多达四个的数据文件：<code>backup</code>, <code>swapfile</code>, <code>undofile</code> 和 <code>viminfo</code>. Unix 下的 vim 分别默认存在 <code>&quot;.,~/tmp,~/&quot;</code>, <code>&quot;.,~/tmp,/var/tmp,/tmp&quot;</code>, <code>&quot;.&quot;</code>, 其中 <code>viminfo</code> 的具体储存位置我一时还查不出来，就懒得深究了。后来得知：undofile 默认没有值，不保存撤销记录，viminfo 位于用户目录。</p><p>neovim 则全改储存在 <code>$XDG_DATA_HOME/nvim/</code> 下各自的目录里，此外 viminfo 更是被抛弃，被叫 ShaDa 且更为先进的二进制文件所代替，后者位于 <code>$XDG_DATA_HOME/nvim/shada/main.shada</code>。</p><p>再加上用户自行安装的 neovim 二进制包也在 <code>$HOME/.local/bin</code> 里，一家人更加整整齐齐。</p><p>至于如何安装，请自行解决。</p><h2 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h2><p>我的配置目录如下</p><figure class="highlight shell hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">~/.config/nvim</span><br><span class="line">➜ tree -L 2</span><br><span class="line">.</span><br><span class="line">├── autoload</span><br><span class="line">│   └── functions.vim</span><br><span class="line">├── colors</span><br><span class="line">│   ├── NeoSolarized.vim</span><br><span class="line">│   └── solarized.vim</span><br><span class="line">├── init.vim</span><br><span class="line">└── rc</span><br><span class="line">    ├── 01.settings.vim</span><br><span class="line">    ├── 02.plugin.vim</span><br><span class="line">    ├── 03.airline.vim</span><br><span class="line">    ├── 04.tabs.vim</span><br><span class="line">    ├── 05.dev.vim</span><br><span class="line">    ├── 06.tagbar.vim</span><br><span class="line">    ├── 07.ctrlp.vim</span><br><span class="line">    ├── 08.fzf.vim</span><br><span class="line">    ├── 09.nerdtree.vim</span><br><span class="line">    └── 10.startify.vim</span><br></pre></td></tr></table></figure><p>刚安装时，默认的配置文件只有 <code>init.vim</code>，neovim 默认会加载它。这里我们先看看我的配置</p><figure class="highlight shell hljs"><figcaption><span>init.vim</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">for f in split(glob('~/.config/nvim/rc/*.vim'), '\n')</span><br><span class="line">    exe 'source' f</span><br><span class="line">endfor</span><br></pre></td></tr></table></figure><p>其实，思路很简单，真正的配置都放在 <code>rc</code> 目录下，这样做的目的是使配置文件更加的清晰简单，大概就是分为基础配置，插件安装，插件配置三大块，大家根据名字应该能很容易的理解</p><h2 id="插件"><a href="#插件" class="headerlink" title="插件"></a>插件</h2><p><a style="background-color:black;color:white;text-decoration:none;padding:4px 6px;font-family:-apple-system, BlinkMacSystemFont, &quot;San Francisco&quot;, &quot;Helvetica Neue&quot;, Helvetica, Ubuntu, Roboto, Noto, &quot;Segoe UI&quot;, Arial, sans-serif;font-size:12px;font-weight:bold;line-height:1.2;display:inline-block;border-radius:3px" href="https://unsplash.com/@mfildzafadzil?utm_medium=referral&amp;utm_campaign=photographer-credit&amp;utm_content=creditBadge" target="_blank" rel="noopener noreferrer" title="Download free do whatever you want high-resolution photos from M.Fildza Fadzil"><span style="display:inline-block;padding:2px 3px"><svg xmlns="http://www.w3.org/2000/svg" style="height:12px;width:auto;position:relative;vertical-align:middle;top:-2px;fill:white" viewbox="0 0 32 32"><title>unsplash-logo</title><path d="M10 9V0h12v9H10zm12 5h10v18H0V14h10v9h12v-9z"/></svg></span><span style="display:inline-block;padding:2px 3px">M.Fildza Fadzil</span></a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;基本上，只要你使用过终端，多多少少应该都接触过 vim，但对大多数的新手来说，vim 的体验感绝对算不上好，甚至可以用糟糕来形容。但事实上，大部分人都没能体会到 vim 的牛逼之处就早早的放弃了，所以我们接&lt;a href=&quot;https://gallonhu.github.i
      
    
    </summary>
    
    
      <category term="Tutorials" scheme="http://gallonhu.github.io/categories/Tutorials/"/>
    
    
      <category term="Terminal" scheme="http://gallonhu.github.io/tags/Terminal/"/>
    
      <category term="Vim" scheme="http://gallonhu.github.io/tags/Vim/"/>
    
  </entry>
  
  <entry>
    <title>终端利器之zsh篇</title>
    <link href="http://gallonhu.github.io/posts/eec0bc4e/"/>
    <id>http://gallonhu.github.io/posts/eec0bc4e/</id>
    <published>2019-12-16T06:50:38.000Z</published>
    <updated>2020-01-18T13:33:53.475Z</updated>
    
    <content type="html"><![CDATA[<p>对于开发者而言，终端的使用频率算是比较高的。其实，对我而言，日常中的大部分开发都是在终端中完成的，算得上是半个重度终端使用者了。恰好这次重新整理博客，所以打算写一个终端系列。主要包括终端美化和一些使用技巧。这篇文章主要介绍 <code>zsh</code>，后续会出文章介绍 <code>vim</code> 和 <code>tmux</code>。</p><p>这个系列所有的配置文件都在 <a href="https://github.com/GallonHu/terminal-config" target="_blank" rel="noopener">github 仓库</a>，感兴趣的自提，喜欢的不妨给个<code>star</code>~</p><a id="more"></a><p>先放一张效果图</p><div align="center"><img src="https://cdn.jsdelivr.net/gh/GallonHu/pic@master/screenshot/Screen-Shot-2019-12-16-at-3.27.32-PM.png" style="zoom:75%;"></div><h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><h3 id="zsh安装"><a href="#zsh安装" class="headerlink" title="zsh安装"></a>zsh安装</h3><p><em>Macos</em> 默认安装了 <code>zsh</code>，以下为 <em>centos</em> 安装的命令</p><figure class="highlight bash hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">sudo yjm install zsh</span><br><span class="line"></span><br><span class="line"><span class="hljs-comment"># 用户默认使用 zsh</span></span><br><span class="line">sudo chsh -s /bin/zsh &lt;username&gt;</span><br></pre></td></tr></table></figure><h3 id="oh-my-zsh安装"><a href="#oh-my-zsh安装" class="headerlink" title="oh-my-zsh安装"></a>oh-my-zsh安装</h3><p><code>zsh</code> 本体有着强大的功能，但碍于其复杂的配置，对普通用户而言并不太适合。但是，一个开源项目的出现打破了这一局面 —— 它就是本文的主角：<a href="https://github.com/robbyrussell/oh-my-zsh" target="_blank" rel="noopener">Oh My Zsh</a>。借助 Oh My Zsh，你只需要进行极为简单的安装配置，就可以用上 <code>zsh</code>，并享受许多酷炫的功能，它的安装也很简单。</p><figure class="highlight bash hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sh -c <span class="hljs-string">"<span class="hljs-variable">$(curl -fsSL https://raw.github.com/robbyrussell/oh-my-zsh/master/tools/install.sh)</span>"</span></span><br></pre></td></tr></table></figure><p>在安装过程中会提示 <code>Do you want to change your default shell to zsh? [Y/n]</code>（是否将默认 Shell 切换到 Zsh），按下 <code>Y</code> 并回车即可。随后会提示 <code>Password for xxx</code>，输入你的用户密码并回车即可。当你看见大大的 <code>Oh my zsh</code> 标志时就表示 Oh My Zsh 已经安装成功了。</p><h2 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h2><h3 id="目录结构"><a href="#目录结构" class="headerlink" title="目录结构"></a>目录结构</h3><p>欲善其功，必先利其器。了解 <code>oh-my-zsh</code> 的目录结构能极大的加深你对它的理解，也能让你对后续的配置更熟悉。</p><p>为了书写的方便，如无特别注明，后续所有的 <code>zsh</code> 都指 <code>oh-my-zsh</code>。</p><p>安装完 <code>zsh</code> 后，会自动在 <em>$HOME</em> 下生成默认配置文件 <code>.zshrc</code>。一般而言，用户只需要修改此文件即可。</p><p><code>zsh</code> 的目录结构如下</p><figure class="highlight bash hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">.oh-my-zsh</span><br><span class="line">├── CODE_OF_CONDUCT.md</span><br><span class="line">├── CONTRIBUTING.md</span><br><span class="line">├── LICENSE.txt</span><br><span class="line">├── README.md</span><br><span class="line">├── cache</span><br><span class="line">├── custom</span><br><span class="line">├── lib</span><br><span class="line">├── <span class="hljs-built_in">log</span></span><br><span class="line">├── oh-my-zsh.sh</span><br><span class="line">├── plugins</span><br><span class="line">├── templates</span><br><span class="line">├── themes</span><br><span class="line">└── tools</span><br></pre></td></tr></table></figure><p>其中只有三个文件夹需要你关注</p><ul><li>custom 第三方插件和主题的存放位置</li></ul><figure class="highlight shell hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">custom</span><br><span class="line">├── example.zsh</span><br><span class="line">├── plugins</span><br><span class="line">└── themes</span><br></pre></td></tr></table></figure><ul><li>plugins 和 themes 内置插件和主题存放位置</li></ul><p>了解完目录，我们再看一下 <code>zsh</code> 加载插件和主题的过程。</p><p>首先看一下 <code>.zshrc</code></p><figure class="highlight shell hljs"><figcaption><span>.zshrc </span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">source $ZSH/oh-my-zsh.sh</span><br></pre></td></tr></table></figure><p>在设置完各种配置后，<code>zsh</code> 会先执行 <code>oh-my-zsh.sh</code> 脚本，这个才是真正加载你的配置的时候。我们把加载插件的过程拿出来看看，其他的加载过程都差不多</p><figure class="highlight shell hljs"><figcaption><span>oh-my-zsh.sh</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> Add all defined plugins to fpath. This must be <span class="hljs-keyword">done</span></span></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> before running compinit.</span></span><br><span class="line">for plugin ($plugins); do</span><br><span class="line">  if is_plugin $ZSH_CUSTOM $plugin; then</span><br><span class="line">    fpath=($ZSH_CUSTOM/plugins/$plugin $fpath)</span><br><span class="line">  elif is_plugin $ZSH $plugin; then</span><br><span class="line">    fpath=($ZSH/plugins/$plugin $fpath)</span><br><span class="line">  else</span><br><span class="line">    echo "[oh-my-zsh] plugin '$plugin' not found"</span><br><span class="line">  fi</span><br><span class="line">done</span><br></pre></td></tr></table></figure><p>可以很直观的看到，它会遍历你使用的所有插件，然后，它先去第三方插件目录下查找，没找到的话再去内置插件目录下查找。这样以来，我们就很直观的了解了，若想用第三方插件，只需要把它放到 <code>custom/plugins</code> 目录下即可。同样，主题也是如此。 </p><p>有了上面的基础后，下面我们主要从美化的角度来进行配置。 </p><h3 id="美化配置"><a href="#美化配置" class="headerlink" title="美化配置"></a>美化配置</h3><p>美化主要包括两部分，主题和字体。</p><h4 id="主题"><a href="#主题" class="headerlink" title="主题"></a>主题</h4><p>主题的设置在 <code>.zshrc</code> 中，修改下面内容为你喜欢的主题即可</p><figure class="highlight shell hljs"><figcaption><span>.zshrc</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ZSH_THEME="spaceship"</span><br></pre></td></tr></table></figure><p><code>zsh</code>有很多 <a href="https://github.com/robbyrussell/oh-my-zsh/wiki/Themes" target="_blank" rel="noopener">内置主题</a> 和 <a href="https://github.com/robbyrussell/oh-my-zsh/wiki/External-themes" target="_blank" rel="noopener">第三方主题</a>，大家可以参考链接给的官方文档挑选喜欢的。</p><p>下面介绍的是我使用的主题 <a href="https://github.com/denysdovhan/spaceship-prompt" target="_blank" rel="noopener">spaceship</a> 的配置。</p><p>首先看一下配置完成的效果</p><div align="center"><img src="   https://cdn.jsdelivr.net/gh/GallonHu/pic@master/screenshot/Screen-Shot-2019-12-16-at-5.24.26-PM.2019-12-16-18_28_37.gif" style="zoom:75%;"></div><p>关于这个主题的更多特性，想要了解更多的可以去官方了解。</p><p><strong>安装</strong></p><p>先 <code>clone</code> 主题</p><figure class="highlight shell hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git clone https://github.com/denysdovhan/spaceship-prompt.git "$ZSH_CUSTOM/themes/spaceship-prompt"</span><br></pre></td></tr></table></figure><p>链接到第三方主题目录</p><figure class="highlight shell hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ln -s "$ZSH_CUSTOM/themes/spaceship-prompt/spaceship.zsh-theme" "$ZSH_CUSTOM/themes/spaceship.zsh-theme"</span><br></pre></td></tr></table></figure><p>然后在 <code>.zshrc</code> 中设置主题，再刷新或者重启终端即可。</p><h4 id="字体"><a href="#字体" class="headerlink" title="字体"></a>字体</h4><p>如果你是安装前面的步骤一步一步安装的，到这里你应该会发现出现了乱码的情况，这主要是字体不支持的缘故。这里，我们安装一下 <a href="https://github.com/powerline/fonts" target="_blank" rel="noopener">powerline</a>。</p><figure class="highlight shell hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> <span class="hljs-built_in">clone</span></span></span><br><span class="line">git clone https://github.com/powerline/fonts.git --depth=1</span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> install</span></span><br><span class="line">cd fonts</span><br><span class="line">./install.sh</span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> clean-up a bit</span></span><br><span class="line">cd ..</span><br><span class="line">rm -rf fonts</span><br></pre></td></tr></table></figure><p>再在你使用的终端中选择需要的字体，这里以 <code>iterm2</code> 为例。打开 <code>Preferences-&gt;Profiles-&gt;Text-&gt;Change Font</code> 选择字体，我这里使用的是 <code>SauceCodePro Nerd Font</code>。</p><img src=" https://cdn.jsdelivr.net/gh/GallonHu/pic@master/screenshot/Screen-Shot-2019-12-16-at-7.04.31-PM.png" style="zoom:75%;"><h2 id="插件"><a href="#插件" class="headerlink" title="插件"></a>插件</h2><p>接下来是关于我使用的插件，主要分为内置插件和三方插件。</p><p>插件的配置在 <code>.zshrc</code> 中</p><figure class="highlight shell hljs"><figcaption><span>.zshrc</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">plugins=(</span><br><span class="line">  git sudo vscode wakatime z zsh-autosuggestions extract web-search git-open zsh-syntax-highlighting </span><br><span class="line">)</span><br></pre></td></tr></table></figure><h3 id="内置插件"><a href="#内置插件" class="headerlink" title="内置插件"></a>内置插件</h3><h4 id="git"><a href="#git" class="headerlink" title="git"></a>git</h4><p>为 <code>git</code> 添加了很多快捷键，比如</p><p><code>gaa</code> :  <em>git add -A</em></p><p><code>gc</code>:  <em>git commit -v</em></p><p><code>ggp</code>:  <em>git push origin $(current_branch)</em></p><p><code>ggl</code>:  <em>git pull origin $(current_branch)</em></p><p>这里就不一一列举了，感兴趣的可以自行查看 <code>.oh-my-zsh/plugins/git/README.md</code>。 </p><h4 id="sudo"><a href="#sudo" class="headerlink" title="sudo"></a>sudo</h4><p>通过按两下 <code>esc</code> 自动添加 <code>sudo</code> 前缀。</p><p><strong>效果</strong>  </p><img src=" https://cdn.jsdelivr.net/gh/GallonHu/pic@master/screenshot/Screen-Shot-2019-12-16-at-9.08.47-PM.2019-12-16-21_12_21.gif" style="zoom:80%;"><h4 id="z"><a href="#z" class="headerlink" title="z"></a>z</h4><p>快速跳转，谁用谁知道。</p><p><strong>效果</strong></p><img src=" https://cdn.jsdelivr.net/gh/GallonHu/pic@master/screenshot/Screen-Shot-2019-12-16-at-9.16.23-PM.2019-12-16-21_22_52.gif" style="zoom:80%;"><h4 id="extract"><a href="#extract" class="headerlink" title="extract"></a>extract</h4><p>不用记那么多解压参数，一键解压，无脑操作。</p><p><strong>效果</strong></p><img src=" https://cdn.jsdelivr.net/gh/GallonHu/pic@master/screenshot/Screen-Shot-2019-12-16-at-9.19.55-PM.2019-12-16-21_23_54.gif" style="zoom:80%;"><h4 id="web-search"><a href="#web-search" class="headerlink" title="web-search"></a>web-search</h4><p>终端打开浏览器搜索。</p><p><strong>效果</strong></p><img src=" https://cdn.jsdelivr.net/gh/GallonHu/pic@master/screenshot/Screen-Shot-2019-12-16-at-9.21.17-PM.2019-12-16-21_25_01.gif" style="zoom:80%;"><h3 id="三方插件"><a href="#三方插件" class="headerlink" title="三方插件"></a>三方插件</h3><h4 id="git-open"><a href="#git-open" class="headerlink" title="git-open"></a><a href="https://github.com/paulirish/git-open" target="_blank" rel="noopener">git-open</a></h4><p>快速打开 <code>git</code> 仓库。</p><p><strong>安装</strong></p><figure class="highlight bash hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git <span class="hljs-built_in">clone</span> https://github.com/paulirish/git-open.git <span class="hljs-variable">$ZSH_CUSTOM</span>/plugins/git-open</span><br></pre></td></tr></table></figure><p>配置文件中插件下添加<code>git-open</code> 。</p><p>默认使用<code>git open</code>打开仓库，你可以重新设置一下快捷键，比如<code>go</code>，我因为使用<code>golang</code>所以换成了<code>Go</code>。   </p><figure class="highlight shell hljs"><figcaption><span>.zshrc</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">alias Go="git-open"</span><br></pre></td></tr></table></figure><p><strong>效果</strong></p><img src="https://cdn.jsdelivr.net/gh/GallonHu/pic@master/screenshot/2019-12-16-20_16_12.gif" style="zoom:80%;"><h4 id="vscode"><a href="#vscode" class="headerlink" title="vscode"></a><a href="https://github.com/valentinocossar/vscode" target="_blank" rel="noopener">vscode</a></h4><p>在终端中使用 <code>vscode</code> 打开文件。</p><p><strong>安装</strong></p><figure class="highlight bash hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git <span class="hljs-built_in">clone</span> https://github.com/valentinocossar/vscode.git <span class="hljs-variable">$ZSH_CUSTOM</span>/plugins/vscode</span><br></pre></td></tr></table></figure><p>配置文件中插件下添加 <code>vscode</code> 。</p><p><strong>使用</strong></p><p><code>vs</code> ：后接文件、目录或者路径。</p><p>组合参数</p><p><code>a</code>：最后编辑的窗口</p><p><code>t</code>：当前目录</p><p><code>s</code>：<em>sudo</em>  </p><p>所以你可以使用一下组合</p><p><code>vs</code>：接文件、目录或路径，使用<code>vs code</code>打开 。</p><p><code>vsa</code>：打开上次编辑的窗口。</p><p><code>vst</code>：打开当前目录</p><p>随笔你组合。</p><p><strong>效果</strong></p><img src=" https://cdn.jsdelivr.net/gh/GallonHu/pic@master/screenshot//Screen-Shot-2019-12-16-at-8.32.56-PM.2019-12-16-20_34_36.gif" style="zoom:80%;"><h4 id="waketime"><a href="#waketime" class="headerlink" title="waketime"></a><a href="https://github.com/sobolevn/wakatime-zsh-plugin" target="_blank" rel="noopener">waketime</a></h4><p><code>waketime</code> 可以记录你的使用时长，同时还会记录你具体在那个项目上花了多少时间，最后还能分析你的使用习惯等待。当然，它基本在各个平台都有自己的插件。</p><p>想要使用这个插件，首先，你要去 <a href="https://wakatime.com/" target="_blank" rel="noopener">waketime官网</a> 申请一个账号，然后获取自己的密钥，然后再写入配置文件中。具体的操作流程，有需要或者兴趣的可以自行解决，官网或者百度都有教程，这里就不细说。</p><p><strong>安装</strong></p><figure class="highlight bash hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git <span class="hljs-built_in">clone</span> https://github.com/sobolevn/wakatime-zsh-plugin.git wakatime <span class="hljs-variable">$ZSH_CUSTOM</span>/plugins/vscode</span><br></pre></td></tr></table></figure><p>配置文件中插件下添加 <code>waketime</code> 。</p><p><strong>效果</strong></p><img src=" https://cdn.jsdelivr.net/gh/GallonHu/pic@master/screenshot/screencapture-wakatime-dashboard-2019-12-16-20_44_07.png" style="zoom:80%;"><h4 id="zsh-autosuggestions"><a href="#zsh-autosuggestions" class="headerlink" title="zsh-autosuggestions"></a><a href="https://github.com/zsh-users/zsh-autosuggestions" target="_blank" rel="noopener">zsh-autosuggestions</a></h4><p>自动提示，五星好评，居家必备。</p><p><strong>安装</strong></p><figure class="highlight bash hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git <span class="hljs-built_in">clone</span> https://github.com/zsh-users/zsh-autosuggestions <span class="hljs-variable">$ZSH_CUSTOM</span>//plugins/zsh-autosuggestions</span><br></pre></td></tr></table></figure><p>配置文件中插件下添加 <code>zsh-autosuggestions</code> 。</p><p>效果这里就不放了，看前面的那个图，大家应该就能感受的到。</p><h4 id="zsh-syntax-highlighting"><a href="#zsh-syntax-highlighting" class="headerlink" title="zsh-syntax-highlighting"></a><a href="https://github.com/zsh-users/zsh-syntax-highlighting" target="_blank" rel="noopener">zsh-syntax-highlighting</a></h4><p>语法高亮。</p><p><strong>安装</strong></p><figure class="highlight bash hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git <span class="hljs-built_in">clone</span> https://github.com/zsh-users/zsh-syntax-highlighting.git <span class="hljs-variable">$ZSH_CUSTOM</span>/plugins/zsh-syntax-highlighting</span><br></pre></td></tr></table></figure><p>配置文件中插件下添加 <code>zsh-syntax-highlighting</code> ，这里需要注意，把这个插件写在最后面。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>当然，以上只是我的配置方案。如果你想自己配置主题和插件，我相信看完这篇文章，对你来说应该都是小菜一碟。</p><p><a style="background-color:black;color:white;text-decoration:none;padding:4px 6px;font-family:-apple-system, BlinkMacSystemFont, &quot;San Francisco&quot;, &quot;Helvetica Neue&quot;, Helvetica, Ubuntu, Roboto, Noto, &quot;Segoe UI&quot;, Arial, sans-serif;font-size:12px;font-weight:bold;line-height:1.2;display:inline-block;border-radius:3px" href="https://unsplash.com/@estebanamaro?utm_medium=referral&amp;utm_campaign=photographer-credit&amp;utm_content=creditBadge" target="_blank" rel="noopener noreferrer" title="Download free do whatever you want high-resolution photos from Esteban Amaro"><span style="display:inline-block;padding:2px 3px"><svg xmlns="http://www.w3.org/2000/svg" style="height:12px;width:auto;position:relative;vertical-align:middle;top:-2px;fill:white" viewbox="0 0 32 32"><title>unsplash-logo</title><path d="M10 9V0h12v9H10zm12 5h10v18H0V14h10v9h12v-9z"/></svg></span><span style="display:inline-block;padding:2px 3px">Esteban Amaro</span></a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;对于开发者而言，终端的使用频率算是比较高的。其实，对我而言，日常中的大部分开发都是在终端中完成的，算得上是半个重度终端使用者了。恰好这次重新整理博客，所以打算写一个终端系列。主要包括终端美化和一些使用技巧。这篇文章主要介绍 &lt;code&gt;zsh&lt;/code&gt;，后续会出文章介绍 &lt;code&gt;vim&lt;/code&gt; 和 &lt;code&gt;tmux&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;这个系列所有的配置文件都在 &lt;a href=&quot;https://github.com/GallonHu/terminal-config&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;github 仓库&lt;/a&gt;，感兴趣的自提，喜欢的不妨给个&lt;code&gt;star&lt;/code&gt;~&lt;/p&gt;
    
    </summary>
    
    
      <category term="Tutorials" scheme="http://gallonhu.github.io/categories/Tutorials/"/>
    
    
      <category term="Zsh" scheme="http://gallonhu.github.io/tags/Zsh/"/>
    
      <category term="Terminal" scheme="http://gallonhu.github.io/tags/Terminal/"/>
    
  </entry>
  
  <entry>
    <title>shell相关</title>
    <link href="http://gallonhu.github.io/posts/dd355129/"/>
    <id>http://gallonhu.github.io/posts/dd355129/</id>
    <published>2019-12-16T03:19:34.000Z</published>
    <updated>2019-12-16T13:30:54.371Z</updated>
    
    <content type="html"><![CDATA[<p>我使用<em>shell</em>过程中碰到的一些问题，记录在此以便查询。</p><h2 id="shell中各种括号的作用"><a href="#shell中各种括号的作用" class="headerlink" title="shell中各种括号的作用"></a>shell中各种括号的作用</h2><h3 id="单小括号"><a href="#单小括号" class="headerlink" title="单小括号 ()"></a>单小括号 ()</h3><ol><li>命令组。括号中的命令将会新开一个子shell顺序执行，所以括号中的变量不能够被脚本余下的部分使用。括号中多个命令之间用分号隔开，最后一个命令可以没有分号，各命令和括号之间不必有空格。</li><li>命令替换。等同于<code>cmd</code>，shell扫描一遍命令行，发现了$(cmd)结构，便将$(cmd)中的cmd执行一次，得到其标准输出，再将此输出放到原来命令。有些shell不支持，如tcsh。</li><li>用于初始化数组。如：array=(a b c d)</li></ol><a id="more"></a><h3 id="双小括号"><a href="#双小括号" class="headerlink" title="双小括号 (())"></a>双小括号 (())</h3><ol><li>整数扩展。这种扩展计算是整数型的计算，不支持浮点型。((exp))结构扩展并计算一个算术表达式的值，如果表达式的结果为0，那么返回的退出状态码为1，或者是”假”，而一个非零值的表达式所返回的退出状态码将为0，或者是”true”。若是逻辑判断，表达式exp为真则为1,假则为0。</li><li>只要括号中的运算符、表达式符合C语言运算规则，都可用在$((exp))中，甚至是三目运算符。作不同进位(如二进制、八进制、十六进制)运算时，输出结果全都自动转化成了十进制。如：echo $((16#5f)) 结果为95 (16进位转十进制)</li><li>单纯用 (( )) 也可重定义变量值，比如 a=5; ((a++)) 可将 $a 重定义为6</li><li>常用于算术运算比较，双括号中的变量可以不使用$符号前缀。括号内支持多个表达式用逗号分开。 只要括号中的表达式符合C语言运算规则,比如可以直接使用for((i=0;i&lt;5;i++)), 如果不使用双括号, 则为for i in <code>seq 0 4</code>或者for i in {0..4}。再如可以直接使用if ((​$i&lt;5)), 如果不使用双括号, 则为if [ $i -lt 5 ]。</li></ol><h3 id="单中括号"><a href="#单中括号" class="headerlink" title="单中括号 []"></a>单中括号 []</h3><ol><li>bash 的内部命令，[和test是等同的。如果我们不用绝对路径指明，通常我们用的都是bash自带的命令。if/test结构中的左中括号是调用test的命令标识，右中括号是关闭条件判断的。这个命令把它的参数作为比较表达式或者作为文件测试，并且根据比较的结果来返回一个退出状态码。if/test结构中并不是必须右中括号，但是新版的Bash中要求必须这样。</li><li>Test和[]中可用的比较运算符只有==和!=，两者都是用于字符串比较的，不可用于整数比较，整数比较只能使用-eq，-gt这种形式。无论是字符串比较还是整数比较都不支持大于号小于号。如果实在想用，对于字符串比较可以使用转义形式，如果比较”ab”和”bc”：[ ab &lt; bc ]，结果为真，也就是返回状态为0。[ ]中的逻辑与和逻辑或使用-a 和-o 表示。</li><li>字符范围。用作正则表达式的一部分，描述一个匹配的字符范围。作为test用途的中括号内不能使用正则。</li><li>在一个array 结构的上下文中，中括号用来引用数组中每个元素的编号。</li></ol><h3 id="双中括号"><a href="#双中括号" class="headerlink" title="双中括号 [[]]"></a>双中括号 [[]]</h3><ol><li>[[是 bash 程序语言的关键字。并不是一个命令，[[ ]] 结构比[ ]结构更加通用。在[[和]]之间所有的字符都不会发生文件名扩展或者单词分割，但是会发生参数扩展和命令替换。</li><li>支持字符串的模式匹配，使用=~操作符时甚至支持shell的正则表达式。字符串比较时可以把右边的作为一个模式，而不仅仅是一个字符串，比如[[ hello == hell? ]]，结果为真。[[ ]] 中匹配字符串或通配符，不需要引号。</li><li>使用[[ … ]]条件判断结构，而不是[ … ]，能够防止脚本中的许多逻辑错误。比如，&amp;&amp;、||、&lt;和&gt; 操作符能够正常存在于[[ ]]条件判断结构中，但是如果出现在[ ]结构中的话，会报错。比如可以直接使用if [[ $a != 1 &amp;&amp; $a != 2 ]], 如果不适用双括号, 则为if [ ​$a -ne 1] &amp;&amp; [ $a != 2 ]或者if [ $a -ne 1 -a $a -ne 2 ]。</li><li>bash把双中括号中的表达式看作一个单独的元素，并返回一个退出状态码。</li></ol><p>例子</p><figure class="highlight shell hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">if ($i&lt;5) </span><br><span class="line">if [ $i -lt 5 ] </span><br><span class="line">if [ $a -ne 1 -a $a != 2 ] </span><br><span class="line">if [ $a -ne 1] &amp;&amp; [ $a != 2 ] </span><br><span class="line">if [[ $a != 1 &amp;&amp; $a != 2 ]] </span><br><span class="line">for i in $(seq 0 4);do echo $i;done</span><br><span class="line">for i in `seq 0 4`;do echo $i;done</span><br><span class="line">for ((i=0;i&lt;5;i++));do echo $i;done</span><br><span class="line">for i in &#123;0..4&#125;;do echo $i;done</span><br></pre></td></tr></table></figure><h3 id="大括号"><a href="#大括号" class="headerlink" title="大括号 {}"></a>大括号 {}</h3><h4 id="常规用法"><a href="#常规用法" class="headerlink" title="常规用法"></a>常规用法</h4><ol><li>大括号拓展。(通配(globbing))将对大括号中的文件名做扩展。在大括号中，不允许有空白，除非这个空白被引用或转义。第一种：对大括号中的以逗号分割的文件列表进行拓展。如 touch {a,b}.txt 结果为a.txt b.txt。第二种：对大括号中以点点（..）分割的顺序文件列表起拓展作用，如：touch {a..d}.txt 结果为a.txt b.txt c.txt d.txt</li></ol><figure class="highlight shell hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> ls &#123;ex1,ex2&#125;.sh </span></span><br><span class="line">ex1.sh ex2.sh </span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> ls &#123;ex&#123;1..3&#125;,ex4&#125;.sh </span></span><br><span class="line">ex1.sh ex2.sh ex3.sh ex4.sh </span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> ls &#123;ex[1-3],ex4&#125;.sh </span></span><br><span class="line">ex1.sh ex2.sh ex3.sh ex4.sh</span><br></pre></td></tr></table></figure><ol start="2"><li>代码块，又被称为内部组，这个结构事实上创建了一个匿名函数 。与小括号中的命令不同，大括号内的命令不会新开一个子shell运行，即脚本余下部分仍可使用括号内变量。括号内的命令间用分号隔开，最后一个也必须有分号。{}的第一个命令和左括号之间必须要有一个空格。</li></ol><figure class="highlight shell hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-meta">$</span><span class="hljs-bash">&#123;var:-string&#125;,<span class="hljs-variable">$&#123;var:+string&#125;</span>,<span class="hljs-variable">$&#123;var:=string&#125;</span>,<span class="hljs-variable">$&#123;var:?string&#125;</span></span></span><br></pre></td></tr></table></figure><ul><li><code>${var:-string}和${var:=string}</code>:若变量var为空，则用在命令行中用string来替换<code>${var:-string}</code>，否则变量var不为空时，则用变量var的值来替换<code>${var:-string}</code>；对于<code>${var:=string}</code>的替换规则和<code>${var:-string}</code>是一样的，所不同之处是<code>${var:=string}</code>若var为空时，用string替换<code>${var:=string}</code>的同时，把string赋给变量var： <code>${var:=string}</code>很常用的一种用法是，判断某个变量是否赋值，没有的话则给它赋上一个默认值。</li><li><code>${var:+string}</code>的替换规则和上面的相反，即只有当var不是空的时候才替换成string，若var为空时则不替换或者说是替换成变量 var的值，即空值。(因为变量var此时为空，所以这两种说法是等价的)</li><li><code>${var:?string}</code>替换规则为：若变量var不为空，则用变量var的值来替换<code>${var:?string}</code>；若变量var为空，则把string输出到标准错误中，并从脚本中退出。我们可利用此特性来检查是否设置了变量的值。</li></ul><p><strong>补充扩展：在上面这几种替换结构中string不一定是常值的，可用另外一个变量的值或是一种命令的输出。</strong></p><h4 id="模式匹配替换结构"><a href="#模式匹配替换结构" class="headerlink" title="模式匹配替换结构"></a>模式匹配替换结构</h4><p>模式匹配记忆方法：</p><p># 是去掉左边(在键盘上#在$之左边)<br>% 是去掉右边(在键盘上%在$之右边)<br># 和 %中的单一符号是最小匹配，两个相同符号是最大匹配。</p><figure class="highlight shell hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-meta">$</span><span class="hljs-bash">&#123;var%pattern&#125;,<span class="hljs-variable">$&#123;var%%pattern&#125;</span>,<span class="hljs-variable">$&#123;var#pattern&#125;</span>,<span class="hljs-variable">$&#123;var##pattern&#125;</span></span></span><br></pre></td></tr></table></figure><ul><li>第一种模式：<code>${variable%pattern}</code>，这种模式时，shell在variable中查找，看它是否是给的模式pattern结尾，如果是，就从命令行把variable中的内容去掉右边最短的匹配模式</li><li>第二种模式：<code>${variable%%pattern}，</code>这种模式时，shell在variable中查找，看它是否是给的模式pattern结尾，如果是，就从命令行把variable中的内容去掉右边最长的匹配模式</li><li>第三种模式：<code>${variable#pattern}</code> 这种模式时，shell在variable中查找，看它是否是给的模式pattern开始，如果是，就从命令行把variable中的内容去掉左边最短的匹配模式</li><li>第四种模式： <code>${variable##pattern}</code>这种模式时，shell在variable中查找，看它是否是给的模式pattern结尾，如果是，就从命令行把variable中的内容去掉右边最长的匹配模式</li></ul><p>　　这四种模式中都不会改变variable的值，其中，只有在pattern中使用了*匹配符号时，%和%%，#和##才有区别。结构中的pattern支持通配符，*表示零个或多个任意字符，?表示仅与一个任意字符匹配，[…]表示匹配中括号里面的字符，[!…]表示不匹配中括号里面的字符。</p><figure class="highlight shell hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> var=testcase </span></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> <span class="hljs-built_in">echo</span> <span class="hljs-variable">$var</span> </span></span><br><span class="line">testcase </span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> <span class="hljs-built_in">echo</span> <span class="hljs-variable">$&#123;var%s*e&#125;</span> </span></span><br><span class="line">testca </span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> <span class="hljs-built_in">echo</span> <span class="hljs-variable">$var</span> </span></span><br><span class="line">testcase </span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> <span class="hljs-built_in">echo</span> <span class="hljs-variable">$&#123;var%%s*e&#125;</span> </span></span><br><span class="line">te </span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> <span class="hljs-built_in">echo</span> <span class="hljs-variable">$&#123;var#?e&#125;</span> </span></span><br><span class="line">stcase </span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> <span class="hljs-built_in">echo</span> <span class="hljs-variable">$&#123;var##?e&#125;</span> </span></span><br><span class="line">stcase </span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> <span class="hljs-built_in">echo</span> <span class="hljs-variable">$&#123;var##*e&#125;</span></span></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> <span class="hljs-built_in">echo</span> <span class="hljs-variable">$&#123;var##*s&#125;</span> </span></span><br><span class="line">e </span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> <span class="hljs-built_in">echo</span> <span class="hljs-variable">$&#123;var##test&#125;</span> </span></span><br><span class="line">case</span><br></pre></td></tr></table></figure><h4 id="字符串提取和替换"><a href="#字符串提取和替换" class="headerlink" title="字符串提取和替换"></a>字符串提取和替换</h4><figure class="highlight shell hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-meta">$</span><span class="hljs-bash">&#123;var:num&#125;,<span class="hljs-variable">$&#123;var:num1:num2&#125;</span>,<span class="hljs-variable">$&#123;var/pattern/pattern&#125;</span>,<span class="hljs-variable">$&#123;var//pattern/pattern&#125;</span></span></span><br></pre></td></tr></table></figure><ul><li>第一种模式：<code>${var:num}</code>，这种模式时，shell在var中提取第num个字符到末尾的所有字符。若num为正数，从左边0处开始；若num为负数，从右边开始提取字串，但必须使用在冒号后面加空格或一个数字或整个num加上括号，如${var: -2}、​${var:1-3}或​${var:(-2)}。</li><li>第二种模式：<code>${var:num1:num2}，</code>num1是位置，num2是长度。表示从$var字符串的第​$num1个位置开始提取长度为$num2的子串。不能为负数。</li><li>第三种模式：<code>${var/pattern/pattern}</code>表示将var字符串的第一个匹配的pattern替换为另一个pattern。</li><li>第四种模式：<code>${var//pattern/pattern}</code>表示将var字符串中的所有能匹配的pattern替换为另一个pattern。</li></ul><figure class="highlight shell hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> var=/home/centos </span></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> <span class="hljs-built_in">echo</span> <span class="hljs-variable">$var</span> </span></span><br><span class="line">/home/centos</span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> <span class="hljs-built_in">echo</span> <span class="hljs-variable">$&#123;var:5&#125;</span> </span></span><br><span class="line">/centos</span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> <span class="hljs-built_in">echo</span> <span class="hljs-variable">$&#123;var: -6&#125;</span> </span></span><br><span class="line">centos </span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> <span class="hljs-built_in">echo</span> <span class="hljs-variable">$&#123;var:(-6)&#125;</span> </span></span><br><span class="line">centos </span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> <span class="hljs-built_in">echo</span> <span class="hljs-variable">$&#123;var:1:4&#125;</span> </span></span><br><span class="line">home </span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> <span class="hljs-built_in">echo</span> <span class="hljs-variable">$&#123;var/o/h&#125;</span> </span></span><br><span class="line">/hhme/centos</span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> <span class="hljs-built_in">echo</span> <span class="hljs-variable">$&#123;var//o/h&#125;</span> </span></span><br><span class="line">/hhme/cenths</span><br></pre></td></tr></table></figure><h3 id="后的括号"><a href="#后的括号" class="headerlink" title="$后的括号"></a>$后的括号</h3><ol><li>${a} 变量a的值, 在不引起歧义的情况下可以省略大括号。</li><li>$(cmd) 命令替换，和<code>cmd</code>效果相同，结果为shell命令cmd的输，过某些Shell版本不支持$()形式的命令替换, 如tcsh。</li><li>$((expression)) 和<code>exprexpression</code>效果相同, 计算数学表达式exp的数值, 其中exp只要符合C语言的运算规则即可, 甚至三目运算符和逻辑表达式都可以计算。</li></ol><h3 id="多条命令执行"><a href="#多条命令执行" class="headerlink" title="多条命令执行"></a>多条命令执行</h3><ol><li>单小括号，(cmd1;cmd2;cmd3) 新开一个子shell顺序执行命令cmd1,cmd2,cmd3, 各命令之间用分号隔开, 最后一个命令后可以没有分号。</li><li>单大括号，{ cmd1;cmd2;cmd3;} 在当前shell顺序执行命令cmd1,cmd2,cmd3, 各命令之间用分号隔开, 最后一个命令后必须有分号, 第一条命令和左括号之间必须用空格隔开。</li></ol><p>对{}和()而言, 括号中的重定向符只影响该条命令， 而括号外的重定向符影响到括号中的所有命令。</p><h2 id="shell编程四剑客"><a href="#shell编程四剑客" class="headerlink" title="shell编程四剑客"></a>shell编程四剑客</h2><h3 id="find"><a href="#find" class="headerlink" title="find"></a>find</h3><p>Linux find命令用来在指定目录下查找文件。任何位于参数之前的字符串都将被视为欲查找的目录名。如果使用该命令时，不设置任何参数，则find命令将在当前目录下查找子目录与文件。并且将查找到的子目录和文件全部进行显示。</p><h4 id="语法"><a href="#语法" class="headerlink" title="语法"></a>语法</h4><blockquote><p>find   path   -option   [   -print ]   [ -exec   -ok   command ]   {} ;</p><p><strong>参数说明</strong> :</p><p>find 根据下列规则判断 path 和 expression，在命令列上第一个 - ( ) , ! 之前的部份为 path，之后的是 expression。如果 path 是空字串则使用目前路径，如果 expression 是空字串则使用 -print 为预设 expression。</p><p>expression 中可使用的选项有二三十个之多，在此只介绍最常用的部份。</p><p>-mount, -xdev : 只检查和指定目录在同一个文件系统下的文件，避免列出其它文件系统中的文件</p><p>-amin n : 在过去 n 分钟内被读取过</p><p>-anewer file : 比文件 file 更晚被读取过的文件</p><p>-atime n : 在过去n天内被读取过的文件</p><p>-cmin n : 在过去 n 分钟内被修改过</p><p>-cnewer file :比文件 file 更新的文件</p><p>-ctime n : 在过去n天内被修改过的文件</p><p>-empty : 空的文件-gid n or -group name : gid 是 n 或是 group 名称是 name</p><p>-ipath p, -path p : 路径名称符合 p 的文件，ipath 会忽略大小写</p><p>-name name, -iname name : 文件名称符合 name 的文件。iname 会忽略大小写</p><p>-size n : 文件大小 是 n 单位，b 代表 512 位元组的区块，c 表示字元数，k 表示 kilo bytes，w 是二个位元组。-type c : 文件类型是 c 的文件。</p><p>d: 目录</p><p>c: 字型装置文件</p><p>b: 区块装置文件</p><p>p: 具名贮列</p><p>f: 一般文件</p><p>l: 符号连结</p><p>s: socket</p><p>-pid n : process id 是 n 的文件</p><p>你可以使用 ( ) 将运算式分隔，并使用下列运算。</p><p>exp1 -and exp2</p><p>! expr</p><p>-not expr</p><p>exp1 -or exp2</p><p>exp1, exp2</p></blockquote><h4 id="例子"><a href="#例子" class="headerlink" title="例子"></a>例子</h4><figure class="highlight shell hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> 查找home目录下名字为<span class="hljs-built_in">test</span>的所有txt文件</span></span><br><span class="line">find /home/ -name "test.txt"</span><br><span class="line"></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> 查找当前路径下，一天内创建的，名字以.txt结尾的目录（f表示文件），并将它复制到tmp目录下</span></span><br><span class="line">find . -name "*.txt" -type d -mtime -1 -exec cp -r &#123;&#125; /tmp/ \;</span><br><span class="line"></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> 查找当前路径下30天以前的后缀是<span class="hljs-built_in">log</span>的文件，然后删除掉</span></span><br><span class="line">find . -type f -name "*.log" -mtime +30 -exec rm -rf &#123;&#125; \;</span><br></pre></td></tr></table></figure><h3 id="grep"><a href="#grep" class="headerlink" title="grep"></a>grep</h3><p>Linux grep 命令用于查找文件里符合条件的字符串。</p><p>grep 指令用于查找内容包含指定的范本样式的文件，如果发现某文件的内容符合所指定的范本样式，预设 grep 指令会把含有范本样式的那一列显示出来。若不指定任何文件名称，或是所给予的文件名为 <strong>-</strong>，则 grep 指令会从标准输入设备读取数据。</p><h4 id="语法-1"><a href="#语法-1" class="headerlink" title="语法"></a>语法</h4><blockquote><p>  grep [-abcEFGhHilLnqrsvVwxy][-A&lt;显示列数&gt;][-B&lt;显示列数&gt;][-C&lt;显示列数&gt;][-d&lt;进行动作&gt;][-e&lt;范本样式&gt;][-f&lt;范本文件&gt;][–help][范本样式][文件或目录…]</p><p>  <strong>参数</strong>：</p><ul><li><strong>-a 或 –text</strong> : 不要忽略二进制的数据。</li><li><strong>-A&lt;显示行数&gt; 或 –after-context=&lt;显示行数&gt;</strong> : 除了显示符合范本样式的那一列之外，并显示该行之后的内容。</li><li><strong>-b 或 –byte-offset</strong> : 在显示符合样式的那一行之前，标示出该行第一个字符的编号。</li><li><strong>-B&lt;显示行数&gt; 或 –before-context=&lt;显示行数&gt;</strong> : 除了显示符合样式的那一行之外，并显示该行之前的内容。</li><li><strong>-c 或 –count</strong> : 计算符合样式的列数。</li><li><strong>-C&lt;显示行数&gt; 或 –context=&lt;显示行数&gt;或-&lt;显示行数&gt;</strong> : 除了显示符合样式的那一行之外，并显示该行之前后的内容。</li><li><strong>-d &lt;动作&gt; 或 –directories=&lt;动作&gt;</strong> : 当指定要查找的是目录而非文件时，必须使用这项参数，否则grep指令将回报信息并停止动作。</li><li><strong>-e&lt;范本样式&gt; 或 –regexp=&lt;范本样式&gt;</strong> : 指定字符串做为查找文件内容的样式。</li><li><strong>-E 或 –extended-regexp</strong> : 将样式为延伸的正则表达式来使用。</li><li><strong>-f&lt;规则文件&gt; 或 –file=&lt;规则文件&gt;</strong> : 指定规则文件，其内容含有一个或多个规则样式，让grep查找符合规则条件的文件内容，格式为每行一个规则样式。</li><li><strong>-F 或 –fixed-regexp</strong> : 将样式视为固定字符串的列表。</li><li><strong>-G 或 –basic-regexp</strong> : 将样式视为普通的表示法来使用。</li><li><strong>-h 或 –no-filename</strong> : 在显示符合样式的那一行之前，不标示该行所属的文件名称。</li><li><strong>-H 或 –with-filename</strong> : 在显示符合样式的那一行之前，表示该行所属的文件名称。</li><li><strong>-i 或 –ignore-case</strong> : 忽略字符大小写的差别。</li><li><strong>-l 或 –file-with-matches</strong> : 列出文件内容符合指定的样式的文件名称。</li><li><strong>-L 或 –files-without-match</strong> : 列出文件内容不符合指定的样式的文件名称。</li><li><strong>-n 或 –line-number</strong> : 在显示符合样式的那一行之前，标示出该行的列数编号。</li><li><strong>-o 或 –only-matching</strong> : 只显示匹配PATTERN 部分。</li><li><strong>-q 或 –quiet或–silent</strong> : 不显示任何信息。</li><li><strong>-r 或 –recursive</strong> : 此参数的效果和指定”-d recurse”参数相同。</li><li><strong>-s 或 –no-messages</strong> : 不显示错误信息。</li><li><strong>-v 或 –revert-match</strong> : 显示不包含匹配文本的所有行。</li><li><strong>-V 或 –version</strong> : 显示版本信息。</li><li><strong>-w 或 –word-regexp</strong> : 只显示全字符合的列。</li><li><strong>-x –line-regexp</strong> : 只显示全列符合的列。</li><li><strong>-y</strong> : 此参数的效果和指定”-i”参数相同。</li></ul></blockquote><h4 id="例子-1"><a href="#例子-1" class="headerlink" title="例子"></a>例子</h4><figure class="highlight shell hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> 查找passwd中的root字符并加行号加颜色显示</span></span><br><span class="line">grep -n --color "root" /etc/passwd</span><br><span class="line"></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> 查找文件中不含<span class="hljs-comment">#的行</span></span></span><br><span class="line">grep -v "#" /usr/data.txt</span><br></pre></td></tr></table></figure><h3 id="awk"><a href="#awk" class="headerlink" title="awk"></a>awk</h3><p>AWK是一种处理文本文件的语言，是一个强大的文本分析工具。</p><p>之所以叫AWK是因为其取了三位创始人 Alfred Aho，Peter Weinberger, 和 Brian Kernighan 的 Family Name 的首字符。</p><h4 id="语法-2"><a href="#语法-2" class="headerlink" title="语法"></a>语法</h4><blockquote><p>  awk [选项参数] ‘script’ var=value file(s)<br>  或<br>  awk [选项参数] -f scriptfile var=value file(s)</p><p>  <strong>选项参数说明：</strong></p><ul><li>-F fs or –field-separator fs<br>指定输入文件折分隔符，fs是一个字符串或者是一个正则表达式，如-F:。</li><li>-v var=value or –asign var=value<br>赋值一个用户定义变量。</li><li>-f scripfile or –file scriptfile<br>从脚本文件中读取awk命令。</li><li>-mf nnn and -mr nnn<br>对nnn值设置内在限制，-mf选项限制分配给nnn的最大块数目；-mr选项限制记录的最大数目。这两个功能是Bell实验室版awk的扩展功能，在标准awk中不适用。</li><li>-W compact or –compat, -W traditional or –traditional<br>在兼容模式下运行awk。所以gawk的行为和标准的awk完全一样，所有的awk扩展都被忽略。</li><li>-W copyleft or –copyleft, -W copyright or –copyright<br>打印简短的版权信息。</li><li>-W help or –help, -W usage or –usage<br>打印全部awk选项和每个选项的简短说明。</li><li>-W lint or –lint<br>打印不能向传统unix平台移植的结构的警告。</li><li>-W lint-old or –lint-old<br>打印关于不能向传统unix平台移植的结构的警告。</li><li>-W posix<br>打开兼容模式。但有以下限制，不识别：/x、函数关键字、func、换码序列以及当fs是一个空格时，将新行作为一个域分隔符；操作符<strong>和</strong>=不能代替^和^=；fflush无效。</li><li>-W re-interval or –re-inerval<br>允许间隔正则表达式的使用，参考(grep中的Posix字符类)，如括号表达式[[:alpha:]]。</li><li>-W source program-text or –source program-text<br>使用program-text作为源代码，可与-f命令混用。</li><li>-W version or –version<br>打印bug报告信息的版本。</li></ul></blockquote><h4 id="例子-2"><a href="#例子-2" class="headerlink" title="例子"></a>例子</h4><figure class="highlight shell hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> 显示所有数据并在第一列加上行号</span></span><br><span class="line">awk '&#123;print NR "\t" $0&#125;' test.txt</span><br><span class="line"></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> 显示所有数据并在第一列显示当前行的列数（空格分割为界）</span></span><br><span class="line">awk '&#123;print NF "\t" $0&#125;' test.txt</span><br><span class="line"></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> 查找功能</span></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> 查找第一列为bob的数据</span></span><br><span class="line">awk '$1=="bob"&#123;print $0&#125;' test.txt</span><br><span class="line"></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> 查找第7行数据</span></span><br><span class="line">awk 'NR==7&#123;print $0&#125;' test.txt</span><br><span class="line"></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> 输入按逗号分割开，输出按制表符分割显示（输入输出分隔符默认都是空格）</span></span><br><span class="line">awk 'BEGIN&#123;FS=","; OFS="\t"&#125; &#123;print $1, $2&#125;'</span><br><span class="line"></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> 将第3列的数据隐藏，显示为xxx</span></span><br><span class="line">awk '&#123;$3="xxx"; print $0&#125;' data.txt</span><br><span class="line"></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> 打出文件的最后一列数据</span></span><br><span class="line">awk '&#123;print $NF&#125;' data.txt</span><br><span class="line"></span><br><span class="line">awk '&#123;a=2; b="apple"; c=3; print b+c&#125;'  # 输出3，字符串和数字相加会把字符串中的最前面数字部分才会相加，没有数字部分则为0</span><br><span class="line">awk '&#123;a=2; b="32apple"; c=3; print b+c&#125;'  # 输出35，只有最前面是数字才会相加</span><br></pre></td></tr></table></figure><p><strong>Regular Expression(正则表达式)</strong></p><figure class="highlight shell hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> 匹配字符串中含有abc的值</span></span><br><span class="line">awk '/abc/&#123;print $0&#125;' data.txt</span><br><span class="line"></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> 匹配字符串中含有<span class="hljs-string">'a+一个任意字符+c'</span>的值</span></span><br><span class="line">awk '/a.c/&#123;print $0&#125;' data.txt</span><br><span class="line"></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> 如果就要匹配<span class="hljs-string">'a.c'</span>这个字符串就需要用转义字符</span></span><br><span class="line">awk '/a\.c/&#123;print $0&#125;' data.txt</span><br><span class="line"></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> ^和$ 表示开始和结尾</span></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> 匹配必须以abc开始的值</span></span><br><span class="line">awk '/^abc/&#123;print $0&#125;' data.txt</span><br><span class="line"></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> 匹配必须以abc结尾的值</span></span><br><span class="line">awk '/abc$/&#123;print $0&#125;' data.txt</span><br><span class="line"></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> 匹配<span class="hljs-string">'a+a到z任意一个字符+c'</span></span></span><br><span class="line">awk '/a[a-z]c/&#123;print $0&#125;' data.txt</span><br><span class="line"></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> 匹配<span class="hljs-string">'a+除了小写a到z之外的一个字符+c'</span></span></span><br><span class="line">awk '/a[^a-z]c/&#123;print $0&#125;' data.txt</span><br><span class="line"></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> 匹配<span class="hljs-string">'0个a或者任意个a+b'</span></span></span><br><span class="line">awk '/a*b/&#123;print $0&#125;' data.txt</span><br><span class="line"></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> 匹配<span class="hljs-string">'至少一个a+b'</span></span></span><br><span class="line">awk '/a+b/&#123;print $0&#125;' data.txt</span><br><span class="line"></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> 匹配<span class="hljs-string">'a可以有也可以没有+b'</span></span></span><br><span class="line">awk '/a?b/&#123;print $0&#125;' data.txt</span><br><span class="line"></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> 匹配<span class="hljs-string">'abbbc'</span></span></span><br><span class="line">awk '/ab&#123;3&#125;c/&#123;print $0&#125;' data.txt</span><br><span class="line"></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> 匹配<span class="hljs-string">'a+3个b到10个b+c'</span></span></span><br><span class="line">awk '/ab&#123;3,10&#125;c/&#123;print $0&#125;' data.txt</span><br></pre></td></tr></table></figure><h3 id="sed"><a href="#sed" class="headerlink" title="sed"></a>sed</h3><p>Linux sed 命令是利用脚本来处理文本文件。</p><p>sed 可依照脚本的指令来处理、编辑文本文件。</p><p>Sed 主要用来自动编辑一个或多个文件、简化对文件的反复操作、编写转换程序等。</p><h4 id="语法-3"><a href="#语法-3" class="headerlink" title="语法"></a>语法</h4><blockquote><p>  sed [-hnV][-e&lt;script&gt;][-f&lt;script文件&gt;][文本文件]</p><p>  <strong>参数说明</strong>：</p><ul><li>-e&lt;script文件&gt;或–expression=&lt;script文件&gt; 以选项中指定的script来处理输入的文本文件。</li><li>-f&lt;script文件&gt;或–file=&lt;script文件&gt; 以选项中指定的script文件来处理输入的文本文件。</li><li>-h或–help 显示帮助。</li><li>-n或–quiet或–silent 仅显示script处理后的结果。</li><li>-V或–version 显示版本信息。</li></ul><p>  <strong>动作说明</strong>：</p><ul><li>a ：新增， a 的后面可以接字串，而这些字串会在新的一行出现(目前的下一行)～</li><li>c ：取代， c 的后面可以接字串，这些字串可以取代 n1,n2 之间的行！</li><li>d ：删除，因为是删除啊，所以 d 后面通常不接任何咚咚；</li><li>i ：插入， i 的后面可以接字串，而这些字串会在新的一行出现(目前的上一行)；</li><li>p ：打印，亦即将某个选择的数据印出。通常 p 会与参数 sed -n 一起运行～</li><li>s ：取代，可以直接进行取代的工作哩！通常这个 s 的动作可以搭配正规表示法！例如 1,20s/old/new/g 就是啦！</li></ul></blockquote><h4 id="例子-3"><a href="#例子-3" class="headerlink" title="例子"></a>例子</h4><p>将文本以行为单位加载进内存的模式空间，默认不编辑原文件，仅对模式空间中的数据做处理，之后再显示出来</p><figure class="highlight shell hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> 删除第1行和第2行(d表示删除)</span></span><br><span class="line">sed '1,2d' test.txt</span><br><span class="line"></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> 删除第3行到最后一行（$表示最后一行，$-1表示倒数第二行）</span></span><br><span class="line">sed '3,$d' test.txt</span><br><span class="line"></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> 模式匹配，删除包含oot的行</span></span><br><span class="line">sed '/oot/d' test.txt</span><br><span class="line"></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> 显示以/开始的行，会重复显示，因为模式空间还会显示一次，可加<span class="hljs-string">'-n'</span>静默模式不显示模式空间的内容</span></span><br><span class="line">sed '/^\//p' test.txt</span><br><span class="line"></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> 在以/开头的行后面加上hello</span></span><br><span class="line">sed -n '/^\//a \hello' test.txt</span><br><span class="line"></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> 把包含oot的行数据保存到etc/fstab中</span></span><br><span class="line">sed -n '/oot/w test.txt' /etc/fstab</span><br><span class="line"></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> 把文件中的oot替换成OOT(默认只替换每行中第一次被匹配的字符串，加了修饰g，全局替换)</span></span><br><span class="line">sed 's/oot/OOT/g' test.txt</span><br></pre></td></tr></table></figure><h3 id="几个例子"><a href="#几个例子" class="headerlink" title="几个例子"></a>几个例子</h3><figure class="highlight shell hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> 查找当前目录下包含127.0.0.1关键字的文件</span></span><br><span class="line">grep -rl '127.0.0.1' ./</span><br><span class="line">find . -type f |xargs grep "127.0.0.1"</span><br><span class="line">find . -type f -exec awk '/127.0.0.1/' &#123;&#125; \;</span><br><span class="line"></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> 显示除过第3行到第10行的内容</span></span><br><span class="line">sed '3,10d' test.txt</span><br><span class="line">awk '!(NR&gt;=3&amp;&amp;NR&lt;=10)' test.txt</span><br><span class="line"></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> 显示第3行到第10行的内容</span></span><br><span class="line">sed -n '3,10p' test.txt</span><br><span class="line">awk 'NR&gt;=3&amp;&amp;NR&lt;=10' test.txt</span><br><span class="line">head -10 test.txt|tail -8</span><br><span class="line">awk 'NR==3,NR==7' test.txt# (逗号表示连续，第一次匹配到第二次匹配中间的所有行)</span><br><span class="line"></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> 只显示第3行和第10行的内容</span></span><br><span class="line">awk 'NR==3;NR==10' test.txt# (分号表示分隔符，分割多条命令)</span><br></pre></td></tr></table></figure><p><a style="background-color:black;color:white;text-decoration:none;padding:4px 6px;font-family:-apple-system, BlinkMacSystemFont, &quot;San Francisco&quot;, &quot;Helvetica Neue&quot;, Helvetica, Ubuntu, Roboto, Noto, &quot;Segoe UI&quot;, Arial, sans-serif;font-size:12px;font-weight:bold;line-height:1.2;display:inline-block;border-radius:3px" href="https://unsplash.com/@anniespratt?utm_medium=referral&amp;utm_campaign=photographer-credit&amp;utm_content=creditBadge" target="_blank" rel="noopener noreferrer" title="Download free do whatever you want high-resolution photos from Annie Spratt"><span style="display:inline-block;padding:2px 3px"><svg xmlns="http://www.w3.org/2000/svg" style="height:12px;width:auto;position:relative;vertical-align:middle;top:-2px;fill:white" viewbox="0 0 32 32"><title>unsplash-logo</title><path d="M10 9V0h12v9H10zm12 5h10v18H0V14h10v9h12v-9z"/></svg></span><span style="display:inline-block;padding:2px 3px">Annie Spratt</span></a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;我使用&lt;em&gt;shell&lt;/em&gt;过程中碰到的一些问题，记录在此以便查询。&lt;/p&gt;
&lt;h2 id=&quot;shell中各种括号的作用&quot;&gt;&lt;a href=&quot;#shell中各种括号的作用&quot; class=&quot;headerlink&quot; title=&quot;shell中各种括号的作用&quot;&gt;&lt;/a&gt;shell中各种括号的作用&lt;/h2&gt;&lt;h3 id=&quot;单小括号&quot;&gt;&lt;a href=&quot;#单小括号&quot; class=&quot;headerlink&quot; title=&quot;单小括号 ()&quot;&gt;&lt;/a&gt;单小括号 ()&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;命令组。括号中的命令将会新开一个子shell顺序执行，所以括号中的变量不能够被脚本余下的部分使用。括号中多个命令之间用分号隔开，最后一个命令可以没有分号，各命令和括号之间不必有空格。&lt;/li&gt;
&lt;li&gt;命令替换。等同于&lt;code&gt;cmd&lt;/code&gt;，shell扫描一遍命令行，发现了$(cmd)结构，便将$(cmd)中的cmd执行一次，得到其标准输出，再将此输出放到原来命令。有些shell不支持，如tcsh。&lt;/li&gt;
&lt;li&gt;用于初始化数组。如：array=(a b c d)&lt;/li&gt;
&lt;/ol&gt;
    
    </summary>
    
    
      <category term="Tutorials" scheme="http://gallonhu.github.io/categories/Tutorials/"/>
    
    
      <category term="Shell" scheme="http://gallonhu.github.io/tags/Shell/"/>
    
  </entry>
  
  <entry>
    <title>Centos-NTP</title>
    <link href="http://gallonhu.github.io/posts/87856f92/"/>
    <id>http://gallonhu.github.io/posts/87856f92/</id>
    <published>2019-12-16T03:16:08.000Z</published>
    <updated>2019-12-16T03:17:33.734Z</updated>
    
    <content type="html"><![CDATA[<h3 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h3><ol><li><p>NTP时钟同步方式说明<br> NTP在linux下有两种时钟同步方式，分别为直接同步和平滑同步：</p><ul><li><p>直接同步<br>  使用ntpdate命令进行同步，直接进行时间变更。如果服务器上存在一个12点运行的任务，当前服务器时间是13点，但标准时间时11点，使用此命令可能会造成任务重复执行。因此使用ntpdate同步可能会引发风险，因此该命令也多用于配置时钟同步服务时第一次同步时间时使用。 </p></li><li><p>平滑同步<br>  使用ntpd进行时钟同步，可以保证一个时间不经历两次，它每次同步时间的偏移量不会太陡，是慢慢来的，这正因为这样，ntpd平滑同步可能耗费的时间比较长。</p><a id="more"></a></li></ul></li><li><p>标准时钟同步服务<br> <a href="http://www.pool.ntp.org/zone/cn" target="_blank" rel="noopener">网站</a>包含全球的标准时间同步服务，也包括对中国时间的同步，对应的URL 为 cn.pool.ntp.org，在其中也描述了ntp配置文件中的建议写法：<br> server 1.cn.pool.ntp.org<br> server 3.asia.pool.ntp.org<br> server 2.asia.pool.ntp.org</p></li><li><p>环境</p></li></ol><table><thead><tr><th>节点</th><th>IP</th></tr></thead><tbody><tr><td>master</td><td>192.168.0.100</td></tr><tr><td>slave1</td><td>192.168.0.101</td></tr><tr><td>slave2</td><td>192.168.0.102</td></tr><tr><td>slave3</td><td>192.168.0.103</td></tr></tbody></table><h3 id="master-配置"><a href="#master-配置" class="headerlink" title="master 配置"></a>master 配置</h3><figure class="highlight shell hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> 安装 ntp</span></span><br><span class="line">yum install ntp</span><br><span class="line"></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> 启动 ntp 服务</span></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> 设置开机自启</span></span><br><span class="line">systemctl start ntpd</span><br><span class="line">systemctl enable ntpd</span><br><span class="line"></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> 配置 ntp.conf</span></span><br><span class="line">vi /etc/ntp.conf</span><br><span class="line"></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> For more information about this file, see the man pages</span></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> ntp.conf(5), ntp_acc(5), ntp_auth(5), ntp_clock(5), ntp_misc(5), ntp_mon(5).</span></span><br><span class="line">driftfile /var/lib/ntp/drift</span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> Permit time synchronization with our time <span class="hljs-built_in">source</span>, but <span class="hljs-keyword">do</span> not</span></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> permit the <span class="hljs-built_in">source</span> to query or modify the service on this system.</span></span><br><span class="line">restrict default nomodify notrap nopeer noquery</span><br><span class="line"></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> Permit all access over the loopback interface.  This could</span></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> be tightened as well, but to <span class="hljs-keyword">do</span> so would effect some of</span></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> the administrative <span class="hljs-built_in">functions</span>.</span></span><br><span class="line">restrict 127.0.0.1</span><br><span class="line">restrict ::1</span><br><span class="line"></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> Hosts on <span class="hljs-built_in">local</span> network are less restricted.</span></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash">restrict 192.168.1.0 mask 255.255.255.0 nomodify notrap</span></span><br><span class="line"></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> Use public servers from the pool.ntp.org project.</span></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> Please consider joining the pool (http://www.pool.ntp.org/join.html).</span></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash">server 0.centos.pool.ntp.org iburst</span></span><br><span class="line"></span><br><span class="line">server 2.cn.pool.ntp.org</span><br><span class="line">server 1.asia.pool.ntp.org</span><br><span class="line">server 2.asia.pool.ntp.org</span><br><span class="line"></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash">broadcast 192.168.1.255 autokey        <span class="hljs-comment"># broadcast server</span></span></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash">broadcastclient                        <span class="hljs-comment"># broadcast client</span></span></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash">broadcast 224.0.1.1 autokey            <span class="hljs-comment"># multicast server</span></span></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash">multicastclient 224.0.1.1              <span class="hljs-comment"># multicast client</span></span></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash">manycastserver 239.255.254.254         <span class="hljs-comment"># manycast server</span></span></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash">manycastclient 239.255.254.254 autokey <span class="hljs-comment"># manycast client</span></span></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> 允许上层时间服务器主动修改本机时间</span></span><br><span class="line">restrict 2.cn.pool.ntp.org nomodify notrap noquery</span><br><span class="line">restrict 1.asia.pool.ntp.org nomodify notrap noquery</span><br><span class="line">restrict 2.asia.pool.ntp.org nomodify notrap noquery</span><br><span class="line"></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> Enable public key cryptography.</span></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash">crypto</span></span><br><span class="line"></span><br><span class="line">includefile /etc/ntp/crypto/pw</span><br><span class="line"></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> Key file containing the keys and key identifiers used when operating</span></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> with symmetric key cryptography. </span></span><br><span class="line">keys /etc/ntp/keys</span><br><span class="line"></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> Specify the key identifiers <span class="hljs-built_in">which</span> are trusted.</span></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash">trustedkey 4 8 42</span></span><br><span class="line"></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> Specify the key identifier to use with the ntpdc utility.</span></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash">requestkey 8</span></span><br><span class="line"></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> Specify the key identifier to use with the ntpq utility.</span></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash">controlkey 8</span></span><br><span class="line"></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> Enable writing of statistics records.</span></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash">statistics clockstats cryptostats loopstats peerstats</span></span><br><span class="line"></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> Disable the monitoring facility to prevent amplification attacks using ntpdc</span></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> monlist <span class="hljs-built_in">command</span> when default restrict does not include the noquery flag. See</span></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> CVE-2013-5211 <span class="hljs-keyword">for</span> more details.</span></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> Note: Monitoring will not be disabled with the limited restriction flag.</span></span><br><span class="line">disable monitor</span><br><span class="line"></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> 重启 ntpd </span></span><br><span class="line">systemctl restart ntpd</span><br></pre></td></tr></table></figure><h3 id="slave-设置"><a href="#slave-设置" class="headerlink" title="slave 设置"></a>slave 设置</h3><figure class="highlight shell hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> 安装 ntp 并启动服务和开机自启</span></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> 和 master 设置方式一样</span></span><br><span class="line"></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> 配置 ntp.conf</span></span><br><span class="line">vi /etc/ntp.conf</span><br><span class="line"></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> For more information about this file, see the man pages</span></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> ntp.conf(5), ntp_acc(5), ntp_auth(5), ntp_clock(5), ntp_misc(5), ntp_mon(5).</span></span><br><span class="line"></span><br><span class="line">driftfile /var/lib/ntp/drift</span><br><span class="line"></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> Permit time synchronization with our time <span class="hljs-built_in">source</span>, but <span class="hljs-keyword">do</span> not</span></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> permit the <span class="hljs-built_in">source</span> to query or modify the service on this system.</span></span><br><span class="line">restrict default nomodify notrap nopeer noquery</span><br><span class="line"></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> Permit all access over the loopback interface.  This could</span></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> be tightened as well, but to <span class="hljs-keyword">do</span> so would effect some of</span></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> the administrative <span class="hljs-built_in">functions</span>.</span></span><br><span class="line">restrict 127.0.0.1</span><br><span class="line">restrict ::1</span><br><span class="line"></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> Hosts on <span class="hljs-built_in">local</span> network are less restricted.</span></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash">restrict 192.168.1.0 mask 255.255.255.0 nomodify notrap</span></span><br><span class="line"></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> Use public servers from the pool.ntp.org project.</span></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> Please consider joining the pool (http://www.pool.ntp.org/join.html).</span></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash">server 0.centos.pool.ntp.org iburst</span></span><br><span class="line"></span><br><span class="line">server 192.168.0.100</span><br><span class="line">restrict 192.168.0.100 nomodify notrap noquery</span><br><span class="line"></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash">broadcast 192.168.1.255 autokey        <span class="hljs-comment"># broadcast server</span></span></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash">broadcastclient                        <span class="hljs-comment"># broadcast client</span></span></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash">broadcast 224.0.1.1 autokey            <span class="hljs-comment"># multicast server</span></span></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash">multicastclient 224.0.1.1              <span class="hljs-comment"># multicast client</span></span></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash">manycastserver 239.255.254.254         <span class="hljs-comment"># manycast server</span></span></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash">manycastclient 239.255.254.254 autokey <span class="hljs-comment"># manycast client</span></span></span><br><span class="line"></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> Enable public key cryptography.</span></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash">crypto</span></span><br><span class="line">includefile /etc/ntp/crypto/pw</span><br><span class="line">    </span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> Key file containing the keys and key identifiers used when operating</span></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> with symmetric key cryptography. </span></span><br><span class="line">keys /etc/ntp/keys </span><br><span class="line">    </span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> Specify the key identifiers <span class="hljs-built_in">which</span> are trusted.</span></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash">trustedkey 4 8 42</span></span><br><span class="line"></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> Specify the key identifier to use with the ntpdc utility.</span></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash">requestkey 8</span></span><br><span class="line"></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> Specify the key identifier to use with the ntpq utility.</span></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash">controlkey 8</span></span><br><span class="line"></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> Enable writing of statistics records.</span></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash">statistics clockstats cryptostats loopstats peerstats</span></span><br><span class="line"></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> Disable the monitoring facility to prevent amplification attacks using ntpdc</span></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> monlist <span class="hljs-built_in">command</span> when default restrict does not include the noquery flag. See</span></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> CVE-2013-5211 <span class="hljs-keyword">for</span> more details.</span></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> Note: Monitoring will not be disabled with the limited restriction flag.</span></span><br><span class="line">disable monitor</span><br><span class="line"></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> 重启 ntpd</span></span><br></pre></td></tr></table></figure><h3 id="使用方式"><a href="#使用方式" class="headerlink" title="使用方式"></a>使用方式</h3><p>ntpq -p 查看网络中的NTP服务器，同时显示客户端和每个服务器的关系</p><figure class="highlight shell hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> ntpq -p 查看网络中的NTP服务器，同时显示客户端和每个服务器的关系</span></span><br><span class="line">[root@master ~]# ntpq -p</span><br><span class="line">     remote           refid      st t when poll reach   delay   offset  jitter</span><br><span class="line">==============================================================================</span><br><span class="line">+ntp7.flashdance 194.58.202.20    2 u   40   64  377  297.202    2.506   6.218</span><br><span class="line">*ntp.nic.kz      .SHM.            1 u   47   64  377  433.554  -74.865   7.147</span><br><span class="line">+send.mx.cdnetwo 216.239.35.8     2 u   33   64  377  262.368  -122.93  25.064</span><br><span class="line"> localhost       .INIT.          16 l    -  512    0    0.000    0.000   0.000</span><br><span class="line"> </span><br><span class="line">[root@slave1 ~]# ntpq -p</span><br><span class="line">     remote           refid      st t when poll reach   delay   offset  jitter</span><br><span class="line">==============================================================================</span><br><span class="line">*master          80.241.0.72      2 u   58   64  377    0.306   14.913   1.479</span><br><span class="line"> localhost       .INIT.          16 l    -  512    0    0.000    0.000   0.000</span><br></pre></td></tr></table></figure><figure class="highlight shell hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> ntpstat 查看时间同步状态</span></span><br><span class="line">[root@master ~]# ntpstat</span><br><span class="line">synchronised to NTP server (80.241.0.72) at stratum 2</span><br><span class="line">   time correct to within 343 ms</span><br><span class="line">   polling server every 64 s</span><br><span class="line"></span><br><span class="line">[root@slave1 ~]# ntpstat</span><br><span class="line">synchronised to NTP server (192.168.0.100) at stratum 3</span><br><span class="line">   time correct to within 347 ms</span><br><span class="line">   polling server every 64 s</span><br></pre></td></tr></table></figure><p><a style="background-color:black;color:white;text-decoration:none;padding:4px 6px;font-family:-apple-system, BlinkMacSystemFont, &quot;San Francisco&quot;, &quot;Helvetica Neue&quot;, Helvetica, Ubuntu, Roboto, Noto, &quot;Segoe UI&quot;, Arial, sans-serif;font-size:12px;font-weight:bold;line-height:1.2;display:inline-block;border-radius:3px" href="https://unsplash.com/@lenswithbenefits?utm_medium=referral&amp;utm_campaign=photographer-credit&amp;utm_content=creditBadge" target="_blank" rel="noopener noreferrer" title="Download free do whatever you want high-resolution photos from tommy boudreau"><span style="display:inline-block;padding:2px 3px"><svg xmlns="http://www.w3.org/2000/svg" style="height:12px;width:auto;position:relative;vertical-align:middle;top:-2px;fill:white" viewbox="0 0 32 32"><title>unsplash-logo</title><path d="M10 9V0h12v9H10zm12 5h10v18H0V14h10v9h12v-9z"/></svg></span><span style="display:inline-block;padding:2px 3px">tommy boudreau</span></a></p>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;&lt;p&gt;NTP时钟同步方式说明&lt;br&gt; NTP在linux下有两种时钟同步方式，分别为直接同步和平滑同步：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;直接同步&lt;br&gt;  使用ntpdate命令进行同步，直接进行时间变更。如果服务器上存在一个12点运行的任务，当前服务器时间是13点，但标准时间时11点，使用此命令可能会造成任务重复执行。因此使用ntpdate同步可能会引发风险，因此该命令也多用于配置时钟同步服务时第一次同步时间时使用。 &lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;平滑同步&lt;br&gt;  使用ntpd进行时钟同步，可以保证一个时间不经历两次，它每次同步时间的偏移量不会太陡，是慢慢来的，这正因为这样，ntpd平滑同步可能耗费的时间比较长。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;/ol&gt;
    
    </summary>
    
    
      <category term="Linux" scheme="http://gallonhu.github.io/categories/Linux/"/>
    
    
      <category term="NTP" scheme="http://gallonhu.github.io/tags/NTP/"/>
    
  </entry>
  
  <entry>
    <title>HA高可用集群搭建</title>
    <link href="http://gallonhu.github.io/posts/735ce64f/"/>
    <id>http://gallonhu.github.io/posts/735ce64f/</id>
    <published>2019-12-16T03:01:42.000Z</published>
    <updated>2020-01-18T14:00:13.315Z</updated>
    
    <content type="html"><![CDATA[<p>之前已经搭建好了一个集群，<a href="https://gallonhu.github.io/posts/f9bc2212">传送</a> 这次在原来的基础上做一个双<em>master</em>的高可用集群。</p><h2 id="Hadoop-HA简介及工作原理"><a href="#Hadoop-HA简介及工作原理" class="headerlink" title="Hadoop HA简介及工作原理"></a>Hadoop HA简介及工作原理</h2><p>Hadoop NameNode官方开始支持HA集群默认是从2.0开始，之前的版本均是不支持NameNode HA的高可用的。</p><h3 id="Hadoop-HA简介"><a href="#Hadoop-HA简介" class="headerlink" title="Hadoop HA简介"></a>Hadoop HA简介</h3><h4 id="Hadoop-HA集群运作机制介绍"><a href="#Hadoop-HA集群运作机制介绍" class="headerlink" title="Hadoop-HA集群运作机制介绍"></a>Hadoop-HA集群运作机制介绍</h4><ul><li>HA即高可用（7*24小时不中断服务）</li><li>实现高可用最关键的是消除单点故障</li><li>分成各个组件的HA机制——HDFS的HA、YARN的HA</li></ul><a id="more"></a><h4 id="HDFS的HA机制详解"><a href="#HDFS的HA机制详解" class="headerlink" title="HDFS的HA机制详解"></a>HDFS的HA机制详解</h4><p>通过双namenode消除单点故障，以下为双namenode协调工作的特点：</p><p>A、元数据管理方式需要改变：</p><ul><li>内存中各自保存一份元数据</li><li>Edits日志只能有一份，只有Active状态的namenode节点可以做写操作</li><li>两个namenode都可以读取edits</li><li>共享的edits放在一个共享存储中管理（qjournal和NFS两个主流实现）</li></ul><p>B、需要一个状态管理功能模块</p><ul><li>实现了一个zkfailover，常驻在每一个namenode所在的节点</li><li>每一个zkfailover负责监控自己所在namenode节点，利用zk进行状态标识</li><li>当需要进行状态切换时，由zkfailover来负责切换</li><li>切换时需要防止brain split现象的发生</li></ul><h3 id="Hadoop-HA工作原理图例"><a href="#Hadoop-HA工作原理图例" class="headerlink" title="Hadoop HA工作原理图例"></a>Hadoop HA工作原理图例</h3><h4 id="HDFS的HA架构"><a href="#HDFS的HA架构" class="headerlink" title="HDFS的HA架构"></a>HDFS的HA架构</h4><div align="center"><img src=" http://q1i38chc1.bkt.clouddn.com/bing/9d746e6e0c774166bf30f2de0e6c2c72.png" style="zoom:80%;"></div>使用 Active NameNode，Standby NameNode 两个结点解决单点问题，两个结点通过JounalNode 共享状态，采用ZKFC选举Active实时监控集群状态，自动进行故障备援。<!-- less --><ul><li>Active NameNode：接受 client 的 RPC 请求并处理，同时写自己的 Editlog 和共享存储上的 Editlog，接收 DataNode 的 Block report, block location updates 和 heartbeat；</li><li>Standby NameNode：同样会接到来自 DataNode 的 Block report, block location updates 和heartbeat，同时会从共享存储的 Editlog 上读取并执行这些 log 操作，使得自己的 NameNode 中的元数据（Namespcae information + Block locations map）都是和 Active NameNode 中的元数据是同步的。所以说 Standby 模式的 NameNode 是一个热备（Hot Standby NameNode），一旦切换成 Active 模式，马上就可以提供 NameNode 服务</li><li>JounalNode：用于Active NameNode ， Standby NameNode 同步数据，本身由一组 JounnalNode 结点组成，该组结点基数个，支持 Paxos 协议，保证高可用，是 CDH5 唯一支持的共享方式（相对于 CDH4 促在NFS共享方式）</li><li>ZKFC：监控NameNode进程，自动备援。</li></ul><h4 id="YARN的HA架构"><a href="#YARN的HA架构" class="headerlink" title="YARN的HA架构"></a>YARN的HA架构</h4><div align="center"><img src=" http://q1i38chc1.bkt.clouddn.com/bing/e515121712f648b58cc804e2de8a302c.jpg" style="zoom:80%;"></div>ResourceManager HA由一对Active，Standby结点构成，通过RMStateStore 存储内部数据和主要应用的数据及标记。<p>支持可替代的RMStateStore实现方式如下：</p><ul><li>基于内存的MemoryRMStateStore</li><li>基于文件系统的FileSystemRMStateStore</li><li>基于 zookeeper的ZKRMStateStore<br>ResourceManager HA 的架构模式同NameNode HA的架构模式基本一致，数据共享由 RMStateStore，而ZKFC成为ResourceManager进程的一个服务，非独立存在。</li></ul><h3 id="Hadoop-HA解决方案架构"><a href="#Hadoop-HA解决方案架构" class="headerlink" title="Hadoop HA解决方案架构"></a>Hadoop HA解决方案架构</h3><p>Hadoop中的HDFS、MapReduce和YARN的单点故障解决方案架构是完全一致的。</p><ul><li>手动模式：指由管理员通过命令进行主备切换，这通常在服务升级时有用。</li><li>自动模式：自动模式可降低运维成本并自动切换，但存在潜在危险，如脑裂。</li></ul><div align="center"><img src=" http://q1i38chc1.bkt.clouddn.com/bing/hadoop-ha.png" style="zoom:80%;"></div>本文将重点介绍下自动模式切换的部署方式。<blockquote><p>什么是脑裂：脑裂是Hadoop2.X版本后出现的全新问题，从字面意思我们可以理解为“大脑分裂”；我们想一下，当一个正常人，突然出现有了两个大脑，而且这两个大脑都有自己的意识，对于这个人来说肯定是灾难性问题。同理，在Hadoop中，为了防止单点失效问题而出现了两个namenode（HA机制），这两个namenode正常情况下是起到一个失效，另一个代替的作用，但在实际运行过程中很有可能出现两个namenode同时服务于整个集群的情况，这种情况称之为脑裂。</p><p>为什么会出现脑裂：脑裂通常发生在主从namenode切换时，由于ActiveNameNode的网络延迟、设备故障等问题，另一个NameNode会认为活跃的NameNode成为失效状态，此时StandbyNameNode会转换成活跃状态，此时集群中将会出现两个活跃的namenode。因此，可能出现的因素有网络延迟、心跳故障、设备故障等。</p><p>怎么解决脑裂问题：1.新增一条心跳线，防止namennode状态无法正常传达。2.使用隔离机制，通过调用活跃节点中的隔离方法，让其主动转换为standby状态，如果该方法失效则使用远程调用执行kill -9命令杀死相应进程，如果该方法仍然无法成功隔离，管理人员可以事先在每台namenode节点中编写一个shell脚本，当出现脑裂问题时，执行该脚本来切断电源，已达到隔离目的。</p></blockquote><p>其他平台HA类似</p><h2 id="HA环境准备"><a href="#HA环境准备" class="headerlink" title="HA环境准备"></a>HA环境准备</h2><h3 id="各主机IP规划"><a href="#各主机IP规划" class="headerlink" title="各主机IP规划"></a>各主机IP规划</h3><table><thead><tr><th align="left">主机名</th><th align="left">IP地址</th><th align="left">操作系统</th><th align="left">安装软件</th><th align="left">运行进程</th></tr></thead><tbody><tr><td align="left">sgmaster1</td><td align="left">192.168.1.100</td><td align="left">centos7.4</td><td align="left">jdk、hadoop、zookeeper、hbase、spark</td><td align="left">NameNode、DFSZKFailoverController(zkfc)、ResourceManager、HMaster、HRegionServer、Master</td></tr><tr><td align="left">sgmaster2</td><td align="left">192.168.1.101</td><td align="left">centos7.4</td><td align="left">jdk、hadoop、zookeeper、hbase、spark</td><td align="left">NameNode、DFSZKFailoverController(zkfc)、ResourceManager、HMaster、HRegionServer、Master</td></tr><tr><td align="left">sgslaver1</td><td align="left">192.168.1.102</td><td align="left">centos7.4</td><td align="left">jdk、hadoop、zookeeper、hbase、spark</td><td align="left">DataNode、NodeManager、JournalNode、QuorumPeerMain、Worker、HRegionServer</td></tr><tr><td align="left">sgslaver2</td><td align="left">192.168.1.103</td><td align="left">centos7.4</td><td align="left">jdk、hadoop、zookeeper、hbase、spark</td><td align="left">DataNode、NodeManager、JournalNode、QuorumPeerMain、Worker、HRegionServer</td></tr><tr><td align="left">sgslaver3</td><td align="left">192.168.1.104</td><td align="left">centos7.4</td><td align="left">jdk、hadoop、zookeeper、hbase、spark</td><td align="left">DataNode、NodeManager、JournalNode、QuorumPeerMain、Worker、HRegionServer</td></tr></tbody></table><h3 id="准备"><a href="#准备" class="headerlink" title="准备"></a>准备</h3><ul><li>添加 hosts</li><li>ssh 互信</li><li>软件包安装配置</li></ul><p>以上内容可参考另外一篇<a href="http://gallonhu.coding.me/2019/10/21/大数据平台安装/" target="_blank" rel="noopener">博文</a></p><h2 id="HA配置"><a href="#HA配置" class="headerlink" title="HA配置"></a>HA配置</h2><h3 id="Zookeeper"><a href="#Zookeeper" class="headerlink" title="Zookeeper"></a>Zookeeper</h3><h4 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h4><p><strong>zoo.cfg</strong></p><figure class="highlight shell hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">vim $ZOOKEEPER_HOME/conf/zoo.cfg</span><br><span class="line"></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> The number of ticks that can pass between</span></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> sending a request and getting an acknowledgement</span></span><br><span class="line">syncLimit=5</span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> the directory <span class="hljs-built_in">where</span> the snapshot is stored.</span></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> <span class="hljs-keyword">do</span> not use /tmp <span class="hljs-keyword">for</span> storage, /tmp here is just</span></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> example sakes.</span></span><br><span class="line">dataDir=/data/zookeeper</span><br><span class="line">dataLogDir=/data/zookeeper/logs</span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> the port at <span class="hljs-built_in">which</span> the clients will connect</span></span><br><span class="line">clientPort=2181</span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> the maximum number of client connections.</span></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> increase this <span class="hljs-keyword">if</span> you need to handle more clients</span></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash">maxClientCnxns=60</span></span><br><span class="line"><span class="hljs-meta">#</span></span><br><span class="line">admin.serverPort=8090</span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> Be sure to <span class="hljs-built_in">read</span> the maintenance section of the</span></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> administrator guide before turning on autopurge.</span></span><br><span class="line"><span class="hljs-meta">#</span></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> http://zookeeper.apache.org/doc/current/zookeeperAdmin.html<span class="hljs-comment">#sc_maintenance</span></span></span><br><span class="line"><span class="hljs-meta">#</span></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> The number of snapshots to retain <span class="hljs-keyword">in</span> dataDir</span></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash">autopurge.snapRetainCount=3</span></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> Purge task interval <span class="hljs-keyword">in</span> hours</span></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> Set to <span class="hljs-string">"0"</span> to <span class="hljs-built_in">disable</span> auto purge feature</span></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash">autopurge.purgeInterval=1</span></span><br><span class="line">server.1=sgmaster1:2888:3888</span><br><span class="line">server.2=sgmaster2:2888:3888</span><br><span class="line">server.3=sgslaver1:2888:3888</span><br><span class="line">server.4=sgslaver2:2888:3888</span><br><span class="line">server.5=sgslaver3:2888:3888</span><br></pre></td></tr></table></figure><p><strong>创建myid</strong></p><figure class="highlight shell hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> 分别对应1-5，各自执行即可。</span></span><br><span class="line">echo "1" &gt; /data/zookeeper/myid</span><br></pre></td></tr></table></figure><h4 id="启动或关闭"><a href="#启动或关闭" class="headerlink" title="启动或关闭"></a>启动或关闭</h4><figure class="highlight shell hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">zkServer.sh start</span><br><span class="line">zkServer.sh stop</span><br></pre></td></tr></table></figure><h3 id="Hadoop"><a href="#Hadoop" class="headerlink" title="Hadoop"></a>Hadoop</h3><h4 id="配置-1"><a href="#配置-1" class="headerlink" title="配置"></a>配置</h4><p><strong>core-site.xml</strong></p><figure class="highlight xml hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-tag">&lt;<span class="hljs-name">configuration</span>&gt;</span></span><br><span class="line">    <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span></span><br><span class="line">        <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>fs.defaultFS<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span></span><br><span class="line">        <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>hdfs://ns<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span></span><br><span class="line">    <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span></span><br><span class="line">    <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span></span><br><span class="line">        <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>hadoop.tmp.dir<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span></span><br><span class="line">        <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>/data/hadoop<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span></span><br><span class="line">    <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span></span><br><span class="line">    <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span></span><br><span class="line">         <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>ha.zookeeper.quorum<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span></span><br><span class="line">   <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>sgmaster1:2181,sgmaster2:2181,sgslaver1:2181,sgslaver2:2181,sgslaver3:2181<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span></span><br><span class="line">    <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span></span><br><span class="line">    <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span></span><br><span class="line">        <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>ha.zookeeper.session-timeout.ms<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span></span><br><span class="line">        <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>15000<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span></span><br><span class="line"> <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span></span><br><span class="line"><span class="hljs-tag">&lt;/<span class="hljs-name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure><p><strong>hdfs-site.xml</strong></p><figure class="highlight xml hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">        <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>shell(/bin/true)<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span></span><br><span class="line">    <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span></span><br><span class="line">    <span class="hljs-comment">&lt;!--SSH私钥 --&gt;</span></span><br><span class="line">    <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span></span><br><span class="line">        <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>dfs.ha.fencing.ssh.private-key-files<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span></span><br><span class="line">        <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>/root/.ssh/id_rsa<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span></span><br><span class="line">    <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span></span><br><span class="line">    <span class="hljs-comment">&lt;!--SSH超时时间 --&gt;</span></span><br><span class="line">    <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span></span><br><span class="line">        <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>dfs.ha.fencing.ssh.connect-timeout<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span></span><br><span class="line">        <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>30000<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span></span><br><span class="line">    <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span></span><br><span class="line">    <span class="hljs-comment">&lt;!--Journal Node文件存储地址 --&gt;</span></span><br><span class="line">    <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span></span><br><span class="line">        <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>dfs.journalnode.edits.dir<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span></span><br><span class="line">        <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>/data/hadoop/journal<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span></span><br><span class="line">    <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span></span><br><span class="line"><span class="hljs-tag">&lt;/<span class="hljs-name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure><p><strong>yarn-site.xml</strong></p><figure class="highlight xml hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">    <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span></span><br><span class="line">    <span class="hljs-comment">&lt;!-- 分别指定RM的地址 --&gt;</span></span><br><span class="line">    <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span></span><br><span class="line">        <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>yarn.resourcemanager.hostname.rm1<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span></span><br><span class="line">        <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>sgmaster1<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span></span><br><span class="line">    <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span></span><br><span class="line">    <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span></span><br><span class="line">        <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>yarn.resourcemanager.hostname.rm2<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span></span><br><span class="line">        <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>sgmaster2<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span></span><br><span class="line">    <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span></span><br><span class="line">    <span class="hljs-comment">&lt;!-- 指定zk集群地址 --&gt;</span></span><br><span class="line">    <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span></span><br><span class="line">        <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>yarn.resourcemanager.zk-address<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span></span><br><span class="line">        <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>sgmaster1:2181,sgmaster2:2181,sgslaver1:2181,sgslaver2:2181,sgslaver3:2181<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span></span><br><span class="line">    <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span></span><br><span class="line">    <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span></span><br><span class="line">        <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>yarn.nodemanager.aux-services<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span></span><br><span class="line">        <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>mapreduce_shuffle<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span></span><br><span class="line">    <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span></span><br><span class="line"><span class="hljs-tag">&lt;/<span class="hljs-name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure><p><strong>mapred-site.xml</strong></p><figure class="highlight xml hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-tag">&lt;<span class="hljs-name">configuration</span>&gt;</span></span><br><span class="line">    <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span></span><br><span class="line">        <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>mapreduce.framework.name<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span></span><br><span class="line">        <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>yarn<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span></span><br><span class="line">    <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span></span><br><span class="line"><span class="hljs-tag">&lt;/<span class="hljs-name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure><p><strong>workers</strong></p><figure class="highlight xml hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sgslaver1</span><br><span class="line">sgslaver2</span><br><span class="line">sgslaver3</span><br></pre></td></tr></table></figure><h4 id="启动及维护"><a href="#启动及维护" class="headerlink" title="启动及维护"></a>启动及维护</h4><h5 id="初始化zookeeper并启动集群"><a href="#初始化zookeeper并启动集群" class="headerlink" title="初始化zookeeper并启动集群"></a>初始化zookeeper并启动集群</h5><ul><li>启动zookeeper节点：从节点分别执行</li></ul><figure class="highlight shell hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">zkServer.sh start</span><br></pre></td></tr></table></figure><ul><li>格式化zookeeper节点：sgmaster1执行</li></ul><figure class="highlight shell hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hdfs zkfc -formatZK</span><br></pre></td></tr></table></figure><h5 id="初始化hadoop并启动集群"><a href="#初始化hadoop并启动集群" class="headerlink" title="初始化hadoop并启动集群"></a>初始化hadoop并启动集群</h5><ul><li>启动journalnode节点：从节点分别执行</li></ul><figure class="highlight shell hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hdfs --daemon start journalnode</span><br></pre></td></tr></table></figure><ul><li>格式化namenode：sgmaster1上执行</li></ul><figure class="highlight shell hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hdfs namenode -format</span><br></pre></td></tr></table></figure><ul><li>节点sgmaster1</li></ul><figure class="highlight shell hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> 验证，显示NameNode和DataNode</span></span><br><span class="line">start-dfs.sh</span><br><span class="line"></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> 验证，显示ResourceManager和NodeManager</span></span><br><span class="line">start-yarn.sh</span><br></pre></td></tr></table></figure><ul><li>节点sgmaster2</li></ul><figure class="highlight shell hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hdfs namenode -bootstrapStandby</span><br><span class="line">hadoop-daemon.sh start namenode</span><br></pre></td></tr></table></figure><blockquote><p>  此时sre01和sre02均处于standby状态。</p></blockquote><ul><li>启动zkfc服务：master上分别执行</li></ul><figure class="highlight shell hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hdfs --daemon start zkfc</span><br></pre></td></tr></table></figure><ul><li><p>健康状态检查：运行状态说明。</p><ul><li>启动zkfc服务后，sgmaster1和sgmaster2会自动选举出active节点。</li><li>此时一个节点为active状态，另一个处于standby状态。</li><li>在浏览器中打开 <a href="http://sgmaster1:50070" target="_blank" rel="noopener">NamaNode UI</a>、<a href="http://sgmaster1:8088" target="_blank" rel="noopener">Yarn UI</a>，可以产看主节点和备用主节点的状态</li></ul><div align="center"><img src=" https://cdn.jsdelivr.net/gh/GallonHu/pic@master/screenshot/Screen-Shot-2019-12-02-at-9.31.46-PM.png" style="zoom:80%;"></div></li></ul><div align="center"><img src="  https://cdn.jsdelivr.net/gh/GallonHu/pic@master/screenshot/Screen-Shot-2019-12-02-at-9.41.52-PM.png" style="zoom:80%;"></div><h4 id="HA故障自动切换测试"><a href="#HA故障自动切换测试" class="headerlink" title="HA故障自动切换测试"></a>HA故障自动切换测试</h4><h5 id="主节点—-gt-备用主节点"><a href="#主节点—-gt-备用主节点" class="headerlink" title="主节点—&gt;备用主节点"></a>主节点—&gt;备用主节点</h5><ul><li><p>kill掉主节点的namenode，查看备用主节点的namenode状态是否切换为active；</p></li><li><p>kill掉主节点的ResourceManager，查看备用主节点的ResourceManager是否切换为active；</p></li></ul><p>######备用主节点—&gt;主节点</p><p>若上述操作执行成功，那么再测试反向故障自动转移</p><ul><li>先启动被杀死的原主节点的namenode和ResourceManager</li></ul><figure class="highlight plain hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hadoop-daemon.sh start namenode </span><br><span class="line"></span><br><span class="line">yarn-daemon.sh start resourcemanager</span><br></pre></td></tr></table></figure><ul><li>再kill备用主节点的namenode和ResourceManager，查看主节点的状态，若能切换为active，那么Hadoop HA高可用集群搭建完成。</li></ul><h3 id="Hbase"><a href="#Hbase" class="headerlink" title="Hbase"></a>Hbase</h3><h4 id="配置-2"><a href="#配置-2" class="headerlink" title="配置"></a>配置</h4><p><strong>hbase-env.sh</strong></p><figure class="highlight shell hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> A string representing this instance of hbase. <span class="hljs-variable">$USER</span> by default.</span></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> <span class="hljs-built_in">export</span> HBASE_IDENT_STRING=<span class="hljs-variable">$USER</span></span></span><br><span class="line"></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> The scheduling priority <span class="hljs-keyword">for</span> daemon processes.  See <span class="hljs-string">'man nice'</span>.</span></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> <span class="hljs-built_in">export</span> HBASE_NICENESS=10</span></span><br><span class="line"></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> The directory <span class="hljs-built_in">where</span> pid files are stored. /tmp by default.</span></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> <span class="hljs-built_in">export</span> HBASE_PID_DIR=/var/hadoop/pids</span></span><br><span class="line">export HBASE_PID_DIR=/data/hbase/pids</span><br><span class="line"></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> Seconds to sleep between slave commands.  Unset by default.  This</span></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> can be useful <span class="hljs-keyword">in</span> large clusters, <span class="hljs-built_in">where</span>, e.g., slave rsyncs can</span></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> otherwise arrive faster than the master can service them.</span></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> <span class="hljs-built_in">export</span> HBASE_SLAVE_SLEEP=0.1</span></span><br><span class="line"></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> Tell HBase whether it should manage it<span class="hljs-string">'s own instance of ZooKeeper or not.</span></span></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> <span class="hljs-built_in">export</span> HBASE_MANAGES_ZK=<span class="hljs-literal">true</span></span></span><br><span class="line">export HBASE_MANAGES_ZK=false</span><br><span class="line"></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> The default <span class="hljs-built_in">log</span> rolling policy is RFA, <span class="hljs-built_in">where</span> the <span class="hljs-built_in">log</span> file is rolled as per the size defined <span class="hljs-keyword">for</span> the</span></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> RFA appender. Please refer to the log4j.properties file to see more details on this appender.</span></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> In <span class="hljs-keyword">case</span> one needs to <span class="hljs-keyword">do</span> <span class="hljs-built_in">log</span> rolling on a date change, one should <span class="hljs-built_in">set</span> the environment property</span></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> HBASE_ROOT_LOGGER to <span class="hljs-string">"&lt;DESIRED_LOG LEVEL&gt;,DRFA"</span>.</span></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> For example:</span></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> HBASE_ROOT_LOGGER=INFO,DRFA</span></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> The reason <span class="hljs-keyword">for</span> changing default to RFA is to avoid the boundary <span class="hljs-keyword">case</span> of filling out disk space as</span></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> DRFA doesn<span class="hljs-string">'t put any cap on the log size. Please refer to HBase-5655 for more context.</span></span></span><br><span class="line"></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> Tell HBase whether it should include Hadoop<span class="hljs-string">'s lib when start up,</span></span></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> the default value is <span class="hljs-literal">false</span>,means that includes Hadoop<span class="hljs-string">'s lib.</span></span></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> <span class="hljs-built_in">export</span> HBASE_DISABLE_HADOOP_CLASSPATH_LOOKUP=<span class="hljs-string">"true"</span></span></span><br></pre></td></tr></table></figure><p><strong>hbase-site.xml</strong></p><figure class="highlight xml hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">  <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span></span><br><span class="line">    <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>hbase.master.info.port<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span></span><br><span class="line">    <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>16010<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span></span><br><span class="line">  <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span></span><br><span class="line">  <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span></span><br><span class="line">    <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>hbase.regionserver.info.port<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span></span><br><span class="line">    <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>16030<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span></span><br><span class="line">  <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span></span><br><span class="line">  <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span></span><br><span class="line">    <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>hbase.unsafe.stream.capability.enforce<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span></span><br><span class="line">    <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>false<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span></span><br><span class="line">    <span class="hljs-tag">&lt;<span class="hljs-name">description</span>&gt;</span>完全分布式式必须为false<span class="hljs-tag">&lt;/<span class="hljs-name">description</span>&gt;</span></span><br><span class="line">  <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span></span><br><span class="line"><span class="hljs-tag">&lt;/<span class="hljs-name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure><p><strong>regionservers</strong></p><figure class="highlight shell hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">sgmaster1</span><br><span class="line">sgmaster2</span><br><span class="line">sgslaver1</span><br><span class="line">sgslaver2</span><br><span class="line">sgslaver3</span><br></pre></td></tr></table></figure><h4 id="创建pid文件保存目录"><a href="#创建pid文件保存目录" class="headerlink" title="创建pid文件保存目录"></a>创建pid文件保存目录</h4><figure class="highlight shell hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mkdir -p /data/hbase/pids</span><br></pre></td></tr></table></figure><h4 id="启动"><a href="#启动" class="headerlink" title="启动"></a>启动</h4><ul><li>在主节点上启动HBase</li></ul><p><strong>这里的主节点是指NameNode状态为active的节点</strong></p><figure class="highlight shell hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> 查看HMaster、Regionserver进程是否启动</span></span><br><span class="line">start-hbase.sh</span><br></pre></td></tr></table></figure><ul><li>在备用主节点启动HMaster进程</li></ul><figure class="highlight shell hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hbase-daemon.sh start master</span><br></pre></td></tr></table></figure><h4 id="HA高可用测试"><a href="#HA高可用测试" class="headerlink" title="HA高可用测试"></a>HA高可用测试</h4><p>在浏览器中打开 <a href="http://sgmaster1:16010" target="_blank" rel="noopener">Web UI</a>，可以查看主节点和备用主节点的状态</p><div align="center"><img src=" https://cdn.jsdelivr.net/gh/GallonHu/pic@master/screenshot/Screen-Shot-2019-12-02-at-9.56.01-PM.png" style="zoom:80%;"></div><h5 id="主节点—-gt-备用主节点-1"><a href="#主节点—-gt-备用主节点-1" class="headerlink" title="主节点—&gt;备用主节点"></a>主节点—&gt;备用主节点</h5><blockquote><p>  这里的主节点指使用start-hbase.sh命令启动HBase集群的机器</p></blockquote><p>kill掉主节点的HMaster进程，在浏览器中查看备用主节点的HBase是否切换为active；</p><p>若上述操作成功，则在主节点启动被杀死的HMaster进程：</p><figure class="highlight plain hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hbase-daemon.sh start master</span><br></pre></td></tr></table></figure><p>然后，kill掉备用主节点的HMaster进程，在浏览器中查看主节点的HBase是否切换为active，若操作成功，则HBase高可用集群搭建完成；</p><h3 id="Spark"><a href="#Spark" class="headerlink" title="Spark"></a>Spark</h3><h4 id="配置-3"><a href="#配置-3" class="headerlink" title="配置"></a>配置</h4><p><strong>spark-env.sh</strong></p><figure class="highlight shell hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> - SPARK_SHUFFLE_OPTS, to <span class="hljs-built_in">set</span> config properties only <span class="hljs-keyword">for</span> the external shuffle service (e.g. <span class="hljs-string">"-Dx=y"</span>)</span></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> - SPARK_DAEMON_JAVA_OPTS, to <span class="hljs-built_in">set</span> config properties <span class="hljs-keyword">for</span> all daemons (e.g. <span class="hljs-string">"-Dx=y"</span>)</span></span><br><span class="line">export SPARK_DAEMON_JAVA_OPTS="-Dspark.deploy.recoveryMode=ZOOKEEPER -Dspark.deploy.zookeeper.url=sgmaster1:2181,sgmaster2:2181,sgslaver1:2181,sgslaver2:2181,sgslaver3:2181 -Dspark.deploy.zookeeper.dir=/spark"</span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> - SPARK_DAEMON_CLASSPATH, to <span class="hljs-built_in">set</span> the classpath <span class="hljs-keyword">for</span> all daemons</span></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> - SPARK_PUBLIC_DNS, to <span class="hljs-built_in">set</span> the public dns name of the master or workers</span></span><br><span class="line"></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> Generic options <span class="hljs-keyword">for</span> the daemons used <span class="hljs-keyword">in</span> the standalone deploy mode</span></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> - SPARK_CONF_DIR      Alternate conf dir. (Default: <span class="hljs-variable">$&#123;SPARK_HOME&#125;</span>/conf)</span></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> - SPARK_LOG_DIR       Where <span class="hljs-built_in">log</span> files are stored.  (Default: <span class="hljs-variable">$&#123;SPARK_HOME&#125;</span>/logs)</span></span><br><span class="line">SPARK_LOG_DIR=/data/spark/logs</span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> - SPARK_PID_DIR       Where the pid file is stored. (Default: /tmp)</span></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> - SPARK_IDENT_STRING  A string representing this instance of spark. (Default: <span class="hljs-variable">$USER</span>)</span></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> - SPARK_NICENESS      The scheduling priority <span class="hljs-keyword">for</span> daemons. (Default: 0)</span></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> - SPARK_NO_DAEMONIZE  Run the proposed <span class="hljs-built_in">command</span> <span class="hljs-keyword">in</span> the foreground. It will not output a PID file.</span></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> Options <span class="hljs-keyword">for</span> native BLAS, like Intel MKL, OpenBLAS, and so on.</span></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> You might get better performance to <span class="hljs-built_in">enable</span> these options <span class="hljs-keyword">if</span> using native BLAS (see SPARK-21305).</span></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> - MKL_NUM_THREADS=1        Disable multi-threading of Intel MKL</span></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> - OPENBLAS_NUM_THREADS=1   Disable multi-threading of OpenBLAS</span></span><br><span class="line"></span><br><span class="line">export JAVA_HOME=/opt/java/jdk1.8.0_221</span><br><span class="line">export SCALA_HOME=/opt/scala/scala-2.12.10</span><br><span class="line">export HADOOP_HOME=/opt/hadoop/hadoop-3.1.2</span><br><span class="line">export HADOOP_CONF_DIR=$HADOOP_HOME/etc/hadoop</span><br><span class="line">export PYSPARK_PYTHON=/usr/local/bin/python3</span><br><span class="line">export PYSPARK_DRIVER_PYTHON=/usr/local/bin/ipython</span><br></pre></td></tr></table></figure><h4 id="启动-1"><a href="#启动-1" class="headerlink" title="启动"></a>启动</h4><h5 id="在主节点启动master进程"><a href="#在主节点启动master进程" class="headerlink" title="在主节点启动master进程"></a>在主节点启动master进程</h5><figure class="highlight shell hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">start-master.sh</span><br></pre></td></tr></table></figure><h5 id="在备用主节点启动master进程"><a href="#在备用主节点启动master进程" class="headerlink" title="在备用主节点启动master进程"></a>在备用主节点启动master进程</h5><figure class="highlight shell hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">start-master.sh</span><br></pre></td></tr></table></figure><h5 id="web"><a href="#web" class="headerlink" title="web"></a>web</h5><p>浏览器访问 <a href="http://sgmaster1:8001" target="_blank" rel="noopener">Web UI</a></p><div align="center"><img src=" https://cdn.jsdelivr.net/gh/GallonHu/pic@master/screenshot/Screen-Shot-2019-12-02-at-10.13.18-PM.png" style="zoom:80%;"></div><h5 id="启动全部worker节点"><a href="#启动全部worker节点" class="headerlink" title="启动全部worker节点"></a>启动全部worker节点</h5><p>在ALIVE MASTER节点</p><figure class="highlight shell hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">start-slaves.sh</span><br></pre></td></tr></table></figure><p><a style="background-color:black;color:white;text-decoration:none;padding:4px 6px;font-family:-apple-system, BlinkMacSystemFont, &quot;San Francisco&quot;, &quot;Helvetica Neue&quot;, Helvetica, Ubuntu, Roboto, Noto, &quot;Segoe UI&quot;, Arial, sans-serif;font-size:12px;font-weight:bold;line-height:1.2;display:inline-block;border-radius:3px" href="https://unsplash.com/@austinfruits?utm_medium=referral&amp;utm_campaign=photographer-credit&amp;utm_content=creditBadge" target="_blank" rel="noopener noreferrer" title="Download free do whatever you want high-resolution photos from Austin Fruits"><span style="display:inline-block;padding:2px 3px"><svg xmlns="http://www.w3.org/2000/svg" style="height:12px;width:auto;position:relative;vertical-align:middle;top:-2px;fill:white" viewbox="0 0 32 32"><title>unsplash-logo</title><path d="M10 9V0h12v9H10zm12 5h10v18H0V14h10v9h12v-9z"/></svg></span><span style="display:inline-block;padding:2px 3px">Austin Fruits</span></a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;之前已经搭建好了一个集群，&lt;a href=&quot;https://gallonhu.github.io/posts/f9bc2212&quot;&gt;传送&lt;/a&gt; 这次在原来的基础上做一个双&lt;em&gt;master&lt;/em&gt;的高可用集群。&lt;/p&gt;
&lt;h2 id=&quot;Hadoop-HA简介及工作原理&quot;&gt;&lt;a href=&quot;#Hadoop-HA简介及工作原理&quot; class=&quot;headerlink&quot; title=&quot;Hadoop HA简介及工作原理&quot;&gt;&lt;/a&gt;Hadoop HA简介及工作原理&lt;/h2&gt;&lt;p&gt;Hadoop NameNode官方开始支持HA集群默认是从2.0开始，之前的版本均是不支持NameNode HA的高可用的。&lt;/p&gt;
&lt;h3 id=&quot;Hadoop-HA简介&quot;&gt;&lt;a href=&quot;#Hadoop-HA简介&quot; class=&quot;headerlink&quot; title=&quot;Hadoop HA简介&quot;&gt;&lt;/a&gt;Hadoop HA简介&lt;/h3&gt;&lt;h4 id=&quot;Hadoop-HA集群运作机制介绍&quot;&gt;&lt;a href=&quot;#Hadoop-HA集群运作机制介绍&quot; class=&quot;headerlink&quot; title=&quot;Hadoop-HA集群运作机制介绍&quot;&gt;&lt;/a&gt;Hadoop-HA集群运作机制介绍&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;HA即高可用（7*24小时不中断服务）&lt;/li&gt;
&lt;li&gt;实现高可用最关键的是消除单点故障&lt;/li&gt;
&lt;li&gt;分成各个组件的HA机制——HDFS的HA、YARN的HA&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
    
      <category term="Bigdata" scheme="http://gallonhu.github.io/categories/Bigdata/"/>
    
    
      <category term="Install" scheme="http://gallonhu.github.io/tags/Install/"/>
    
  </entry>
  
  <entry>
    <title>大数据平台安装</title>
    <link href="http://gallonhu.github.io/posts/f9bc2212/"/>
    <id>http://gallonhu.github.io/posts/f9bc2212/</id>
    <published>2019-12-16T03:00:04.000Z</published>
    <updated>2019-12-16T03:23:30.926Z</updated>
    
    <content type="html"><![CDATA[<p>本文主要记录了 hadoop 大数据集群的相关组件安装及记录过程</p><a id="more"></a><h2 id="基本设置"><a href="#基本设置" class="headerlink" title="基本设置"></a>基本设置</h2><table><thead><tr><th>节点</th><th>IP</th></tr></thead><tbody><tr><td>master</td><td>192.168.0.100</td></tr><tr><td>slave1</td><td>192.168.0.101</td></tr><tr><td>slave2</td><td>192.168.0.102</td></tr><tr><td>slave3</td><td>192.168.0.103</td></tr></tbody></table><table><thead><tr><th>组件</th><th>版本</th><th>安装位置</th><th>logs 位置</th></tr></thead><tbody><tr><td>java</td><td>1.8</td><td>/opt/java/jdk1.8.0_221</td><td></td></tr><tr><td>hadoop</td><td>3.1.2</td><td>/opt/hadoop/hadoop-3.1.2</td><td>/data/hadoop/logs</td></tr><tr><td>hive</td><td>3.1.2</td><td>/opt/hive/apache-hive-3.1.2-bin</td><td>/data/hive/logs</td></tr><tr><td>zookeeper</td><td>3.5.6</td><td>/opt/zookeeper/apache-zookeeper-3.5.6-bin</td><td>/data/zookeeper/logs</td></tr><tr><td>kafka</td><td>2.12</td><td>/opt/kafka/kafka_2.12-2.3.0</td><td>/data/kafka/logs</td></tr><tr><td>flume</td><td>1.9.0</td><td>/opt/flume/apache-flume-1.9.0-bin</td><td>/data/flum/logs</td></tr><tr><td>hbase</td><td>2.2.1</td><td>/opt/hbase/hbase-2.2.1</td><td>/data/hbase/logs</td></tr><tr><td>spark</td><td>2.4.4</td><td>/opt/spark/spark-2.4.4-bin-hadoop2.7</td><td>/data/spark/logs</td></tr></tbody></table><!-- less --><h2 id="ssh-互信"><a href="#ssh-互信" class="headerlink" title="ssh 互信"></a>ssh 互信</h2><h3 id="节点配置"><a href="#节点配置" class="headerlink" title="节点配置"></a>节点配置</h3><figure class="highlight shell hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> 主节点的配置, 其他节点上配置类似</span></span><br><span class="line"></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> 修改主机名, 退出重新登录即可</span></span><br><span class="line">hostnamectl set-hostname master; </span><br><span class="line">exit;</span><br><span class="line"></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> 添加各节点映射</span></span><br><span class="line">vi /etc/hosts</span><br><span class="line">192.168.0.100 master</span><br><span class="line">192.168.0.101 slave1</span><br><span class="line">192.168.0.102 slave2</span><br><span class="line">192.168.0.103 slave3</span><br></pre></td></tr></table></figure><h3 id="脚本"><a href="#脚本" class="headerlink" title="脚本"></a>脚本</h3><p><strong>在主节点安装两个脚本到 /usr/local/bin 目录下</strong></p><p>脚本一: 集群间同步拷贝文件</p><p>cluster_copy_all_nodes</p><figure class="highlight shell hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash">!/bin/bash</span></span><br><span class="line">SELF=`hostname`</span><br><span class="line">if [ -z "$NODE_LIST" ]; then</span><br><span class="line">  echo</span><br><span class="line">  echo Error: NODE_LIST environment variable must be set in .bash_profile</span><br><span class="line">  exit 1</span><br><span class="line">fi</span><br><span class="line">for i in $NODE_LIST; do</span><br><span class="line">  if [ ! $i = $SELF ]; then</span><br><span class="line">    if [ $1 = "-r" ]; then</span><br><span class="line">      scp -oStrictHostKeyChecking=no -r $2 $i:$3</span><br><span class="line">    else</span><br><span class="line">      scp -oStrictHostKeyChecking=no $1 $i:$2</span><br><span class="line">    fi</span><br><span class="line">  fi</span><br><span class="line">done</span><br><span class="line">wait</span><br></pre></td></tr></table></figure><p>脚本二: 用来集群间同步运行命令</p><p>cluster_run_all_nodes</p><figure class="highlight shell hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash">!/bin/bash</span></span><br><span class="line">if [ -z "$NODE_LIST" ]; then</span><br><span class="line">  echo</span><br><span class="line">  echo Error: NODE_LIST environment variable must be set in .bash_profile</span><br><span class="line">  exit 1</span><br><span class="line">fi</span><br><span class="line">if [[ $1 = '--background' ]]; then</span><br><span class="line">  shift</span><br><span class="line">  for i in $NODE_LIST; do</span><br><span class="line">    ssh -oStrictHostKeyChecking=no -n $i "$@" &amp;</span><br><span class="line">  done</span><br><span class="line">else</span><br><span class="line">  for i in $NODE_LIST; do</span><br><span class="line">    ssh -oStrictHostKeyChecking=no $i "$@"</span><br><span class="line">  done</span><br><span class="line">fi</span><br><span class="line">wait</span><br></pre></td></tr></table></figure><p>授予两个脚本的可执行权限</p><figure class="highlight shell hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">chmod +x /usr/local/bin/cluster_*</span><br></pre></td></tr></table></figure><h3 id="配置环境变量"><a href="#配置环境变量" class="headerlink" title="配置环境变量"></a>配置环境变量</h3><p>配置主节点环境变量</p><figure class="highlight shell hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">vi ~/.bash_profile</span><br><span class="line">export NODE_LIST='master slave1 slave2 slave3'</span><br><span class="line"></span><br><span class="line">source ~/.bash_profile</span><br></pre></td></tr></table></figure><h3 id="配置集群ssh互信"><a href="#配置集群ssh互信" class="headerlink" title="配置集群ssh互信"></a>配置集群ssh互信</h3><p><strong>1. 各节点生成密钥和公钥</strong></p><figure class="highlight shell hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cluster_run_all_nodes "hostname; ssh-keygen -q -t rsa  -N \"\" -f  ~/.ssh/id_rsa"</span><br></pre></td></tr></table></figure><p>如果配置有误，或者清除ssh互信的当前所有配置信息</p><figure class="highlight shell hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cluster_run_all_nodes "hostname ; rm -rf ~/.ssh"</span><br><span class="line">rm -rf ~/.ssh</span><br></pre></td></tr></table></figure><p><strong>2. 将所有的公钥文件汇总到一个总的授权key文件中</strong></p><p>在主节点上汇总, 直接 shell 执行</p><figure class="highlight shell hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">IP_NET="192.168.0." </span><br><span class="line">for((i=100;i&lt;=103;i++))</span><br><span class="line">do</span><br><span class="line">ssh $IP_NET$i cat ~/.ssh/id_rsa.pub &gt;&gt; ~/.ssh/authorized_keys</span><br><span class="line">echo Summarize ssh info from $IP_NET$i into a single file.</span><br><span class="line">done</span><br></pre></td></tr></table></figure><p>出于安全性考虑，将这个授权key文件赋予600权限</p><figure class="highlight shell hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">chmod 600 ~/.ssh/authorized_keys</span><br></pre></td></tr></table></figure><p><strong>3. 将这个包含了所有互信机器认证key的认证文件，分发到各个机器中去</strong></p><figure class="highlight shell hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cluster_copy_all_nodes ~/.ssh/authorized_keys ~/.ssh/</span><br></pre></td></tr></table></figure><p><strong>4.  验证ssh互信</strong></p><p>master 上运行，都不输入密码返回主机名和时间即可</p><figure class="highlight shell hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cluster_run_all_nodes "hostname;date"</span><br></pre></td></tr></table></figure><h3 id="结尾"><a href="#结尾" class="headerlink" title="结尾"></a>结尾</h3><p>至此，ssh集群间的互信已经配置完成。<br>但为了更加灵活的再其他节点也可以用到我们自定义的脚本，我们还可以做以下工作</p><p>同步拷贝 master 的配置文件到其他节点</p><figure class="highlight shell hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">cluster_copy_all_nodes ~/.bash_profile ~/</span><br><span class="line">cluster_copy_all_nodes /etc/hosts /etc</span><br><span class="line">cluster_copy_all_nodes /usr/local/bin/cluster_copy_all_nodes /usr/local/bin/</span><br><span class="line">cluster_copy_all_nodes /usr/local/bin/cluster_run_all_nodes /usr/local/bin/</span><br></pre></td></tr></table></figure><p>这时任意登录其他节点，也可以使用cluster_run_all_nodes验证ssh互信了</p><figure class="highlight shell hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cluster_run_all_nodes "hostname;date"</span><br></pre></td></tr></table></figure><h2 id="Hadoop"><a href="#Hadoop" class="headerlink" title="Hadoop"></a>Hadoop</h2><h3 id="关闭防火墙"><a href="#关闭防火墙" class="headerlink" title="关闭防火墙"></a>关闭防火墙</h3><figure class="highlight shell hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> 关闭 SELINUX</span></span><br><span class="line">vi /etc/selinux/config</span><br><span class="line">SELINUX=disabled</span><br><span class="line"></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> 关闭防火墙</span></span><br><span class="line">systemctl stop firewalld</span><br><span class="line">systemctl disable firewalld</span><br></pre></td></tr></table></figure><h3 id="Java-安装配置"><a href="#Java-安装配置" class="headerlink" title="Java 安装配置"></a>Java 安装配置</h3><figure class="highlight shell hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> 之后我们所有的环境配置包都放到/opt/下</span></span><br><span class="line"></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> 新建java目录，把下载好的jdk的二进制包拷到下面</span></span><br><span class="line">mkdir -p /opt/java</span><br><span class="line">tar -zxvf jdk-8u221-linux-x64.tar.gz -C /opt/java/</span><br><span class="line"></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> 配置环境变量，在profile文件最后添加java的环境变量</span></span><br><span class="line">vim /etc/profile</span><br><span class="line">export JAVA_HOME=/opt/java/jdk1.8.0_221</span><br><span class="line">export PATH=$PATH:$JAVA_HOME/bin</span><br><span class="line"></span><br><span class="line">source /etc/profile</span><br><span class="line">java -version</span><br><span class="line"></span><br><span class="line">java version "1.8.0_221"</span><br><span class="line">Java(TM) SE Runtime Environment (build 1.8.0_221-b11)</span><br><span class="line">Java HotSpot(TM) 64-Bit Server VM (build 25.221-b11, mixed mode)</span><br></pre></td></tr></table></figure><h3 id="主节点"><a href="#主节点" class="headerlink" title="主节点"></a>主节点</h3><p><strong>1. 下载解压</strong></p><figure class="highlight shell hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> 在/opt 下创建hadoop文件夹，将下载好的 hadoop 压缩包上传进去解压</span></span><br><span class="line">mkdir -p /opt/hadoop</span><br><span class="line">tar -zxvf hadoop-3.2.1.tar.gz -C /opt/hadoop</span><br></pre></td></tr></table></figure><p><strong>2. 配置环境变量</strong></p><figure class="highlight shell hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">vi /etc/profile</span><br><span class="line"></span><br><span class="line">export HADOOP_HOME=/opt/hadoop/hadoop-3.2.1</span><br><span class="line">export HADOOP_INSTALL=$HADOOP_HOME</span><br><span class="line">export HADOOP_MAPRED_HOME=$HADOOP_HOME</span><br><span class="line">export HADOOP_HDFS_HOME=$HADOOP_HOME</span><br><span class="line">export HADOOP_COMMON_HOME=$HADOOP_HOME</span><br><span class="line">export HADOOP_CONF_DIR=$HADOOP_HOME/etc/hadoop</span><br><span class="line"></span><br><span class="line">export YARN_HOME=$HADOOP_HOME</span><br><span class="line">export YARN_CONF_DIR=$HADOOP_HOME/etc/hadoop</span><br><span class="line"></span><br><span class="line">export PATH=$PATH:$HADOOP_HOME/sbin:$HADOOP_HOME/bin</span><br></pre></td></tr></table></figure><p><strong>3. 配置 NAMENODE</strong></p><figure class="highlight shell hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> 配置文件主要在 HADOOP_CONF_DIR 下面</span></span><br><span class="line"></span><br><span class="line">vi $HADOOP_CONF_DIR/core-site.xml</span><br><span class="line"></span><br><span class="line">&lt;configuration&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;fs.defaultFS&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;hdfs://master:9000&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;hadoop.tmp.dir&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;/data/hadoop&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br><span class="line"></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> fs.defaultFS指定了hdfs的默认路径；hadoop.tmp.dir指定了hadoop文件存放路径的根目录, 需手动创建</span></span><br></pre></td></tr></table></figure><p><strong>4. 配置HDFS</strong></p><figure class="highlight shell hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">vi $HADOOP_CONF_DIR/hdfs-site.xml</span><br><span class="line"></span><br><span class="line">&lt;configuration&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">    &lt;name&gt;dfs.replication&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;2&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;dfs.namenode.secondary.http-address&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;master:50090&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;dfs.namenode.secondary.https-address&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;master:50091&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br><span class="line"></span><br><span class="line">可以不用设置dfs.namenode.name.dir和dfs.datanode.data.dir，因为它们的值/data/hadoop会继承自core-site.xml中的hadoop.tmp.dir。</span><br><span class="line">dfs.replication设置副本数量，因为3节点中只有2个DataNode，因此此处为2，默认是3。</span><br></pre></td></tr></table></figure><p><strong>5. 配置 MapReduce</strong></p><figure class="highlight shell hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">vi $HADOOP_CONF_DIR/mapred-site.xml</span><br><span class="line"></span><br><span class="line">&lt;configuration&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;mapreduce.framework.name&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;yarn&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br><span class="line"></span><br><span class="line">YARN是一个通用的资源协调器，不仅可以为MapReduce服务，也可以为Spark、Tez等应用服务。</span><br></pre></td></tr></table></figure><p><strong>6. 配置 YARN</strong></p><figure class="highlight shell hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">vi $HADOOP_CONF_DIR/yarn-site.xml</span><br><span class="line"></span><br><span class="line">&lt;configuration&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;mapreduce_shuffle&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;master&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure><p><strong>7. 配置 workers</strong></p><figure class="highlight shell hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> 我们使用 master 来作为 NameNode, slave1 slave2 slave3 作为 DataNode。workers默认只有一行内容: localhost，使用 vi 编辑 slaves，并写入下面内容：</span></span><br><span class="line">vi $HADOOP_CONF_DIR/workers</span><br><span class="line"></span><br><span class="line">slave1</span><br><span class="line">slave2</span><br><span class="line">slave3</span><br></pre></td></tr></table></figure><p><strong>8. 配置 hadoop-env.sh</strong></p><figure class="highlight shell hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">vi $HADOOP_CONF_DIR/hadoop-env.sh</span><br><span class="line"></span><br><span class="line">export HADOOP_LOG_DIR=/data/hadoop/logs</span><br><span class="line">export JAVA_HOME=/opt/java/jdk1.8.0_221</span><br></pre></td></tr></table></figure><h3 id="子节点"><a href="#子节点" class="headerlink" title="子节点"></a>子节点</h3><p><strong>1. 创建 数据存储目录</strong></p><figure class="highlight shell hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cluster_run_all_nodes "hostname; mkdir -p /data/hadoop"</span><br></pre></td></tr></table></figure><p><strong>2. 将 java 复制到子节点</strong></p><figure class="highlight shell hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cluster_copy_all_nodes /opt/hadoop /opt</span><br></pre></td></tr></table></figure><p><strong>3. 将 hadoop 复制到子节点</strong></p><figure class="highlight shell hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> hadoop 目录下 share/doc 为文档并且比较大, 先删除, 再复制到其他节点</span></span><br><span class="line">rm -rf /opt/hadoop/hadoop-3.2.1/share/doc/</span><br><span class="line"></span><br><span class="line">cluster_copy_all_nodes -r /opt/hadoop/ /opt</span><br></pre></td></tr></table></figure><p><strong>4. 复制配置文件到子节点</strong></p><figure class="highlight shell hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cluster_copy_all_nodes /etc/profile /etc/</span><br></pre></td></tr></table></figure><p><strong>5. 刷新环境</strong></p><figure class="highlight shell hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cluster_run_all_nodes "hostname; source /etc/profile"</span><br></pre></td></tr></table></figure><p><strong>6. 修改 shell 脚本</strong>（option）</p><p>使用 root 用户安装的 hadoop, 需要修改 /sbin/ 中以下文件</p><figure class="highlight shell hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> 对于 start-dfs.sh 和 stop-dfs.sh 文件，添加下列参数</span></span><br><span class="line"></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash">!/usr/bin/env bash</span></span><br><span class="line">HDFS_DATANODE_USER=root</span><br><span class="line">HADOOP_SECURE_DN_USER=hdfsclu</span><br><span class="line">HDFS_NAMENODE_USER=root</span><br><span class="line">HDFS_SECONDARYNAMENODE_USER=root</span><br><span class="line"></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> 对于start-yarn.sh和stop-yarn.sh文件，添加下列参数</span></span><br><span class="line"></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash">!/usr/bin/env bash</span></span><br><span class="line">YARN_RESOURCEMANAGER_USER=root</span><br><span class="line">HADOOP_SECURE_DN_USER=yarn</span><br><span class="line">YARN_NODEMANAGER_USER=root</span><br></pre></td></tr></table></figure><h3 id="测试是否配置成功"><a href="#测试是否配置成功" class="headerlink" title="测试是否配置成功"></a>测试是否配置成功</h3><figure class="highlight shell hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> 只要在主节点上启动，执行过程可能稍慢，耐心等待</span></span><br><span class="line"></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> 格式化 namenode</span></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> 这个命令非常危险！你应当只在新建集群后执行一次，因为 namenode 保存的是 HDFS 的所有元信息，如果丢失了，整个集群中 DataNode 的数据都无法访问，就算它们还在磁盘上</span></span><br><span class="line">hdfs namenode -format</span><br><span class="line"></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> 启动 hadoop</span></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> hadoop 所有启动文件脚本都在 /sbin 下</span></span><br><span class="line">cd $HADOOP_HOME/sbin</span><br><span class="line">./start-all.sh</span><br><span class="line"></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> 主节点输入 jps</span></span><br><span class="line">6517 Jps</span><br><span class="line">5832 NameNode</span><br><span class="line">5289 ResourceManager</span><br><span class="line">6106 SecondaryNameNode</span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> 从节点输入 jps</span></span><br><span class="line">2931 NodeManager</span><br><span class="line">3068 Jps</span><br><span class="line">2815 DataNode</span><br><span class="line"></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> 至此, hadoop 搭建完成</span></span><br></pre></td></tr></table></figure><h3 id="web-ui"><a href="#web-ui" class="headerlink" title="web ui"></a>web ui</h3><p>namenode 在 hadoop3.0 以后默认端口为 9870 不是 50070</p><p><a href="http://master:9870" target="_blank" rel="noopener">namenode</a></p><p><a href="http://master:8088" target="_blank" rel="noopener">ResourceManager</a></p><h2 id="Hive"><a href="#Hive" class="headerlink" title="Hive"></a>Hive</h2><h3 id="环境配置"><a href="#环境配置" class="headerlink" title="环境配置"></a>环境配置</h3><figure class="highlight shell hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> 注意：Hive只需要在master节点上安装配置</span></span><br><span class="line"></span><br><span class="line">mkdir -p /opt/hive</span><br><span class="line">tar -zxvf apache-hive-3.1.2-bin.tar.gz -C /opt/hive</span><br><span class="line"></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> 添加环境变量</span></span><br><span class="line">vi /etc/profile</span><br><span class="line"></span><br><span class="line">export HIVE_HOME=/opt/hive/apache-hive-3.1.2-bin</span><br><span class="line">export PATH=$PATH:$HIVE_HOME/bin</span><br><span class="line"></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> 刷新环境变量</span></span><br><span class="line">source /etc/profile</span><br></pre></td></tr></table></figure><h3 id="修改-hive-site-xml"><a href="#修改-hive-site-xml" class="headerlink" title="修改 hive-site.xml"></a>修改 hive-site.xml</h3><figure class="highlight shell hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br></pre></td><td class="code"><pre><span class="line">vi $HIVE_HOME/conf/hive-site.xml</span><br><span class="line"></span><br><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;javax.jdo.option.ConnectionURL&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;jdbc:mysql://master:3306/hive?createDatabaseIfNotExist=true&lt;/value&gt;</span><br><span class="line">    &lt;description&gt;</span><br><span class="line">      JDBC connect string for a JDBC metastore.</span><br><span class="line">      To use SSL to encrypt/authenticate the connection, provide database-specific SSL flag in the connection URL.</span><br><span class="line">      For example, jdbc:postgresql://myhost/db?ssl=true for postgres database.</span><br><span class="line">    &lt;/description&gt;</span><br><span class="line"> &lt;/property&gt;</span><br><span class="line"> </span><br><span class="line"> &lt;property&gt;</span><br><span class="line">    &lt;name&gt;javax.jdo.option.ConnectionDriverName&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;com.mysql.jdbc.Driver&lt;/value&gt;</span><br><span class="line">    &lt;description&gt;Driver class name for a JDBC metastore&lt;/description&gt;</span><br><span class="line"> &lt;/property&gt;</span><br><span class="line">  </span><br><span class="line"> &lt;property&gt;</span><br><span class="line">    &lt;name&gt;javax.jdo.option.ConnectionUserName&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;root&lt;/value&gt;</span><br><span class="line">    &lt;description&gt;Username to use against metastore database&lt;/description&gt;</span><br><span class="line"> &lt;/property&gt;</span><br><span class="line">    </span><br><span class="line"> &lt;property&gt;</span><br><span class="line">    &lt;name&gt;javax.jdo.option.ConnectionPassword&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;123456&lt;/value&gt;</span><br><span class="line">    &lt;description&gt;password to use against metastore database&lt;/description&gt;</span><br><span class="line"> &lt;/property&gt;</span><br><span class="line"></span><br><span class="line"> &lt;property&gt;</span><br><span class="line">    &lt;name&gt;hive.querylog.location&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;/opt/hive/apache-hive-3.1.2-bin/tmp/hadoop&lt;/value&gt;</span><br><span class="line">    &lt;description&gt;Location of Hive run time structured log file&lt;/description&gt;</span><br><span class="line">  &lt;/property&gt;</span><br><span class="line"> </span><br><span class="line">  &lt;property&gt;</span><br><span class="line">    &lt;name&gt;hive.server2.logging.operation.log.location&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;/opt/hive/apache-hive-3.1.2-bin/tmp/hadoop/operation_logs&lt;/value&gt;</span><br><span class="line">    &lt;description&gt;Top level directory where operation logs are stored if logging functionality is enabled&lt;/description&gt;</span><br><span class="line">  &lt;/property&gt;</span><br><span class="line">  </span><br><span class="line">  &lt;property&gt;</span><br><span class="line">    &lt;name&gt;hive.exec.local.scratchdir&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;/opt/hive/apache-hive-3.1.2-bin/tmp/hadoop&lt;/value&gt;</span><br><span class="line">    &lt;description&gt;Local scratch space for Hive jobs&lt;/description&gt;</span><br><span class="line">  &lt;/property&gt;</span><br><span class="line">  </span><br><span class="line">  &lt;property&gt;</span><br><span class="line">    &lt;name&gt;hive.downloaded.resources.dir&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;/opt/hive/apache-hive-3.1.2-bin/tmp/$&#123;hive.session.id&#125;_resources&lt;/value&gt;</span><br><span class="line">    &lt;description&gt;Temporary local directory for added resources in the remote file system.&lt;/description&gt;</span><br><span class="line">  &lt;/property&gt;</span><br><span class="line">  </span><br><span class="line">  &lt;property&gt;</span><br><span class="line">    &lt;name&gt;hive.metastore.schema.verification&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;false&lt;/value&gt;</span><br><span class="line">    &lt;description&gt;</span><br><span class="line">      Enforce metastore schema version consistency.</span><br><span class="line">      True: Verify that version information stored in is compatible with one from Hive jars.  Also disable automatic</span><br><span class="line">            schema migration attempt. Users are required to manually migrate schema after Hive upgrade which ensures</span><br><span class="line">            proper metastore schema migration. (Default)</span><br><span class="line">      False: Warn if the version information stored in metastore doesn't match with one from in Hive jars.</span><br><span class="line">    &lt;/description&gt;</span><br><span class="line">  &lt;/property&gt;</span><br></pre></td></tr></table></figure><h3 id="修改-hive-env-sh-文件"><a href="#修改-hive-env-sh-文件" class="headerlink" title="修改 hive-env.sh 文件"></a>修改 hive-env.sh 文件</h3><figure class="highlight shell hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">cp $HIVE_HOME/conf/hive-env.sh.template $HIVE_HOME/conf/hive-env.sh</span><br><span class="line">vi $HIVE_HOME/conf/hive-env.sh</span><br><span class="line"></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> Set HADOOP_HOME to point to a specific hadoop install directory</span></span><br><span class="line">HADOOP_HOME=/opt/hadoop/hadoop-3.2.1</span><br><span class="line"></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> Hive Configuration Directory can be controlled by:</span></span><br><span class="line">export HIVE_CONF_DIR=/opt/hive/apache-hive-3.1.2-bin/conf</span><br><span class="line"></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> Folder containing extra libraries required <span class="hljs-keyword">for</span> hive compilation/execution can be controlled by:</span></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> <span class="hljs-built_in">export</span> HIVE_AUX_JARS_PATH=</span></span><br><span class="line">export JAVA_HOME=/opt/java/jdk1.8.0_221/</span><br><span class="line">export HIVE_HOME=/opt/hive/apache-hive-3.1.2-bin/</span><br></pre></td></tr></table></figure><h3 id="设置-logs"><a href="#设置-logs" class="headerlink" title="设置 logs"></a>设置 logs</h3><figure class="highlight shell hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">cp $HIVE_HOME/conf/hive-log4j2.properties.template $HIVE_HOME/conf/hive-log4j2.properties</span><br><span class="line">vi $HIVE_HOME/conf/hive-log4j2.properties</span><br><span class="line"></span><br><span class="line">property.hive.log.dir = /data/hive/logs</span><br><span class="line"></span><br><span class="line">mkdir -p /data/hive/logs</span><br></pre></td></tr></table></figure><h3 id="安装并配置-mysql"><a href="#安装并配置-mysql" class="headerlink" title="安装并配置 mysql"></a>安装并配置 mysql</h3><figure class="highlight shell hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">wget http://dev.mysql.com/get/mysql-community-release-el7-5.noarch.rpm</span><br><span class="line">rpm -ivh mysql-community-release-el7-5.noarch.rpm</span><br><span class="line"></span><br><span class="line">yum search mysql</span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> 里面有一条</span></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> mysql-community-server.x86_64 : The MySQL server and related files</span></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> 安装它</span></span><br><span class="line">mysql-community-server.x86_64</span><br><span class="line"></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> 刚才yum search的时候,有一条</span></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> mysql-connector-java.noarch : Official JDBC driver <span class="hljs-keyword">for</span> MySQL</span></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> 安装它</span></span><br><span class="line">yum install mysql-connector-java.noarch</span><br><span class="line"></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> 安装好后在 /usr/share/java 下</span></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> 拷贝到 hive 的 lib 文件夹下</span></span><br><span class="line">cp /usr/share/java/mysql-connector-java.jar $HIVE_HOME/lib</span><br><span class="line"></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> 重启 mysql 服务</span></span><br><span class="line">service mysqld restart</span><br><span class="line"></span><br><span class="line">mysql</span><br><span class="line">Welcome to the MySQL monitor.  Commands end with ; or \g.</span><br><span class="line">Your MySQL connection id is 2</span><br><span class="line">Server version: 5.6.46 MySQL Community Server (GPL)</span><br><span class="line"></span><br><span class="line">Copyright (c) 2000, 2019, Oracle and/or its affiliates. All rights reserved.</span><br><span class="line"></span><br><span class="line">Oracle is a registered trademark of Oracle Corporation and/or its</span><br><span class="line">affiliates. Other names may be trademarks of their respective</span><br><span class="line">owners.</span><br><span class="line"></span><br><span class="line">Type 'help;' or '\h' for help. Type '\c' to clear the current input statement.</span><br><span class="line"></span><br><span class="line"><span class="hljs-meta">mysql&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> 安装成功</span></span><br></pre></td></tr></table></figure><p><strong>在mysql上创建hive元数据库，创建hive账号，并进行授权</strong></p><figure class="highlight shell hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> 在mysql上连续执行下述命令</span></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> use mysql;</span></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> update user <span class="hljs-built_in">set</span> password=password(<span class="hljs-string">'123456'</span>) <span class="hljs-built_in">where</span> user=<span class="hljs-string">'root'</span>;</span></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> flush privileges;</span></span><br><span class="line"></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> 重新连接 mysql -u root -p</span></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> create database <span class="hljs-keyword">if</span> not exists hive_metadata;</span></span><br></pre></td></tr></table></figure><h3 id="初始化"><a href="#初始化" class="headerlink" title="初始化"></a>初始化</h3><figure class="highlight shell hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">schematool -dbType mysql -initSchema</span><br></pre></td></tr></table></figure><h3 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h3><figure class="highlight shell hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> 输入 hive</span></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> 进入 hive 交互界面</span></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> 安装成功</span></span><br></pre></td></tr></table></figure><h2 id="Zookeeper"><a href="#Zookeeper" class="headerlink" title="Zookeeper"></a>Zookeeper</h2><h3 id="环境配置-1"><a href="#环境配置-1" class="headerlink" title="环境配置"></a>环境配置</h3><figure class="highlight shell hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> 新建文件夹</span></span><br><span class="line">mkdir -p /opt/zookeeper</span><br><span class="line"></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> 解压</span></span><br><span class="line">tar -zxvf apache-zookeeper-3.5.6-bin.tar.gz -C /opt/zookeeper</span><br><span class="line"></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> 配置环境变量</span></span><br><span class="line">vi /etc/profile</span><br><span class="line">export ZOOKEEPER_HOME=/opt/zookeeper/apache-zookeeper-3.5.6-bin</span><br><span class="line">export PATH=$PATH:$ZOOKEEPER_HOME/bin</span><br></pre></td></tr></table></figure><h3 id="配置-zoo-cfg-文件"><a href="#配置-zoo-cfg-文件" class="headerlink" title="配置 zoo.cfg 文件"></a>配置 zoo.cfg 文件</h3><figure class="highlight shell hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">cp $ZOOKEEPER_HOME/conf/zoo.sample.cfg $ZOOKEEPER_HOME/conf/zoo.cfg</span><br><span class="line">vi $ZOOKEEPER_HOME/conf/zoo.cfg</span><br><span class="line"></span><br><span class="line">dataDir=/data/zookeeper</span><br><span class="line">server.0=master:2888:3888</span><br><span class="line">server.1=slave1:2888:3888 </span><br><span class="line">server.2=slave2:2888:3888</span><br><span class="line">server.3=slave3:2888:3888</span><br><span class="line"></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> server.  </span></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> 后面不能有空格！！！！！</span></span><br></pre></td></tr></table></figure><h3 id="配置-myid-文件"><a href="#配置-myid-文件" class="headerlink" title="配置 myid 文件"></a>配置 myid 文件</h3><figure class="highlight shell hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> 创建 dataDir 目录</span></span><br><span class="line">mkdir -p /data/zookeeper</span><br><span class="line"></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> 创建 myid 文件</span></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> 修改其中的内容</span></span><br><span class="line">vi /data/zookeeper/myid</span><br><span class="line">0</span><br></pre></td></tr></table></figure><h3 id="设置-logs-目录"><a href="#设置-logs-目录" class="headerlink" title="设置 logs 目录"></a>设置 logs 目录</h3><figure class="highlight shell hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">vi log4j.properties</span><br><span class="line"></span><br><span class="line">zookeeper.log.dir=/data/zookeeper/logs</span><br><span class="line"></span><br><span class="line">mkdir -p /data/zookeeper/logs</span><br></pre></td></tr></table></figure><h3 id="配置其他节点"><a href="#配置其他节点" class="headerlink" title="配置其他节点"></a>配置其他节点</h3><figure class="highlight shell hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> 把 mster 上配置好的 zookeeper 文件夹直接传到其他节点</span></span><br><span class="line">cluster_copy_all_nodes -r /opt/zookeeper/ /opt</span><br><span class="line"></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> 把 /data/zookeeper 传到其他节点</span></span><br><span class="line">cluster_copy_all_nodes -r /data/zookeeper/ /data</span><br><span class="line"></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> 修改子节点上 myid 的内容</span></span><br><span class="line"></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> 配置子节点上 /etc/profile</span></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> 刷新环境变量</span></span><br></pre></td></tr></table></figure><h3 id="测试-1"><a href="#测试-1" class="headerlink" title="测试"></a>测试</h3><figure class="highlight shell hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> 在所有节点上分别执行命令</span></span><br><span class="line"></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> 启动服务</span></span><br><span class="line">zkServer.sh start</span><br><span class="line"></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> 查看状态</span></span><br><span class="line">zkServer.sh status</span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> 正确结果应该是: 三个节点中其中一个是leader, 另外两个是follower</span></span><br><span class="line"></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> 检查三个节点是否都有QuromPeerMain进程</span></span><br><span class="line">jps</span><br></pre></td></tr></table></figure><h2 id="Kafka"><a href="#Kafka" class="headerlink" title="Kafka"></a>Kafka</h2><h3 id="安装-scala"><a href="#安装-scala" class="headerlink" title="安装 scala"></a>安装 scala</h3><figure class="highlight shell hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> 解压</span></span><br><span class="line">mkdir -p /opt/scala</span><br><span class="line">tar -zxvf scala-2.12.10.tgz -C /opt/scala/</span><br><span class="line"></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> 配置环境变量</span></span><br><span class="line">vi /etc/profile</span><br><span class="line"></span><br><span class="line">export SCALA_HOME=/opt/scala/scala-2.12.10</span><br><span class="line">export PATH=$PATH:$SCALA_HOME/bin</span><br><span class="line"></span><br><span class="line">source /etc/profile</span><br><span class="line"></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> 验证</span></span><br><span class="line">scala -version</span><br><span class="line">Scala code runner version 2.12.10 -- Copyright 2002-2019, LAMP/EPFL and Lightbend, Inc.</span><br><span class="line"></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> 将 scala 安装到其他节点</span></span><br><span class="line">cluster_copy_all_nodes -r /opt/scala/ /opt</span><br><span class="line">cluster_copy_all_nodes /etc/profile /etc</span><br><span class="line">cluster_run_all_nodes "hostname; source /etc/profile"</span><br></pre></td></tr></table></figure><h3 id="安装配置-kafka"><a href="#安装配置-kafka" class="headerlink" title="安装配置 kafka"></a>安装配置 kafka</h3><figure class="highlight shell hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> 创建目录</span></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> 解压文件</span></span><br><span class="line">mkdir -p /opt/kafka</span><br><span class="line">tar -zxvf kafka_2.12-2.3.0.tgz -C /opt/kafka/</span><br><span class="line"></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> 配置环境变量</span></span><br><span class="line">vi /etc/profile</span><br><span class="line">export KAFKA_HOME=/opt/kafka/kafka_2.12-2.3.0</span><br><span class="line">export PATH=$PATH:$KAFKA_HOME/bin</span><br><span class="line"></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> 修改 server.properties 文件, 找到对应的位置, 修改如下</span></span><br><span class="line">vi $KAFKA_HOME/config/server.properties</span><br><span class="line"></span><br><span class="line">broker.id=0</span><br><span class="line">listeners=PLAINTEXT://192.168.0.100:9092</span><br><span class="line">advertised.listeners=PLAINTEXT://192.168.0.100:9092</span><br><span class="line">log.dirs=/data/kafka/logs</span><br><span class="line">zookeeper.connect=192.168.0.100:2181,192.168.0.101:2181,192.168.0.102:2181,192.168.0.103:2181</span><br><span class="line"></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> 修改 zookeeper.properties 文件, 找到对应的位置, 修改如下</span></span><br><span class="line">dataDir=/data/kafka/zookeeper</span><br><span class="line"></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> 创建相关文件夹</span></span><br><span class="line">mkdir -p /data/kafka/zookeeper</span><br><span class="line">mkdir -p /data/kafka/logs</span><br><span class="line"></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> 同步文件到其他节点</span></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> 在另外节点上，对server.properties要有几处修改</span></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> broker.id 分别修改成： 1  2  3</span></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> listeners 在 ip 那里分别修改成子节点对应的 ip</span></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> advertised.listeners 也在 ip 那里分别修改成子节点对应的 ip</span></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> zookeeper.connect 不需要修改</span></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> 另外节点上也别忘了配置kafka环境变量</span></span><br><span class="line">cluster_copy_all_nodes -r /opt/kafka/ /opt</span><br><span class="line">cluster_copy_all_nodes -r /data/kafka/ /data</span><br><span class="line">cluster_copy_all_nodes /etc/profile /etc</span><br></pre></td></tr></table></figure><h3 id="测试-2"><a href="#测试-2" class="headerlink" title="测试"></a>测试</h3><figure class="highlight shell hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> 在所有节点上都启动 kafka</span></span><br><span class="line">nohup kafka-server-start.sh $KAFKA_HOME/config/server.properties &amp;</span><br><span class="line"></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> 在主节点上创建主题TestTopic</span></span><br><span class="line">kafka-topics.sh --zookeeper 192.168.0.100:2181,192.168.0.101:2181,192.168.0.102:2181,192.168.0.103:2181 --topic TestTopic --replication-factor 1 --partitions 1 --create</span><br><span class="line"></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> 在主节点上启动一个生产者</span></span><br><span class="line">kafka-console-producer.sh --broker-list 192.168.0.100:9092,192.168.0.101:9092,192.168.0.102:9092,192.168.0.103:9092 --topic TestTopic</span><br><span class="line"></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> 在其他节点上分别创建消费者</span></span><br><span class="line">kafka-console-consumer.sh --bootstrap-server 192.168.0.101:9092 --topic TestTopic --from-beginning</span><br><span class="line">kafka-console-consumer.sh --bootstrap-server 192.168.0.102:9092 --topic TestTopic --from-beginning</span><br><span class="line">kafka-console-consumer.sh --bootstrap-server 192.168.0.103:9092 --topic TestTopic --from-beginning</span><br><span class="line"></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> 在主节点生产者命令行那里随便输入一段话</span></span><br><span class="line"><span class="hljs-meta">&gt;</span><span class="hljs-bash"> hello world</span></span><br><span class="line"></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> 然后你就会发现在其他两个消费者节点那里也出现了这句话, 即消费到了该数据</span></span><br></pre></td></tr></table></figure><h2 id="Flume"><a href="#Flume" class="headerlink" title="Flume"></a>Flume</h2><h3 id="环境配置-2"><a href="#环境配置-2" class="headerlink" title="环境配置"></a>环境配置</h3><figure class="highlight shell hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> flume只需要在主节点配置, 不需要在其他节点配置</span></span><br><span class="line"></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> 创建目录, 解压文件</span></span><br><span class="line">mkdir -p /opt/flume</span><br><span class="line">tar -zxvf apache-flume-1.9.0-bin.tar.gz -C /opt/flume/</span><br><span class="line"></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> 环境变量</span></span><br><span class="line">vi /etc/profile</span><br><span class="line">export FLUME_HOME=/opt/flume/apache-flume-1.9.0-bin</span><br><span class="line">export FLUME_CONF_DIR=$FLUME_HOME/conf</span><br><span class="line">export PATH=$PATH:$FLUME_HOME/bin</span><br></pre></td></tr></table></figure><h3 id="修改-flume-conf-properties"><a href="#修改-flume-conf-properties" class="headerlink" title="修改 flume-conf.properties"></a>修改 flume-conf.properties</h3><figure class="highlight shell hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">cp  $FLUME_CONF_DIR/flume-conf.properties.template  $FLUME_CONF_DIR/flume-conf.properties</span><br><span class="line"></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> 在文件追加</span></span><br><span class="line">vi $FLUME_CONF_DIR/flume-conf.properties</span><br><span class="line"></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash">agent1表示代理名称</span></span><br><span class="line">agent1.sources=source1</span><br><span class="line">agent1.sinks=sink1</span><br><span class="line">agent1.channels=channel1</span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash">配置source1</span></span><br><span class="line">agent1.sources.source1.type=spooldir</span><br><span class="line">agent1.sources.source1.spoolDir=/data/flume/logs</span><br><span class="line">agent1.sources.source1.channels=channel1</span><br><span class="line">agent1.sources.source1.fileHeader = false</span><br><span class="line">agent1.sources.source1.interceptors = i1</span><br><span class="line">agent1.sources.source1.interceptors.i1.type = timestamp</span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash">配置channel1</span></span><br><span class="line">agent1.channels.channel1.type=file</span><br><span class="line">agent1.channels.channel1.checkpointDir=/data/flume/logs_tmp_cp</span><br><span class="line">agent1.channels.channel1.dataDirs=/data/flume/logs_tmp</span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash">配置sink1</span></span><br><span class="line">agent1.sinks.sink1.type=hdfs</span><br><span class="line">agent1.sinks.sink1.hdfs.path=hdfs://master:9000/logs</span><br><span class="line">agent1.sinks.sink1.hdfs.fileType=DataStream</span><br><span class="line">agent1.sinks.sink1.hdfs.writeFormat=TEXT</span><br><span class="line">agent1.sinks.sink1.hdfs.rollInterval=1</span><br><span class="line">agent1.sinks.sink1.channel=channel1</span><br><span class="line">agent1.sinks.sink1.hdfs.filePrefix=%Y-%m-%d</span><br><span class="line"></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> 我们看到上面的配置文件中代理 agent1.sources.source1.spoolDir 监听的文件夹是 /data/flume/logs, 所以我们要手动创建一下</span></span><br><span class="line">mkdir -p /data/flume/logs</span><br><span class="line"></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> 上面的配置文件中 agent1.sinks.sink1.hdfs.path=hdfs://master:9000/logs 下，即将监听到的 /data/flume/logs 下的文件自动上传到 hdfs 的 /logs 下, 所以我们要手动创建hdfs 下的目录</span></span><br><span class="line">hdfs dfs -mkdir /logs</span><br></pre></td></tr></table></figure><h3 id="测试-3"><a href="#测试-3" class="headerlink" title="测试"></a>测试</h3><figure class="highlight shell hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> 删除</span></span><br><span class="line">rm $FLMUE_HOME/lib/slf4j-log4j12-1.7.25.jar</span><br><span class="line"></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> 启动服务</span></span><br><span class="line">nohup flume-ng agent -n agent1 -c conf -f $FLUME_CONF_DIR/flume-conf.properties -Dflume.root.logger=DEBUG,console &amp;</span><br><span class="line"></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> 先看下hdfs的logs目录下, 目前什么都没有</span></span><br><span class="line">drwxr-xr-x   - root supergroup          0 2019-10-20 16:53 /logs</span><br><span class="line">drwxr-xr-x   - root supergroup          0 2019-10-20 16:53 /logs</span><br><span class="line"></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> 我们在 /data/flume/logs 随便创建个文件</span></span><br><span class="line">vi /data/flume/logs/test.txt</span><br><span class="line">hunan university</span><br><span class="line">gallon</span><br><span class="line"></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> 然后我们发现hdfs的logs下自动上传了我们刚刚创建的文件</span></span><br><span class="line">hdfs dfs -ls -R /</span><br><span class="line">-rw-r--r--   2 root supergroup         24 2019-10-20 16:45 /logs/2019-10-20.1571561139240</span><br><span class="line"></span><br><span class="line">hdfs dfs -cat  /logs/2019-10-20.1571561139240</span><br><span class="line">hunan university</span><br><span class="line">gallon</span><br></pre></td></tr></table></figure><h2 id="Hbase"><a href="#Hbase" class="headerlink" title="Hbase"></a>Hbase</h2><h3 id="环境配置-3"><a href="#环境配置-3" class="headerlink" title="环境配置"></a>环境配置</h3><figure class="highlight shell hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> 创建目录</span></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> 解压文件</span></span><br><span class="line">mkdir -p /opt/hbase</span><br><span class="line">tar -zxvf hbase-2.2.1-bin.tar.gz -C /opt/hbase</span><br><span class="line"></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> 环境变量</span></span><br><span class="line">vi /etc/profile</span><br><span class="line"></span><br><span class="line">export HBASE_HOME=/opt/hbase/hbase-2.2.1</span><br><span class="line">export PATH=$PAHT:$HBASE_HOME/bin</span><br><span class="line"></span><br><span class="line">source /etc/profile</span><br></pre></td></tr></table></figure><h3 id="修改-hbase-env-sh-文件"><a href="#修改-hbase-env-sh-文件" class="headerlink" title="修改 hbase-env.sh 文件"></a>修改 hbase-env.sh 文件</h3><figure class="highlight shell hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">vi $HBASE_HOME/conf/hbase-env.sh </span><br><span class="line"></span><br><span class="line">export JAVA_HOME=/opt/java/jdk1.8.0_221</span><br><span class="line">export HBASE_LOG_DIR=/data/hbase/logs </span><br><span class="line">export HBASE_MANAGES_ZK=false</span><br></pre></td></tr></table></figure><h3 id="修改-hbase-site-xml-文件"><a href="#修改-hbase-site-xml-文件" class="headerlink" title="修改 hbase-site.xml 文件"></a>修改 hbase-site.xml 文件</h3><figure class="highlight shell hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">vi $HBASE_HOME/conf/hbase-site.xml</span><br><span class="line"></span><br><span class="line">&lt;configuration&gt;</span><br><span class="line">&lt;property&gt; </span><br><span class="line">    &lt;name&gt;hbase.rootdir&lt;/name&gt; </span><br><span class="line">    &lt;value&gt;hdfs://master:9000/hbase&lt;/value&gt; </span><br><span class="line">  &lt;/property&gt; </span><br><span class="line">  &lt;property&gt; </span><br><span class="line">    &lt;name&gt;hbase.cluster.distributed&lt;/name&gt; </span><br><span class="line">    &lt;value&gt;true&lt;/value&gt; </span><br><span class="line">  &lt;/property&gt; </span><br><span class="line">  &lt;property&gt; </span><br><span class="line">    &lt;name&gt;hbase.zookeeper.quorum&lt;/name&gt; </span><br><span class="line">    &lt;value&gt;master,slave1,slave2,slave3&lt;/value&gt; </span><br><span class="line">  &lt;/property&gt;  </span><br><span class="line">  &lt;property&gt;</span><br><span class="line">    &lt;name&gt;hbase.tmp.dir&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;/data/hbase/tmp&lt;/value&gt;</span><br><span class="line">  &lt;/property&gt;</span><br><span class="line">  &lt;property&gt; </span><br><span class="line">    &lt;name&gt;hbase.master&lt;/name&gt; </span><br><span class="line">    &lt;value&gt;hdfs://master:60000&lt;/value&gt; </span><br><span class="line">  &lt;/property&gt;</span><br><span class="line">  &lt;property&gt;</span><br><span class="line">    &lt;name&gt;hbase.master.info.port&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;16010&lt;/value&gt;</span><br><span class="line">  &lt;/property&gt;</span><br><span class="line">  &lt;property&gt;</span><br><span class="line">    &lt;name&gt;hbase.regionserver.info.port&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;16030&lt;/value&gt;</span><br><span class="line">  &lt;/property&gt;</span><br><span class="line">  &lt;property&gt;</span><br><span class="line">    &lt;name&gt;hbase.unsafe.stream.capability.enforce&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;false&lt;/value&gt;</span><br><span class="line">    &lt;description&gt;完全分布式式必须为false&lt;/description&gt;</span><br><span class="line">  &lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure><h3 id="修改-regionservers-文件"><a href="#修改-regionservers-文件" class="headerlink" title="修改 regionservers 文件"></a>修改 regionservers 文件</h3><figure class="highlight shell hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">vi $HBASE_HOME/conf/regionservers </span><br><span class="line"></span><br><span class="line">master</span><br><span class="line">slave1</span><br><span class="line">slave2</span><br><span class="line">slave3</span><br></pre></td></tr></table></figure><h3 id="其他节点配置"><a href="#其他节点配置" class="headerlink" title="其他节点配置"></a>其他节点配置</h3><figure class="highlight shell hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> 复制文件</span></span><br><span class="line">cluster_copy_all_nodes -r /opt/hbase/ /opt</span><br><span class="line">cluster_copy_all_nodes -r /data/hbase/ /data</span><br><span class="line">cluster_copy_all_nodes /etc/profile /etc</span><br><span class="line"></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> 刷新环境</span></span><br><span class="line">cluster_run_all_nodes "hostname; source /etc/profile"</span><br><span class="line"></span><br><span class="line">cluster_run_all_nodes "rm /opt/hbase/hbase-2.2.1/lib/client-facing-thirdparty/slf4j-log4j12-1.7.25.jar"</span><br></pre></td></tr></table></figure><h3 id="测试-4"><a href="#测试-4" class="headerlink" title="测试"></a>测试</h3><figure class="highlight shell hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">rm /opt/hbase/hbase-2.2.1/lib/client-facing-thirdparty/slf4j-log4j12-1.7.25.jar</span><br><span class="line"></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> 注意：测试Hbase之前, zookeeper 和 hadoop 需要提前启动起来</span></span><br><span class="line">start-hbase.sh   </span><br><span class="line"></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> 正确结果：主节点上显示：HMaster / 子节点上显示：HRegionServer</span></span><br></pre></td></tr></table></figure><p>在浏览器中访问 <a href="http://master:16010" target="_blank" rel="noopener">web ui</a></p><h2 id="Spark"><a href="#Spark" class="headerlink" title="Spark"></a>Spark</h2><h3 id="环境配置-4"><a href="#环境配置-4" class="headerlink" title="环境配置"></a>环境配置</h3><figure class="highlight shell hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> 创建目录, 解压文件</span></span><br><span class="line">mkdir -p /opt/spark</span><br><span class="line">tar -zxvf spark-2.4.4-bin-hadoop2.7.tgz -C /opt/spark/</span><br><span class="line"></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> 配置环境变量</span></span><br><span class="line">vi /etc/profile</span><br><span class="line"></span><br><span class="line">export SPARK_HOME=/opt/spark/spark-2.4.4-bin-hadoop2.7</span><br><span class="line">export PATH=$PATH:$SPARK_HOME/sbin:$SPARK_HOME/bin</span><br></pre></td></tr></table></figure><h3 id="修改-spark-env-sh-文件"><a href="#修改-spark-env-sh-文件" class="headerlink" title="修改 spark-env.sh 文件"></a>修改 spark-env.sh 文件</h3><figure class="highlight shell hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">cp $SPARK_HOME/conf/spark-env.sh.template $SPARK_HOME/conf/spark-env.sh</span><br><span class="line">vi $SPARK_HOME/conf/spark-env.sh</span><br><span class="line"></span><br><span class="line">SPARK_LOG_DIR=/data/spark/logs</span><br><span class="line">export JAVA_HOME=/opt/java/jdk1.8.0_221</span><br><span class="line">export SCALA_HOME=/opt/scala/scala-2.12.10</span><br><span class="line">export HADOOP_HOME=/opt/hadoop/hadoop-3.1.2</span><br><span class="line">export HADOOP_CONF_DIR=$HADOOP_HOME/etc/hadoop</span><br><span class="line"></span><br><span class="line">mkdir -p /data/spark/logs</span><br><span class="line"></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> 文件重命名</span></span><br><span class="line">mv $SPARK_HOME/sbin/start-all.sh $SPARK_HOME/sbin/start-spark-all.sh</span><br><span class="line">mv $SPARK_HOME/sbin/stop-all.sh $SPARK_HOME/sbin/stop-spark-all.sh</span><br></pre></td></tr></table></figure><h3 id="修改-slaves-文件"><a href="#修改-slaves-文件" class="headerlink" title="修改 slaves 文件"></a>修改 slaves 文件</h3><figure class="highlight shell hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">cp $SPARK_HOME/conf/slaves.template $SPARK_HOME/conf/slaves</span><br><span class="line">vi $SPARK_HOME/conf/slaves</span><br><span class="line"></span><br><span class="line">master</span><br><span class="line">slave1</span><br><span class="line">slave2</span><br><span class="line">slave3</span><br></pre></td></tr></table></figure><h3 id="其他节点配置-1"><a href="#其他节点配置-1" class="headerlink" title="其他节点配置"></a>其他节点配置</h3><figure class="highlight shell hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cluster_copy_all_nodes -r /opt/spark/ /opt/</span><br><span class="line">cluster_copy_all_nodes /etc/profile /etc</span><br></pre></td></tr></table></figure><h3 id="启动"><a href="#启动" class="headerlink" title="启动"></a>启动</h3><figure class="highlight shell hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">vi start-master.sh</span><br><span class="line"></span><br><span class="line">SPARK_MASTER_WEBUI_PORT=8001</span><br><span class="line"></span><br><span class="line">./start-all.sh</span><br></pre></td></tr></table></figure><p>启动完毕后在主机浏览器访问<a href="http://master:8001/" target="_blank" rel="noopener">界面</a></p><p><a style="background-color:black;color:white;text-decoration:none;padding:4px 6px;font-family:-apple-system, BlinkMacSystemFont, &quot;San Francisco&quot;, &quot;Helvetica Neue&quot;, Helvetica, Ubuntu, Roboto, Noto, &quot;Segoe UI&quot;, Arial, sans-serif;font-size:12px;font-weight:bold;line-height:1.2;display:inline-block;border-radius:3px" href="https://unsplash.com/@heytowner?utm_medium=referral&amp;utm_campaign=photographer-credit&amp;utm_content=creditBadge" target="_blank" rel="noopener noreferrer" title="Download free do whatever you want high-resolution photos from JOHN TOWNER"><span style="display:inline-block;padding:2px 3px"><svg xmlns="http://www.w3.org/2000/svg" style="height:12px;width:auto;position:relative;vertical-align:middle;top:-2px;fill:white" viewbox="0 0 32 32"><title>unsplash-logo</title><path d="M10 9V0h12v9H10zm12 5h10v18H0V14h10v9h12v-9z"/></svg></span><span style="display:inline-block;padding:2px 3px">JOHN TOWNER</span></a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文主要记录了 hadoop 大数据集群的相关组件安装及记录过程&lt;/p&gt;
    
    </summary>
    
    
      <category term="Bigdata" scheme="http://gallonhu.github.io/categories/Bigdata/"/>
    
    
      <category term="Install" scheme="http://gallonhu.github.io/tags/Install/"/>
    
  </entry>
  
  <entry>
    <title>RabbitMQ基础概念</title>
    <link href="http://gallonhu.github.io/posts/1f364dfa/"/>
    <id>http://gallonhu.github.io/posts/1f364dfa/</id>
    <published>2019-12-16T02:48:42.000Z</published>
    <updated>2020-01-18T13:39:58.768Z</updated>
    
    <content type="html"><![CDATA[<h2 id="消息队列相关"><a href="#消息队列相关" class="headerlink" title="消息队列相关"></a>消息队列相关</h2><h3 id="消息队列是什么"><a href="#消息队列是什么" class="headerlink" title="消息队列是什么"></a>消息队列是什么</h3><p><a href="https://www.wikiwand.com/en/Message_queue" target="_blank" rel="noopener">wiki</a>上给出的定义为：</p><p>在<a href="https://www.wikiwand.com/zh-hans/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6" target="_blank" rel="noopener">计算机科学</a>中，<strong>消息队列</strong>（英语：Message queue）是一种<a href="https://www.wikiwand.com/zh-hans/%E8%BF%9B%E7%A8%8B%E9%97%B4%E9%80%9A%E4%BF%A1" target="_blank" rel="noopener">进程间通信</a>或同一进程的不同<a href="https://www.wikiwand.com/zh-hans/%E7%BA%BF%E7%A8%8B" target="_blank" rel="noopener">线程</a>间的通信方式，<a href="https://www.wikiwand.com/zh-hans/%E8%BB%9F%E9%AB%94" target="_blank" rel="noopener">软体</a>的<a href="https://www.wikiwand.com/zh-hans/%E8%B2%AF%E5%88%97" target="_blank" rel="noopener">贮列</a>用来处理一系列的输入，通常是来自使用者。消息队列提供了<a href="https://www.wikiwand.com/zh-hans/%E7%95%B0%E6%AD%A5" target="_blank" rel="noopener">异步</a>的<a href="https://www.wikiwand.com/zh-hans/%E9%80%9A%E4%BF%A1%E5%8D%8F%E8%AE%AE" target="_blank" rel="noopener">通信协议</a>，每一个贮列中的纪录包含详细说明的资料，包含发生的时间，输入装置的种类，以及特定的输入参数，也就是说：消息的发送者和接收者不需要同时与消息队列交互。消息会保存在<a href="https://www.wikiwand.com/zh-hans/%E9%98%9F%E5%88%97" target="_blank" rel="noopener">队列</a>中，直到接收者取回它。<a href="https://www.wikiwand.com/zh-hans/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97#citenote1" target="_blank" rel="noopener">[1]</a></p><p>一个 <a href="https://www.wikiwand.com/zh-hans/WIMP_(%E9%9B%BB%E8%85%A6)" target="_blank" rel="noopener">WIMP</a> 环境像是 <a href="https://www.wikiwand.com/zh-hans/Microsoft_Windows" target="_blank" rel="noopener">Microsoft Windows</a>，借由优先的某些形式（通常是事件的时间或是重要性的顺序）来储存使用者产生的事件到一个 <strong>事件贮列</strong> 中。系统把每个事件从事件贮列中传递给目标的应用程式。</p><a id="more"></a><h3 id="实现方式"><a href="#实现方式" class="headerlink" title="实现方式"></a>实现方式</h3><p>实际上，消息队列常常保存在<a href="https://www.wikiwand.com/zh-hans/%E9%93%BE%E8%A1%A8" target="_blank" rel="noopener">链表</a>结构中。<a href="https://www.wikiwand.com/zh-hans/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97#citenoteibm2" target="_blank" rel="noopener">[2]</a>拥有权限的进程可以向消息队列中写入或读取消息。</p><h3 id="RabbitMQ的特点"><a href="#RabbitMQ的特点" class="headerlink" title="RabbitMQ的特点"></a>RabbitMQ的特点</h3><p><a href="https://www.rabbitmq.com/#features" target="_blank" rel="noopener">官网上描述的特点</a>是:</p><p>RabbitMQ是部署最广泛的开源消息代理。</p><p>RabbitMQ轻量级，易于在内部和云中部署。它支持多种消息传递协议。RabbitMQ部署在分布式和集群中，以满足高规模，高可用性要求。</p><p>RabbitMQ可运行在多数操作系统和云平台中，并为大多数流行的语言提供各种开发工具。</p><h2 id="RabbitMQ中的概念模型"><a href="#RabbitMQ中的概念模型" class="headerlink" title="RabbitMQ中的概念模型"></a>RabbitMQ中的概念模型</h2><h3 id="消息模型"><a href="#消息模型" class="headerlink" title="消息模型"></a>消息模型</h3><p>所有 MQ 产品从模型抽象上来说都是一样的过程：<br>消费者（consumer）订阅某个队列。生产者（producer）创建消息，然后发布到队列（queue）中，最后将消息发送到监听的消费者。</p><div align="center"><img src="  https://cdn.jsdelivr.net/gh/GallonHu/pic@master/screenshot/python-one-overall.png" style="zoom:100%;"></div><h3 id="RabbitMQ-基本概念"><a href="#RabbitMQ-基本概念" class="headerlink" title="RabbitMQ 基本概念"></a>RabbitMQ 基本概念</h3><p>上面只是最简单抽象的描述，具体到 RabbitMQ 则有更详细的概念需要解释。上面介绍过 RabbitMQ 是 AMQP 协议的一个开源实现，所以其内部实际上也是 AMQP 中的基本概念：</p><div align="center"><img src="  https://cdn.jsdelivr.net/gh/GallonHu/pic@master/screenshot/auto-orient.png" style="zoom:75%;"></div><ol><li>Message<br> 消息，消息是不具名的，它由消息头和消息体组成。消息体是不透明的，而消息头则由一系列的可选属性组成，这些属性包括routing-key（路由键）、priority（相对于其他消息的优先权）、delivery-mode（指出该消息可能需要持久性存储）等。</li><li>Publisher<br> 消息的生产者，也是一个向交换器发布消息的客户端应用程序。</li><li>Exchange<br> 交换器，用来接收生产者发送的消息并将这些消息路由给服务器中的队列。</li><li>Binding<br> 绑定，用于消息队列和交换器之间的关联。一个绑定就是基于路由键将交换器和消息队列连接起来的路由规则，所以可以将交换器理解成一个由绑定构成的路由表。</li><li>Queue<br> 消息队列，用来保存消息直到发送给消费者。它是消息的容器，也是消息的终点。一个消息可投入一个或多个队列。消息一直在队列里面，等待消费者连接到这个队列将其取走。</li><li>Connection<br> 网络连接，比如一个TCP连接。</li><li>Channel<br> 信道，多路复用连接中的一条独立的双向数据流通道。信道是建立在真实的TCP连接内地虚拟连接，AMQP 命令都是通过信道发出去的，不管是发布消息、订阅队列还是接收消息，这些动作都是通过信道完成。因为对于操作系统来说建立和销毁 TCP 都是非常昂贵的开销，所以引入了信道的概念，以复用一条 TCP 连接。</li><li>Consumer<br> 消息的消费者，表示一个从消息队列中取得消息的客户端应用程序。</li><li>Virtual Host<br> 虚拟主机，表示一批交换器、消息队列和相关对象。虚拟主机是共享相同的身份认证和加密环境的独立服务器域。每个 vhost 本质上就是一个 mini 版的 RabbitMQ 服务器，拥有自己的队列、交换器、绑定和权限机制。vhost 是 AMQP 概念的基础，必须在连接时指定，RabbitMQ 默认的 vhost 是 / 。</li><li>Broker<br>表示消息队列服务器实体。</li></ol><h3 id="AMQP-中的消息路由"><a href="#AMQP-中的消息路由" class="headerlink" title="AMQP 中的消息路由"></a>AMQP 中的消息路由</h3><p>AMQP 中消息的路由过程和 Java 开发者熟悉的 JMS 存在一些差别，AMQP 中增加了 Exchange 和 Binding 的角色。生产者把消息发布到 Exchange 上，消息最终到达队列并被消费者接收，而 Binding 决定交换器的消息应该发送到那个队列。</p><div align="center"><img src="  https://cdn.jsdelivr.net/gh/GallonHu/pic@master/screenshot/auto-orient-20190331180852379.png" style="zoom:75%;"></div><h4 id="Exchange的类型"><a href="#Exchange的类型" class="headerlink" title="Exchange的类型"></a>Exchange的类型</h4><p>Exchange分发消息时根据类型的不同分发策略有区别，目前共四种类型：direct、fanout、topic、headers 。headers 匹配 AMQP 消息的 header 而不是路由键，此外 headers 交换器和 direct 交换器完全一致，但性能差很多，目前几乎用不到了，所以直接看另外三种类型：</p><ol><li>direct</li></ol><div align="center"><img src="  https://cdn.jsdelivr.net/gh/GallonHu/pic@master/screenshot/auto-orient-20190331180955160.png" style="zoom:75%;"></div><p>消息中的路由键（routing key）如果和 Binding 中的 binding key 一致， 交换器就将消息发到对应的队列中。路由键与队列名完全匹配，如果一个队列绑定到交换机要求路由键为“dog”，则只转发 routing key 标记为“dog”的消息，不会转发“dog.puppy”，也不会转发“dog.guard”等等。它是完全匹配、单播的模式。</p><ol start="2"><li>fanout</li></ol><div align="center"><img src="  https://cdn.jsdelivr.net/gh/GallonHu/pic@master/screenshot/auto-orient-20190331181057327.png" style="zoom:75%;"></div><p>每个发到 fanout 类型交换器的消息都会分到所有绑定的队列上去。fanout 交换器不处理路由键，只是简单的将队列绑定到交换器上，每个发送到交换器的消息都会被转发到与该交换器绑定的所有队列上。很像子网广播，每台子网内的主机都获得了一份复制的消息。fanout 类型转发消息是最快的。</p><ol start="3"><li>topic</li></ol><div align="center"><img src="   https://cdn.jsdelivr.net/gh/GallonHu/pic@master/screenshot/auto-orient-20190331181122950.png" style="zoom:75%;"></div><p> topic 交换器通过模式匹配分配消息的路由键属性，将路由键和某个模式进行匹配，此时队列需要绑定到一个模式上。它将路由键和绑定键的字符串切分成单词，这些单词之间用点隔开。它同样也会识别两个通配符：符号“#”和符号“*”。#匹配0个或多个单词，*匹配不多不少一个单词。</p><p><a style="background-color:black;color:white;text-decoration:none;padding:4px 6px;font-family:-apple-system, BlinkMacSystemFont, &quot;San Francisco&quot;, &quot;Helvetica Neue&quot;, Helvetica, Ubuntu, Roboto, Noto, &quot;Segoe UI&quot;, Arial, sans-serif;font-size:12px;font-weight:bold;line-height:1.2;display:inline-block;border-radius:3px" href="https://unsplash.com/@nineteen?utm_medium=referral&amp;utm_campaign=photographer-credit&amp;utm_content=creditBadge" target="_blank" rel="noopener noreferrer" title="Download free do whatever you want high-resolution photos from Andrew Ly"><span style="display:inline-block;padding:2px 3px"><svg xmlns="http://www.w3.org/2000/svg" style="height:12px;width:auto;position:relative;vertical-align:middle;top:-2px;fill:white" viewbox="0 0 32 32"><title>unsplash-logo</title><path d="M10 9V0h12v9H10zm12 5h10v18H0V14h10v9h12v-9z"/></svg></span><span style="display:inline-block;padding:2px 3px">Andrew Ly</span></a></p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;消息队列相关&quot;&gt;&lt;a href=&quot;#消息队列相关&quot; class=&quot;headerlink&quot; title=&quot;消息队列相关&quot;&gt;&lt;/a&gt;消息队列相关&lt;/h2&gt;&lt;h3 id=&quot;消息队列是什么&quot;&gt;&lt;a href=&quot;#消息队列是什么&quot; class=&quot;headerlink&quot; title=&quot;消息队列是什么&quot;&gt;&lt;/a&gt;消息队列是什么&lt;/h3&gt;&lt;p&gt;&lt;a href=&quot;https://www.wikiwand.com/en/Message_queue&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;wiki&lt;/a&gt;上给出的定义为：&lt;/p&gt;
&lt;p&gt;在&lt;a href=&quot;https://www.wikiwand.com/zh-hans/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;计算机科学&lt;/a&gt;中，&lt;strong&gt;消息队列&lt;/strong&gt;（英语：Message queue）是一种&lt;a href=&quot;https://www.wikiwand.com/zh-hans/%E8%BF%9B%E7%A8%8B%E9%97%B4%E9%80%9A%E4%BF%A1&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;进程间通信&lt;/a&gt;或同一进程的不同&lt;a href=&quot;https://www.wikiwand.com/zh-hans/%E7%BA%BF%E7%A8%8B&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;线程&lt;/a&gt;间的通信方式，&lt;a href=&quot;https://www.wikiwand.com/zh-hans/%E8%BB%9F%E9%AB%94&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;软体&lt;/a&gt;的&lt;a href=&quot;https://www.wikiwand.com/zh-hans/%E8%B2%AF%E5%88%97&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;贮列&lt;/a&gt;用来处理一系列的输入，通常是来自使用者。消息队列提供了&lt;a href=&quot;https://www.wikiwand.com/zh-hans/%E7%95%B0%E6%AD%A5&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;异步&lt;/a&gt;的&lt;a href=&quot;https://www.wikiwand.com/zh-hans/%E9%80%9A%E4%BF%A1%E5%8D%8F%E8%AE%AE&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;通信协议&lt;/a&gt;，每一个贮列中的纪录包含详细说明的资料，包含发生的时间，输入装置的种类，以及特定的输入参数，也就是说：消息的发送者和接收者不需要同时与消息队列交互。消息会保存在&lt;a href=&quot;https://www.wikiwand.com/zh-hans/%E9%98%9F%E5%88%97&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;队列&lt;/a&gt;中，直到接收者取回它。&lt;a href=&quot;https://www.wikiwand.com/zh-hans/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97#citenote1&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;[1]&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;一个 &lt;a href=&quot;https://www.wikiwand.com/zh-hans/WIMP_(%E9%9B%BB%E8%85%A6)&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;WIMP&lt;/a&gt; 环境像是 &lt;a href=&quot;https://www.wikiwand.com/zh-hans/Microsoft_Windows&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Microsoft Windows&lt;/a&gt;，借由优先的某些形式（通常是事件的时间或是重要性的顺序）来储存使用者产生的事件到一个 &lt;strong&gt;事件贮列&lt;/strong&gt; 中。系统把每个事件从事件贮列中传递给目标的应用程式。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Tutorials" scheme="http://gallonhu.github.io/categories/Tutorials/"/>
    
    
      <category term="RabbitMQ" scheme="http://gallonhu.github.io/tags/RabbitMQ/"/>
    
  </entry>
  
  <entry>
    <title>spark基本概念</title>
    <link href="http://gallonhu.github.io/posts/8509da34/"/>
    <id>http://gallonhu.github.io/posts/8509da34/</id>
    <published>2019-12-16T02:43:38.000Z</published>
    <updated>2019-12-16T03:04:17.449Z</updated>
    
    <content type="html"><![CDATA[<h1 id="RDD-Programming-Guide"><a href="#RDD-Programming-Guide" class="headerlink" title="RDD Programming Guide"></a>RDD Programming Guide</h1><p>翻译自<a href="http://spark.apache.org/docs/latest/rdd-programming-guide.html" target="_blank" rel="noopener">官方文档</a>，本文值翻译了部分 Python 部分。</p><h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>从高层次看，每个 Spark 应用都包含一个驱动程序，用于执行用户的 main 函数以及在集群上进行各种并行操作。Spark 提供的重要抽象是弹性分布式数据集（ <em>resilient distributed dataset</em>），这是一个包含诸多元素、被划分到不同节点上进行并行处理的数据集。RDDs 通过打开一个 HDFS 文件（或者其他任何 hadoop 支持的文件系统）、在驱动程序中打开一个已有的 Scala 数据集或者由其他 RDD 转换得到。用户可以要求 Spark 将 RDD 持久化到内存中，这样可以有效的在并行运算中复用。另外，RDDs 在节点发生错误时会自动恢复。</p><p>Spark 的另一个抽象是在并行运算中使用的共享变量。在默认情况下，当 Spark 将一个函数转化成许多任务在不同节点上运行的时候，对于所有在函数中使用的变量，每一个任务都会得到一个副本。有时，一个变量需要在任务之间或者任务和驱动程序之间共享。Spark 支持两种共享变量：广播变量，用来将一个值缓存到所有节点的内存中；累加器，只能用于累加，比如计数器和求和。</p><a id="more"></a><h2 id="连接-Spark"><a href="#连接-Spark" class="headerlink" title="连接 Spark"></a>连接 Spark</h2><p>Spark2.4.4 支持 Python2.7+ 或 Python3.4+。它使用标准的 CPython 解释器，因此诸如 NumPy 之类的 C 库也是可以使用的。</p><p>Python 中的 Spark 应用程序既可以在运行时使用包含 Spark 的 bin/spark-submit 脚本运行，也可以将其包含在setup.py 中，如下所示：</p><figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">install_requires=[</span><br><span class="line">      <span class="hljs-string">'pyspark==&#123;site.SPARK_VERSION&#125;'</span></span><br><span class="line">  ]</span><br></pre></td></tr></table></figure><p>要在 Python 中运行 Spark 应用程序而无需安装 PySpark，请使用 Spark 目录中的 bin/spark-submit 脚本。 该脚本将加载 Spark 的 Java/Scala 库，并允许你将应用程序提交到集群。 你还可以使用 bin/pyspark启动交互是 Python Shell。</p><p>如果你想要访问 HDFS 中的数据，你需要为你使用的 HDFS 版本建立一个 PySpark 连接。</p><p>最后，你需要将一些 Spark 类 import 到你的程序中。加入如下这行：</p><figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">from</span> pyspark <span class="hljs-keyword">import</span> SparkContext, SparkConf</span><br></pre></td></tr></table></figure><h3 id="初始化-Spark"><a href="#初始化-Spark" class="headerlink" title="初始化 Spark"></a>初始化 Spark</h3><p>在一个 Spark 程序中要做的第一件事就是创建一个 SparkContext 对象来高速 Spark 如何连接一个集群。要创建一个 SparkContext，你首先要创建一个包含你的应用的信息的 SparkConf 对象。</p><figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">conf = SparkConf().setAppName(appName).setMaster(master)</span><br><span class="line">sc = SparkContext(conf=conf)</span><br></pre></td></tr></table></figure><p>appName 参数是在集群 UI 上显示你的应用名称。master 是一个 Spark、Mesos 或 YARN 集群的 URL，特殊的 “local” 字符串表示在本地运行。在实际使用中，当你在集群中运行你的程序，你一般不会把 master 参数在代码中写死，而是通过 spark-submit 运行程序来回去这个参数。但是，在本地测试及单元测试时，你仍需要传入 “local” 参数来运行程序。</p><h3 id="使用命令行"><a href="#使用命令行" class="headerlink" title="使用命令行"></a>使用命令行</h3><p>在 PySpark 命令行中，一个特殊的集成在解释器里的 SparkContext 变量已经建立好了，变量名叫做 sc 。创建你自己的 SparkContext 不会起作用。你可以通过使用 —master 命令行参数来设置这个上下文连接的 master 主机，你也可以通过 —py-files 参数传递一个用逗号隔开的列表来将 Python 的 .zip、.egg 或. py 文件添加到运行时路径中。你还可以通过 —package 参数传递一个用逗号隔开的 maven 列表来给这个命令行会话添加依赖（比如Spark 的包）。任何额外的包含依赖包的仓库（比如 SonaType ）都可以通过传给 —repositorys 参数来添加进去。Spark 包的所有 Python 依赖（列在这个包的 requirements.txt 文件中）在必要时都必须通过 pip 手动安装。</p><p>比如，使用四核来运行bin/pyspark应当输入这个命令：</p><figure class="highlight shell hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-meta">$</span><span class="hljs-bash"> ./bin/pyspark --master <span class="hljs-built_in">local</span>[4]</span></span><br></pre></td></tr></table></figure><p>又比如，把 code.py 文件添加到搜索路径中（为了能够 import 在程序中），应当使用这条命令：</p><figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ ./bin/pyspark --master local[<span class="hljs-number">4</span>] --py-files code.py</span><br></pre></td></tr></table></figure><p>想要了解命令行选项的完整信息请执行 pyspark –help 命令。在这些场景下，pyspark 会触发一个更通用的 spark-submit 脚本</p><p>在 IPython 这个加强的 Python 解释器中运行 PySpark 也是可行的。PySpark 可以在 1.0.0 或更高版本的 IPython上运行。为了使用 IPython，必须在运行 bin/pyspark 时将 PYSPARK_DRIVER_PYTHON 变量设置为 ipython，就像这样：</p><figure class="highlight shell hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-meta">$</span><span class="hljs-bash"> PYSPARK_DRIVER_PYTHON=ipython ./bin/pyspark</span></span><br></pre></td></tr></table></figure><p>你还可以通过设置 PYSPARK_DRIVER_PYTHON_OPTS 来定制化 ipython 或 jupyter。</p><h2 id="弹性分布式数据集（RDD）"><a href="#弹性分布式数据集（RDD）" class="headerlink" title="弹性分布式数据集（RDD）"></a>弹性分布式数据集（RDD）</h2><p>Spark 是以 RDD概念为中心运行的。RDD 是一个容错的、可以被并行运算的元素集合。有两种方法创建 RDDs：在你的驱动程序中并行化一个已经存在的集合；从外部存储系统中引用一个数据集，例如一个共享文件系统、HDFS、HBase 或任何提供了 Hadoop 输入格式的数据源。</p><h3 id="并行化数据集"><a href="#并行化数据集" class="headerlink" title="并行化数据集"></a>并行化数据集</h3><p>并行化数据集是通过在驱动程序中一个现有的迭代器或集合上调用 SparkContext 的 parallelize 方法建立的。为了创建一个能够并行操作的分布数据集，集合中的元素都会被拷贝。比如，以下的语句建立了一个包含 1 到 5 的并行化数据集：</p><figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">data = [<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>, <span class="hljs-number">5</span>]</span><br><span class="line">distData = sc.parallelize(data)</span><br></pre></td></tr></table></figure><p>分布式数据集一旦被建立，就可以进行并行运算。例如，我们可以调用 distData.reduce(lambda a, b: a + b) 来对元素进行累加。在后文我们再详细描述分布数据集上的操作。</p><p>并行集合的一个重要参数是将数据集划分成片的数量。对于每一个分片，Spark 会再集群中运行一个对应的任务。典型情况下，集群中的每个 CPU 将对应运行 2-4 个分片。通常，Spark 会根据你的集群自动设置分片的数量。但是，你也可以通过将第二个参数传递给 parallelize 方法(比如 sc.parallelize(data, 10))来手动确定分片数量。注意：有些代码中会使用切片（slice，分片的同义词）这个术语来保持向下兼容性。</p><h3 id="外部数据集"><a href="#外部数据集" class="headerlink" title="外部数据集"></a>外部数据集</h3><p>PySpark 可以通过 Hadoop 支持的外部数据源（包括本地文件系统、HDFS、Cassandra、HBase、Amazon S3 等等）创建分布数据集。Spark 支持文本文件、序列文件和其他任何 Hadoop 输入格式的文件。</p><p>创建文本文件 RDDs 要使用 SparkContext 的 textFile 方法。这个方法输入一个文件的 URL （本地文件路径或 hdfs://、s3a://等等的 URl）然后读入这个文件并建立一个文本行集合。以下是一个例子：</p>  <figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">distFile = sc.textFile(<span class="hljs-string">"data.txt"</span>)</span><br></pre></td></tr></table></figure><p>建立完成后 distFIle 就可以调用数据集操作了。例如，我们可以调用 map 和 reduce 操作来累加所有文件行的长度，代码如下：</p><figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">distFile.map(<span class="hljs-keyword">lambda</span> s: len(s)).reduce(<span class="hljs-keyword">lambda</span> a, b: a + b)</span><br></pre></td></tr></table></figure><p>在 Spark 读入文件时有几点要注意：</p><ul><li>如果使用本地文件路径，要保证文件在工作节点上这个文件也能通过相同的路径访问到。这点可以通过复制文件到所有节点或使用网络挂载的共享文件系统解决。</li><li>包括 textFile 在内的所有基于 Spark 文件读入方法都支持将文件夹、压缩文件和通配符的路径作为参数。比如，以下表达都是合法的：</li></ul><figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">textFile(<span class="hljs-string">"/my/directory"</span>)</span><br><span class="line">textFile(<span class="hljs-string">"/my/directory/*.txt"</span>)</span><br><span class="line">textFile(<span class="hljs-string">"/my/directory/*.gz"</span>)</span><br></pre></td></tr></table></figure><ul><li>textFile 也可以通过传入第二个可选参数来控制文件的分片数量。默认情况下，Spark 为文件的每个块创建一个分片（HDFS 中默认块的大小为 128MB）。但是你也可以通过传入一个更大的值来要求建立更多的分片。注意，分片的数量不能比文件块的数量少。</li></ul><p>除了文本文件，Spark 的 Python API 还支持多种其他数据格式：</p><ul><li>SparkContext.wholeTextFiles 能够读入包含多个小文件的目录，然后为每个文件返回一个 (filename, content) 对。这是与 textFIle 为每个文本行返回一条记录想对应。</li><li>RDD.saveAsPickleFile 和 SparkContext.pickleFile 方法支持将 RDD 以简单序列化的 Python 对象格式保存。序列化的过程中会以默认10个一批的数量批量处理。</li><li>序列文件和其他 Hadoop 输入输出文件。</li></ul><p><strong>注意</strong></p><p>这个特性目前仍处于试验阶段，被标记为Experimental，目前只适用于高级用户。这个特性在未来可能会被基于Spark SQL的读写支持所取代，因为Spark SQL是更好的方式。</p><h4 id="可写类型支持"><a href="#可写类型支持" class="headerlink" title="可写类型支持"></a>可写类型支持</h4><p>PySpark 序列文件支持利用 Java 作为中介载入一个键值对 RDD，将可写类型转化成 Java 的基本类型，然后使用 <a href="https://github.com/irmen/Pyrolite/" target="_blank" rel="noopener">Pyrolite</a> 将 java 结果对象序列化。当将一个键值对 RDD 储存到一个序列文件中时 PySpark 将会运行上述过程的相反过程。首先将 Python 对象反序列化成 Java 对象，然后转化成可写类型。以下可写类型会自动转换：</p><table><thead><tr><th align="left">Writable Type</th><th align="left">Python Type</th></tr></thead><tbody><tr><td align="left">Text</td><td align="left">unicode str</td></tr><tr><td align="left">IntWritable</td><td align="left">int</td></tr><tr><td align="left">FloatWritable</td><td align="left">float</td></tr><tr><td align="left">DoubleWritable</td><td align="left">float</td></tr><tr><td align="left">BooleanWritable</td><td align="left">bool</td></tr><tr><td align="left">BytesWritable</td><td align="left">bytearray</td></tr><tr><td align="left">NullWritable</td><td align="left">None</td></tr><tr><td align="left">MapWritable</td><td align="left">dict</td></tr></tbody></table><p>数组不能自动转换。用户需要在读写时指定 ArrayWritable 的子类型。在读入的时候，默认的转换器会把自定义的 ArrayWritable 子类型转化成 Java 的 Object[]，之后序列化成 Python 的元组。为了获得 Python 的 array.array 类型来使用主要类型的数组，用户需要自行指定转换器。</p><h4 id="保存和读取序列文件"><a href="#保存和读取序列文件" class="headerlink" title="保存和读取序列文件"></a>保存和读取序列文件</h4><p>和文本文件类似，序列文件可以通过指定的路径来保存与读取。键值的类型可以自定义，但对于标准的可写类型可以不指定：</p><figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-meta">&gt;&gt;&gt; </span>rdd = sc.parallelize(range(<span class="hljs-number">1</span>, <span class="hljs-number">4</span>)).map(<span class="hljs-keyword">lambda</span> x: (x, <span class="hljs-string">"a"</span> * x))</span><br><span class="line"><span class="hljs-meta">&gt;&gt;&gt; </span>rdd.saveAsSequenceFile(<span class="hljs-string">"path/to/file"</span>)</span><br><span class="line"><span class="hljs-meta">&gt;&gt;&gt; </span>sorted(sc.sequenceFile(<span class="hljs-string">"path/to/file"</span>).collect())</span><br><span class="line">[(<span class="hljs-number">1</span>, <span class="hljs-string">u'a'</span>), (<span class="hljs-number">2</span>, <span class="hljs-string">u'aa'</span>), (<span class="hljs-number">3</span>, <span class="hljs-string">u'aaa'</span>)]</span><br></pre></td></tr></table></figure><h4 id="保存和读取其他-Hadoop-输入输出格式"><a href="#保存和读取其他-Hadoop-输入输出格式" class="headerlink" title="保存和读取其他 Hadoop 输入输出格式"></a>保存和读取其他 Hadoop 输入输出格式</h4><p>PySpark 也可以读取和写入其他 Hadoop 输入输出格式，包括新旧两种 Hadoop MapReduce APIs。如果有必要，一个 Hadoop 配置文件也可以以 Python 字典的形式传入。以下是一个使用 Elasticsearch ESInputFormat 的例子：</p><figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-meta">&gt;&gt;&gt; </span>conf = &#123;<span class="hljs-string">"es.resource"</span> : <span class="hljs-string">"index/type"</span>&#125;  <span class="hljs-comment"># assume Elasticsearch is running on localhost defaults</span></span><br><span class="line"><span class="hljs-meta">&gt;&gt;&gt; </span>rdd = sc.newAPIHadoopRDD(<span class="hljs-string">"org.elasticsearch.hadoop.mr.EsInputFormat"</span>,</span><br><span class="line">                             <span class="hljs-string">"org.apache.hadoop.io.NullWritable"</span>,</span><br><span class="line">                             <span class="hljs-string">"org.elasticsearch.hadoop.mr.LinkedMapWritable"</span>,</span><br><span class="line">                             conf=conf)</span><br><span class="line"><span class="hljs-meta">&gt;&gt;&gt; </span>rdd.first()  <span class="hljs-comment"># the result is a MapWritable that is converted to a Python dict</span></span><br><span class="line">(<span class="hljs-string">u'Elasticsearch ID'</span>,</span><br><span class="line"> &#123;<span class="hljs-string">u'field1'</span>: <span class="hljs-literal">True</span>,</span><br><span class="line">  <span class="hljs-string">u'field2'</span>: <span class="hljs-string">u'Some Text'</span>,</span><br><span class="line">  <span class="hljs-string">u'field3'</span>: <span class="hljs-number">12345</span>&#125;)</span><br></pre></td></tr></table></figure><p>注意，如果这个读入格式仅仅依赖于一个 Hadoop 配置和/或输入路径，而且键值类型都可以根据前面的表格直接转换，那么刚才提到的这种方法非常合适。</p><p>如果你有一些自定义的序列化二进制数据（比如从 Cassandra/HBase 中读取数据），那么你需要首先在 Scala/Java 端将这些数据转化成可以被 Pyrolite 的串行化器处理的数据类型。一个<a href="https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.api.python.Converter" target="_blank" rel="noopener">转换器</a>特质已经提供好了。简单地拓展这个特质同时在convert方法中实现你自己的转换代码即可。记住，要确保这个类以及访问你的输入格式所需的依赖都被打到了 Spark 作业包中，并且确保这个包已经包含到了 PySpark 的 classpath 中。</p><p>这里有一些通过自定义转换器来使用 Cassandra/HBase 输入输出格式的<a href="https://github.com/apache/spark/tree/master/examples/src/main/python" target="_blank" rel="noopener">Python样例</a>和<a href="https://github.com/apache/spark/tree/master/examples/src/main/scala/org/apache/spark/examples/pythonconverters" target="_blank" rel="noopener">转换器样例</a>。</p><h2 id="RDD-操作"><a href="#RDD-操作" class="headerlink" title="RDD 操作"></a>RDD 操作</h2><p>RDD支持两种类型的操作：转换（从现有操作创建新的数据集）和动作（在操作数据集上进行计算后，将值返回给驱动程序）。例如，map 是一个转换，它将每个数据集元素通过一个函数传递，并返回代表结果的新 RDD。另一方面，reduce 是使用某些函数聚合 RDD 的所有元素并将最终结果返回给驱动程序的操作（尽管也有并行的 reduceByKey 返回分布式数据集）。</p><p>Spark 中的所有转换都是惰性的，因为它们不会立即计算出结果。取而代之的是，他们只记得应用于某些基本数据集（例如文件）的转换。仅当动作要求将结果返回给驱动程序时才计算转换。这种设计使 Spark 可以更高效地运行。例如，我们可以认识到通过 map 创建的数据集将用于 reduce 中，并且仅将 reduce 的结果返回给驱动程序，而不是将较大的 maped 数据集返回给驱动程序。</p><p>默认情况下，每次在其上执行操作时，可能都会重新计算每个转换后的 RDD。但是，您也可以使用 persist（或缓存）方法将 RDD 保留在内存中，在这种情况下，Spark 会将元素保留在群集中，以便下次查询时可以更快地进行访问。还支持将 RDD 持久存储在磁盘上，或在多个节点之间复制。</p><h3 id="基本操作"><a href="#基本操作" class="headerlink" title="基本操作"></a>基本操作</h3><p>为了说明 RDD 的基本操作，请看以下的简单程序：</p><figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">lines = sc.textFile(<span class="hljs-string">"data.txt"</span>)</span><br><span class="line">lineLengths = lines.map(<span class="hljs-keyword">lambda</span> s: len(s))</span><br><span class="line">totalLength = lineLengths.reduce(<span class="hljs-keyword">lambda</span> a, b: a + b)</span><br></pre></td></tr></table></figure><p>第一行定义了一个由外部文件产生的基本 RDD。这个数据集不是从内存中载入的也不是由其他操作产生的；lines 仅仅是一个指向文件的指针。第二行将 lineLengths 定义为 map 操作的结果。再强调一次，由于惰性求值的缘故，lineLengths 并<strong>不会</strong>被立即计算得到。最后，我们运行了 reduce 操作，这是一个启动操作。从这个操作开始，Spark 将计算过程划分成许多任务并在多机上运行，每台机器运行自己部分的 map 操作和 reduce 操作，最终将自己部分的运算结果返回给驱动程序。</p><p>如果w筽们虚妄以后重复使用 lineLengths，只需要在 reduce 前加入下面这行代码：</p><figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">lineLengths.persist()</span><br></pre></td></tr></table></figure><p>这条代码将使得 lineLengths 在第一次计算生成之后保存在内存中。</p><h3 id="向-Spark-传递函数"><a href="#向-Spark-传递函数" class="headerlink" title="向 Spark 传递函数"></a>向 Spark 传递函数</h3><p>Spark 的 API 严重依赖于向驱动程序传递函数作为参数来在集群上运行。有三种推荐的方法来传递函数作为参数：</p><ul><li><a href="https://docs.python.org/3/tutorial/controlflow.html#lambda-expressions" target="_blank" rel="noopener">Lambda 表达式</a>，简单的函数可以直接写成一个 lambda 表达式（lambda 表达式不支持多语句函数和无返回值的语句）。</li><li>对于代码很长的函数，在 Spark 的函数调用中定义。</li><li>模块中的顶层函数。</li></ul><p>例如，传递一个无法转化为 lambda 表达式的长函数，可以像下面代码这样：</p><figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-string">"""MyScript.py"""</span></span><br><span class="line"><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">"__main__"</span>:</span><br><span class="line">    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">myFunc</span><span class="hljs-params">(s)</span>:</span></span><br><span class="line">        words = s.split(<span class="hljs-string">" "</span>)</span><br><span class="line">        <span class="hljs-keyword">return</span> len(words)</span><br><span class="line"></span><br><span class="line">    sc = SparkContext(...)</span><br><span class="line">    sc.textFile(<span class="hljs-string">"file.txt"</span>).map(myFunc)</span><br></pre></td></tr></table></figure><p>值得指出的是，也可以传递类实例中方法的引用（与单例对象相反），这种传递方法会将整个对象传递过去。比如，考虑以下代码：</p><figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">MyClass</span><span class="hljs-params">(object)</span>:</span></span><br><span class="line">    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">func</span><span class="hljs-params">(self, s)</span>:</span></span><br><span class="line">        <span class="hljs-keyword">return</span> s</span><br><span class="line">    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">doStuff</span><span class="hljs-params">(self, rdd)</span>:</span></span><br><span class="line">        <span class="hljs-keyword">return</span> rdd.map(self.func)</span><br></pre></td></tr></table></figure><p>在这里，如果我们创建了一个新的 MyClass 对象，然后对它调用 doStuff  方法，map 会用到这个对象中方法的引用，所以整个对象都需要传递到集群中。</p><p>还有另一种相似的写法，访问外层对象的数据域会传递整个对象的引用：</p><figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">MyClass</span><span class="hljs-params">(object)</span>:</span></span><br><span class="line">    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span><span class="hljs-params">(self)</span>:</span></span><br><span class="line">        self.field = <span class="hljs-string">"Hello"</span></span><br><span class="line">    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">doStuff</span><span class="hljs-params">(self, rdd)</span>:</span></span><br><span class="line">        <span class="hljs-keyword">return</span> rdd.map(<span class="hljs-keyword">lambda</span> s: self.field + x)</span><br></pre></td></tr></table></figure><p>此类问题最简单的避免方法就是，使用一个本地变量缓存一份这个数据域的拷贝，直接访问这个数据域：</p><figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">doStuff</span><span class="hljs-params">(self, rdd)</span>:</span></span><br><span class="line">    field = self.field</span><br><span class="line">    <span class="hljs-keyword">return</span> rdd.map(<span class="hljs-keyword">lambda</span> s: field + x)</span><br></pre></td></tr></table></figure><h3 id="理解闭包"><a href="#理解闭包" class="headerlink" title="理解闭包"></a>理解闭包</h3><p>关于 Spark 的难点之一是理解在跨集群执行代码时变量和方法的作用域和生命周期。修改超出其作用域的 RDD 操作可能经常引起混乱。在下面的示例中，我们将介绍使用 foreach() 递增计数器的代码，其他操作也会导致类似的问题。</p><h4 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h4><p>考虑以下朴素的 RDD 元素求和，其结果可能会有所不同，具体取决于是否在同一 JVM 中进行执行。 一个常见的例子是在本地模式下运行 Spark（–master = local [n]）而不是将 Spark 应用程序部署到集群上（例如，通过将 spark-submit 提交给 YARN）：</p><figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">counter = <span class="hljs-number">0</span></span><br><span class="line">rdd = sc.parallelize(data)</span><br><span class="line"></span><br><span class="line"><span class="hljs-comment"># Wrong: Don't do this!!</span></span><br><span class="line"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">increment_counter</span><span class="hljs-params">(x)</span>:</span></span><br><span class="line">    <span class="hljs-keyword">global</span> counter</span><br><span class="line">    counter += x</span><br><span class="line">rdd.foreach(increment_counter)</span><br><span class="line"></span><br><span class="line">print(<span class="hljs-string">"Counter value: "</span>, counter)</span><br></pre></td></tr></table></figure><h4 id="本地-vs-集群模式"><a href="#本地-vs-集群模式" class="headerlink" title="本地 vs 集群模式"></a>本地 vs 集群模式</h4><p>上面的代码的行为是未定义的，可能无法按预期工作。为了执行作业，Spark 将 RDD 操作的处理分解为小任务，每个任务都由执行程序执行。在执行之前，Spark 会计算任务的结束时间。闭包是执行者在 RDD 上执行其计算所必须可见的那些变量和方法（在本例中为foreach（））。此闭包被序列化并发送给每个执行器。</p><p>发送给每个执行者的闭包中的变量现在都是副本，因此，在 foreach 函数中引用计数器时，它不再是驱动程序节点上的计数器。驱动程序节点的内存中仍然存在一个计数器，但是执行者将不再看到该计数器！执行者仅从序列化闭包中看到副本。因此，由于对计数器的所有操作都引用了序列化闭包内的值，所以计数器的最终值仍将为零。</p><p>在本地模式下，在某些情况下，foreach 函数实际上将在与驱动程序相同的 JVM 中执行，并且将引用相同的原始计数器，并且可能会对其进行实际更新。</p><p>为了确保在此类情况下行为明确，应使用累加器。 Spark 中的累加器专门用于提供一种机制，用于在集群中的各个工作节点之间拆分执行时安全地更新变量。本指南的“累加器”部分将详细讨论这些内容。</p><p>通常，闭包——像循环或局部定义的方法之类的结构，不应用于改变某些全局状态。 Spark 不定义或保证从闭包外部引用的对象的突变行为。某些执行此操作的代码可能会在本地模式下工作，但这只是偶然的情况，此类代码在分布式模式下将无法正常运行。如果需要一些全局聚合，请使用累加器。</p><h4 id="打印-RDD-的元素"><a href="#打印-RDD-的元素" class="headerlink" title="打印 RDD 的元素"></a>打印 RDD 的元素</h4><p>另一个常见用法是尝试使用 rdd.foreach(println) 或 rdd.map(println) 打印出 RDD 的元素。 在单台机器上，这将生成预期的输出并打印所有 RDD 的元素。 但是，在集群模式下，执行者正在调用 stdout 的输出现在写入执行者的 stdout，而不是驱动程序上的那个，因此驱动程序上的 stdout 不会显示这些信息！ 要在驱动程序上打印所有元素，可以使用 collect() 方法先将 RDD 带到驱动程序节点：rdd.collect().foreach(println)。 但是，这可能会导致驱动程序用尽内存，因为 collect() 将整个 RDD 提取到一台计算机上。 如果只需要打印 RDD 的一些元素，更安全的方法是使用 take()：rdd.take(100).foreach(println)。</p><h3 id="使用键值对"><a href="#使用键值对" class="headerlink" title="使用键值对"></a>使用键值对</h3><p>尽管大多数 Spark 操作可在包含任何类型的对象的 RDD 上运行，但一些特殊操作仅可用于键-值对的 RDD。 这类操作中最常见的是分布式 shuffle 操作，例如通过键对元素进行分组或聚合。</p><p>在 Python中，这些操作适用于包含内置 Python 元组（例如（1、2））的 RDD。 只需创建这样的元组，然后调用所需的操作即可。</p><p>例如，以下代码对键值对使用 reduceByKey 操作来统计文件中每一行文本出现的次数：</p><figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">lines = sc.textFile(<span class="hljs-string">"data.txt"</span>)</span><br><span class="line">pairs = lines.map(<span class="hljs-keyword">lambda</span> s: (s, <span class="hljs-number">1</span>))</span><br><span class="line">counts = pairs.reduceByKey(<span class="hljs-keyword">lambda</span> a, b: a + b)</span><br></pre></td></tr></table></figure><p>例如，我们还可以使用 counts.sortByKey() 对字母对进行排序，最后使用 counts.collect() 将它们作为对象列表返回。</p><h3 id="Transformations-操作"><a href="#Transformations-操作" class="headerlink" title="Transformations 操作"></a>Transformations 操作</h3><p>下面的表格列出了 Spark 支持的常用 Transformations 操作。详细细节，请查阅 RDD API文档（<a href="http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.rdd.RDD" target="_blank" rel="noopener">Scala</a>, <a href="http://spark.apache.org/docs/latest/api/java/index.html?org/apache/spark/api/java/JavaRDD.html" target="_blank" rel="noopener">Java</a>, <a href="http://spark.apache.org/docs/latest/api/python/pyspark.html#pyspark.RDD" target="_blank" rel="noopener">Python</a>, <a href="http://spark.apache.org/docs/latest/api/R/index.html" target="_blank" rel="noopener">R</a>）和键值对 RDD 函数文档 （<a href="http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.rdd.PairRDDFunctions" target="_blank" rel="noopener">Scala</a>, <a href="http://spark.apache.org/docs/latest/api/java/index.html?org/apache/spark/api/java/JavaPairRDD.html" target="_blank" rel="noopener">Java</a>）。</p><p>（注：次部分翻译比较简略，仅供参考，具体细节请看文档）</p><table><thead><tr><th align="left">Transformation</th><th align="left">Meaning</th></tr></thead><tbody><tr><td align="left"><strong>map</strong>(<em>func</em>)</td><td align="left">返回一个新的分布数据集，由原数据集元素经 func 处理后的结果组成</td></tr><tr><td align="left"><strong>filter</strong>(<em>func</em>)</td><td align="left">返回一个新的数据集，由传给func 返回 True 的原数据集元素组成</td></tr><tr><td align="left"><strong>flatMap</strong>(<em>func</em>)</td><td align="left">与 map 类似，但是每个传入元素可能有 0 或多个返回值，func 可以返回一个序列而不是一个值</td></tr><tr><td align="left"><strong>mapPartitions</strong>(<em>func</em>)</td><td align="left">类似 map，但是 RDD 的每个分片都会分开独立运行，所以 func 的参数和返回值必须都是迭代器</td></tr><tr><td align="left"><strong>mapPartitionsWithIndex</strong>(<em>func</em>)</td><td align="left">类似 mapParitions，但是 func 有两个参数，第一个是分片的序号，第二个是迭代器。返回值还是迭代器</td></tr><tr><td align="left"><strong>sample</strong>(<em>withReplacement</em>, <em>fraction</em>, <em>seed</em>)</td><td align="left">使用提供的随机数种子取样，然后替换或不替换</td></tr><tr><td align="left"><strong>union</strong>(<em>otherDataset</em>)</td><td align="left">返回新的数据集，包括原数据集和参数数据集的所有元素</td></tr><tr><td align="left"><strong>intersection</strong>(<em>otherDataset</em>)</td><td align="left">返回新数据集，是两个集的交集</td></tr><tr><td align="left"><strong>distinct</strong>([<em>numPartitions</em>]))</td><td align="left">返回新的集，包括原集中的不重复元素返回新的集，包括原集中的不重复元素</td></tr><tr><td align="left"><strong>groupByKey</strong>([<em>numPartitions</em>])</td><td align="left">当用于键值对 RDD 时返回 (键，值迭代器) 对的数据集</td></tr><tr><td align="left"><strong>reduceByKey</strong>(<em>func</em>, [<em>numPartitions</em>])</td><td align="left">当用于键值对 RDD 时返回 (键，值迭代器) 对的数据集。其中每个键的值使用给定的 reduce 函数进行汇总</td></tr><tr><td align="left"><strong>aggregateByKey</strong>(<em>zeroValue</em>)(<em>seqOp</em>, <em>combOp</em>, [<em>numPartitions</em>])</td><td align="left">用于键值对 RDD 时返回（K，U）对集，对每一个 Key 的 value进行聚集计算</td></tr><tr><td align="left"><strong>sortByKey</strong>([<em>ascending</em>], [<em>numPartitions</em>])</td><td align="left">用于键值对 RDD 时会返回 RDD 按键的顺序排序，升降序由第一个参数决定</td></tr><tr><td align="left"><strong>join</strong>(<em>otherDataset</em>, [<em>numPartitions</em>])</td><td align="left">用于键值对 (K, V) 和 (K, W) RDD时返回 (K, (V, W)) 对 RDD</td></tr><tr><td align="left"><strong>cogroup</strong>(<em>otherDataset</em>, [<em>numPartitions</em>])</td><td align="left">用于两个键值对RDD时返回 (K, (V 迭代器， W 迭代器)) RDD</td></tr><tr><td align="left"><strong>cartesian</strong>(<em>otherDataset</em>)</td><td align="left">用于 T 和 U 类型 RDD 时返回 (T, U) 对类型键值对 RDD</td></tr><tr><td align="left"><strong>pipe</strong>(<em>command</em>, <em>[envVars]</em>)</td><td align="left">通过 shell 命令管道处理每个 RDD 分片</td></tr><tr><td align="left"><strong>coalesce</strong>(<em>numPartitions</em>)</td><td align="left">把 RDD 的分片数量降低到参数大小</td></tr><tr><td align="left"><strong>repartition</strong>(<em>numPartitions</em>)</td><td align="left">重新打乱 RDD 中元素顺序并重新分片，数量由参数决定</td></tr><tr><td align="left"><strong>repartitionAndSortWithinPartitions</strong>(<em>partitioner</em>)</td><td align="left">按照参数给定的分片器重新分片，同时每个分片内部按照键排序</td></tr></tbody></table><h3 id="Actions-操作"><a href="#Actions-操作" class="headerlink" title="Actions 操作"></a>Actions 操作</h3><p>下面的表格列出了 Spark 支持的常用 Actions 操作。详细细节，请查阅 RDD API文档 （<a href="http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.rdd.RDD" target="_blank" rel="noopener">Scala</a>, <a href="http://spark.apache.org/docs/latest/api/java/index.html?org/apache/spark/api/java/JavaRDD.html" target="_blank" rel="noopener">Java</a>, <a href="http://spark.apache.org/docs/latest/api/python/pyspark.html#pyspark.RDD" target="_blank" rel="noopener">Python</a>, <a href="http://spark.apache.org/docs/latest/api/R/index.html" target="_blank" rel="noopener">R</a>）和键值对 RDD 函数文档 （<a href="http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.rdd.PairRDDFunctions" target="_blank" rel="noopener">Scala</a>, <a href="http://spark.apache.org/docs/latest/api/java/index.html?org/apache/spark/api/java/JavaPairRDD.html" target="_blank" rel="noopener">Java</a>）。</p><p>（注：次部分翻译比较简略，仅供参考，具体细节请看文档）</p><table><thead><tr><th align="left">Action</th><th align="left">Meaning</th></tr></thead><tbody><tr><td align="left"><strong>reduce</strong>(<em>func</em>)</td><td align="left">使用 func 进行聚合计算，func 的参数是两个，返回值一个，两次 func 运行应当是完全解耦的，这样才能正确地并行运算</td></tr><tr><td align="left"><strong>collect</strong>()</td><td align="left">向驱动程序返回数据集的元素组成的数组</td></tr><tr><td align="left"><strong>count</strong>()</td><td align="left">返回数据集元素的数量</td></tr><tr><td align="left"><strong>first</strong>()</td><td align="left">返回数据集的第一个元素</td></tr><tr><td align="left"><strong>take</strong>(<em>n</em>)</td><td align="left">返回前n个元素组成的数组</td></tr><tr><td align="left"><strong>takeSample</strong>(<em>withReplacement</em>, <em>num</em>, [<em>seed</em>])</td><td align="left">返回一个由原数据集中任意 num 个元素的数组，并且替换之</td></tr><tr><td align="left"><strong>takeOrdered</strong>(<em>n</em>, <em>[ordering]</em>)</td><td align="left">返回排序后的前 n 个元素</td></tr><tr><td align="left"><strong>saveAsTextFile</strong>(<em>path</em>)</td><td align="left">将数据集的元素写成文本文件</td></tr><tr><td align="left"><strong>saveAsSequenceFile</strong>(<em>path</em>) (Java and Scala)</td><td align="left">数据集的元素写成序列文件，这个 API 只能用于 Java 和 Scala 程序</td></tr><tr><td align="left"><strong>saveAsObjectFile</strong>(<em>path</em>) (Java and Scala)</td><td align="left">将数据集的元素使用 Java 的序列化特性写到文件中，这个 API 只能用于 Java 和 Scala 程序</td></tr><tr><td align="left"><strong>countByKey</strong>()</td><td align="left">只能用于键值对 RDD，返回一个 (K, int)  hashmap，返回每个 key 的出现次数</td></tr><tr><td align="left"><strong>foreach</strong>(<em>func</em>)</td><td align="left">对数据集的每个元素执行 func, 通常用于完成一些带有副作用的函数，比如更新累加器（见下文）或与外部存储交互等</td></tr></tbody></table><p>Spark RDD API 还展示了某些操作的异步版本，例如 foreachAsync for foreach，它们立即将FutureAction 返回给调用方，而不是在操作完成时阻塞。 这可用于管理或等待动作的异步执行。</p><h3 id="Shuffle-操作"><a href="#Shuffle-操作" class="headerlink" title="Shuffle 操作"></a>Shuffle 操作</h3><p>Spark 中的某些操作会触发一个称为 shuffle 的事件。 shuffle 是 Spark 的一种用于重新分配数据的机制，可以跨分区对数据进行不同的分组。 这通常涉及跨执行程序和机器复制数据，从而使得 shuffle 成为复杂且高代价的操作。 </p><h4 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h4><p>要了解 shuffle 期间发生的情况，我们可以考虑 reduceByKey 操作的示例。 reduceByKey 操作会生成一个新的 RDD，其中将单个键的所有值组合为一个元组——该键以及针对与该键关联的所有值执行 reduce 函数的结果。难点在于，并非每个键的所有值都必须位于同一分区，甚至同一台计算机上，但是必须将它们放在同一位置才能计算结果。</p><p>在 Spark 中，数据通常不会跨分区分布在特定操作的必要位置。在计算期间，单个任务将在单个分区上进行操作-因此，为了组织要执行的单个 reduceByKey reduce 任务的所有数据，Spark 需要执行所有操作。它必须从所有分区读取以找到所有键的所有值，然后将跨分区的值汇总在一起以计算每个键的最终结果——这称为 shuffle。</p><p>尽管新改组后的数据的每个分区中的元素集都是确定性的，分区本身的顺序也是如此，但这些元素的顺序不是确定性的。如果你希望在 shuffle 后能使数据有序，则可以使用：</p><ul><li>mapPartitions 使用例如. sorted 对每个分区进行排序</li><li>repartitionAndSortWithinPartitions 可以有效地对分区进行排序，同时进行重新分区</li><li>排序以生成全局排序的 RDD</li></ul><p>可能导致 shuffle 的操作包括重新分区操作（ <a href="http://spark.apache.org/docs/latest/rdd-programming-guide.html#RepartitionLink" target="_blank" rel="noopener">repartition</a> 和 <a href="http://spark.apache.org/docs/latest/rdd-programming-guide.html#CoalesceLink" target="_blank" rel="noopener">coalesce</a>），ByKey操作（除计数）（例如  <a href="http://spark.apache.org/docs/latest/rdd-programming-guide.html#GroupByLink" target="_blank" rel="noopener">groupByKey</a> 和 <a href="http://spark.apache.org/docs/latest/rdd-programming-guide.html#ReduceByLink" target="_blank" rel="noopener">reduceByKey</a>）以及联接操作（例如 <a href="http://spark.apache.org/docs/latest/rdd-programming-guide.html#CogroupLink" target="_blank" rel="noopener">cogroup</a> 和 <a href="http://spark.apache.org/docs/latest/rdd-programming-guide.html#JoinLink" target="_blank" rel="noopener">join</a>）。</p><h4 id="性能影响"><a href="#性能影响" class="headerlink" title="性能影响"></a>性能影响</h4><p>shuffle 是一项高代价的操作，因为它涉及磁盘 I/O，数据序列化和网络 I/O。为了组织随机数据，Spark 生成任务集——map 任务以组织数据，以及一组 reduce 任务来聚合数据。此术语来自 MapReduce，与 Spark 的 map 和reduce 操作没有直接关系。</p><p>在内部，单个 map 任务的结果会保留在内存中，直到无法容纳为止。然后，根据目标分区对它们进行排序并写入单个文件。在 reduce 方面，任务读取相关的已排序块。</p><p>某些 shuffle 操作会占用大量的堆内存，因为它们在转移它们之前或之后采用内存中的数据结构来组织记录。具体来说，reduceByKey 和a ggregateByKey 在 map 侧创建这些结构，而 ByKey 操作在 reduce 侧生成这些结构。当内存存不下数据是时，Spark 会将这些表溢出到磁盘上，从而产生磁盘 I/O 的额外开销并增加垃圾回收。</p><p>shuffle 还会在磁盘上生成大量中间文件。从 Spark 1.3 开始，将保留这些文件直到不再使用相应的 RDD 并进行垃圾回收为止。这样做是为了在重新计算沿袭时无需重新创建 shuffle 文件。如果应用程序保留了对这些 RDD 的引用，或者如果 GC 不经常启动，则垃圾回收可能仅在很长一段时间后才会发生。这意味着长时间运行的 Spark 作业可能会占用大量磁盘空间。在配置 Spark 上下文时，临时存储目录由 spark.local.dir 配置参数指定。</p><p>可以通过调整各种配置参数来调整 shuffle 行为。请参阅<a href="http://spark.apache.org/docs/latest/configuration.html" target="_blank" rel="noopener">Spark Configuration Guide</a>中的“shuffle behavior”部分。</p><h3 id="RDD-持久化"><a href="#RDD-持久化" class="headerlink" title="RDD 持久化"></a>RDD 持久化</h3><p>Spark 的一个重要功能就是将数据集持久化（或缓存）到内存中以便在多个操作中重复使用。当我们持久化一个RDD 时，每一个节点将这个 RDD 的每一个分片计算并保存到内存中以便在下次对这个数据集（或者这个数据集衍生的数据集）的计算中可以复用。这使得接下来的计算过程速度能够加快（经常能加快超过十倍的速度）。缓存是加快迭代算法和快速交互过程速度的关键工具。</p><p>你可以通过调用 persist() 或 cache() 方法来标记一个想要持久化的 RDD。在第一次被计算产生之后，它就会始终停留在节点的内存中。Spark 的缓存是具有容错性的——如果 RDD 的任意一个分片丢失了，Spark 就会依照这个RDD 产生的转化过程自动重算一遍。</p><p>另外，每一个持久化的 RDD 都有一个可变的<strong>存储级别</strong>，这个级别使得用户可以改变 RDD 持久化的储存位置。比如，你可以将数据集持久化到硬盘上，也可以将它以序列化的 Java 对象形式（节省空间）持久化到内存中，还可以将这个数据集在节点之间复制。这些存储级别都是通过向 persist() 传递一个 StorageLevel 对象（<a href="https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.storage.StorageLevel" target="_blank" rel="noopener">Scala</a>, <a href="https://spark.apache.org/docs/latest/api/java/index.html?org/apache/spark/storage/StorageLevel.html" target="_blank" rel="noopener">Java</a>, <a href="https://spark.apache.org/docs/latest/api/python/pyspark.storagelevel.StorageLevel-class.html" target="_blank" rel="noopener">Python</a>）来设置的。cache() 方法是使用默认存储等级 StorageLevel.MEMORY_ONLY（在内存中存储反序列化对象）的缩写。存储级别的所有种类请见下表：</p><table><thead><tr><th align="left">Storage Level</th><th align="left">Meaning</th></tr></thead><tbody><tr><td align="left">MEMORY_ONLY</td><td align="left">Store RDD as deserialized Java objects in the JVM. If the RDD does not fit in memory, some partitions will not be cached and will be recomputed on the fly each time they’re needed. This is the default level.</td></tr><tr><td align="left">MEMORY_AND_DISK</td><td align="left">Store RDD as deserialized Java objects in the JVM. If the RDD does not fit in memory, store the partitions that don’t fit on disk, and read them from there when they’re needed.</td></tr><tr><td align="left">MEMORY_ONLY_SER (Java and Scala)</td><td align="left">Store RDD as <em>serialized</em> Java objects (one byte array per partition). This is generally more space-efficient than deserialized objects, especially when using a <a href="http://spark.apache.org/docs/latest/tuning.html" target="_blank" rel="noopener">fast serializer</a>, but more CPU-intensive to read.</td></tr><tr><td align="left">MEMORY_AND_DISK_SER (Java and Scala)</td><td align="left">Similar to MEMORY_ONLY_SER, but spill partitions that don’t fit in memory to disk instead of recomputing them on the fly each time they’re needed.</td></tr><tr><td align="left">DISK_ONLY</td><td align="left">Store the RDD partitions only on disk.</td></tr><tr><td align="left">MEMORY_ONLY_2, MEMORY_AND_DISK_2, etc.</td><td align="left">Same as the levels above, but replicate each partition on two cluster nodes.</td></tr><tr><td align="left">OFF_HEAP (experimental)</td><td align="left">Similar to MEMORY_ONLY_SER, but store the data in <a href="http://spark.apache.org/docs/latest/configuration.html#memory-management" target="_blank" rel="noopener">off-heap memory</a>. This requires off-heap memory to be enabled.</td></tr></tbody></table><p><strong>注意</strong>：在 Python 中，储存的对象永远是通过 <a href="https://docs.python.org/2/library/pickle.html" target="_blank" rel="noopener">Pickle</a> 库序列化过的，所以设不设置序列化级别不会产生影响。在 Python 中可用的存储等级有 <code>MEMORY_ONLY</code>, <code>MEMORY_ONLY_2</code>, <code>MEMORY_AND_DISK</code>, <code>MEMORY_AND_DISK_2</code>, <code>DISK_ONLY</code>, 和 <code>DISK_ONLY_2</code>。</p><p>Spark 还会在 shuffle 操作（比如 reduceByKey）中自动储存中间数据，即使用户没有调用 persist。这是为了防止在 shuffle 过程中某个节点出错而导致的全部重算。不过如果用户打算复用某些结果 RDD，我们仍然建议用户对结果RDD手动调用 persist，而不是依赖自动持久化机制。</p><h4 id="如何选择存储级别"><a href="#如何选择存储级别" class="headerlink" title="如何选择存储级别"></a>如何选择存储级别</h4><p>Spark 的存储级别是为了提供内存使用与 CPU 效率之间的不同取舍平衡程度。我们建议用户通过考虑以下流程来选择合适的存储级别：</p><ul><li>如果你的 RDD 很适合默认的级别（MEMORY_ONLY），那么久使用默认级别吧。这是 CPU 最高效运行的选择，能够让 RDD 上的操作以最快速度运行。</li><li>否则，试试MEMORY_ONLY_SER选项并且 <a href="http://spark.apache.org/docs/latest/tuning.html" target="_blank" rel="noopener">选择一个快的序列化库</a> 来使对象的空间利用率更高，同时尽量保证访问速度足够快。</li><li>不要往硬盘上持久化，除非重算数据集的过程代价确实很昂贵，或者这个过程过滤了巨量的数据。否则，重新计算分片有可能跟读硬盘速度一样快。</li><li>如果你希望快速的错误恢复（比如用 Spark 来处理 web 应用的请求），使用复制级别。所有的存储级别都提供了重算丢失数据的完整容错机制，但是复制一份副本能省去等待重算的时间。</li></ul><h4 id="删除数据"><a href="#删除数据" class="headerlink" title="删除数据"></a>删除数据</h4><p>Spark 会自动监视每个节点的缓存使用同时使用 LRU 算法丢弃旧数据分片。如果你想手动删除某个 RDD 而不是等待它被自动删除，调用 RDD.unpersist() 方法。</p><h2 id="共享变量"><a href="#共享变量" class="headerlink" title="共享变量"></a>共享变量</h2><p>通常情况下，当一个函数传递给一个在远程集群节点上运行的 Spark 操作（比如 map 和 reduce）时，Spark 会对涉及到的变量的所有副本执行这个函数。这些变量会被复制到每个机器上，而且这个过程不会被反馈给驱动程序。通常情况下，在任务之间读写共享变量是很低效的。但是，Spark 仍然提供了有限的两种共享变量类型用于常见的使用场景：广播变量和累加器。</p><h3 id="广播变量"><a href="#广播变量" class="headerlink" title="广播变量"></a>广播变量</h3><p>广播变量允许程序员在每台机器上保持一个只读变量的缓存而不是将一个变量的拷贝传递给各个任务。它们可以被使用，比如，给每一个节点传递一份大输入数据集的拷贝是很低效的。Spark 试图使用高效的广播算法来分布广播变量，以此来降低通信花销。</p><p>Spark Actions 是通过一组阶段执行的，这些阶段由分布式 “shuffle” 操作分开。 Spark 自动广播每个阶段中任务所需的共用数据。 在运行每个任务之前，以这种方式广播的数据以序列化形式缓存并反序列化。 这意味着仅当跨多个阶段的任务需要相同数据或以反序列化形式缓存数据非常重要时，显式创建广播变量才有用。</p><p>可以通过<code>SparkContext.broadcast(v)</code>来从变量 v 创建一个广播变量。这个广播变量是 v 的一个包装，同时它的值可以功过调用<code>value</code>方法来获得。以下的代码展示了这一点：</p><figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-meta">&gt;&gt;&gt; </span>broadcastVar = sc.broadcast([<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>])</span><br><span class="line">&lt;pyspark.broadcast.Broadcast object at <span class="hljs-number">0x102789f10</span>&gt;</span><br><span class="line"></span><br><span class="line"><span class="hljs-meta">&gt;&gt;&gt; </span>broadcastVar.value</span><br><span class="line">[<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>]</span><br></pre></td></tr></table></figure><p>在广播变量被创建之后，在所有函数中都应当使用它来代替原来的变量 v，这样就可以保证 v 在节点之间只被传递一次。另外，v 变量在被广播之后不应该再被修改了，这样可以确保每一个节点上储存的广播变量的一致性（如果这个变量后来又被传输给一个新的节点）。</p><h3 id="累加器"><a href="#累加器" class="headerlink" title="累加器"></a>累加器</h3><p>累加器是在一个相关过程中只能被”累加”的变量，对这个变量的操作可以有效地被并行化。它们可以被用于实现计数器（就像在 MapReduce 过程中）或求和运算。Spark 原生支持对数字类型的累加器，程序员也可以为其他新的类型添加支持。累加器被以一个名字创建之后，会在 Spark 的 UI 中显示出来。这有助于了解计算的累进过程（注意：目前 Python 中不支持这个特性）。</p><p>可以通过<code>SparkContext.accumulator(v)</code>来从变量 v 创建一个累加器。在集群中运行的任务随后可以使用 <code>add</code> 方法或 += 操作符（在 Scala 和 Python 中）来向这个累加器中累加值。但是，他们不能读取累加器中的值。只有驱动程序可以读取累加器中的值，通过累加器的 <code>value</code> 方法。</p><p>以下的代码展示了向一个累加器中累加数组元素的过程：</p><figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-meta">&gt;&gt;&gt; </span>accum = sc.accumulator(<span class="hljs-number">0</span>)</span><br><span class="line"><span class="hljs-meta">&gt;&gt;&gt; </span>accum</span><br><span class="line">Accumulator&lt;id=<span class="hljs-number">0</span>, value=<span class="hljs-number">0</span>&gt;</span><br><span class="line"></span><br><span class="line"><span class="hljs-meta">&gt;&gt;&gt; </span>sc.parallelize([<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>]).foreach(<span class="hljs-keyword">lambda</span> x: accum.add(x))</span><br><span class="line">...</span><br><span class="line"><span class="hljs-number">10</span>/<span class="hljs-number">09</span>/<span class="hljs-number">29</span> <span class="hljs-number">18</span>:<span class="hljs-number">41</span>:<span class="hljs-number">08</span> INFO SparkContext: Tasks finished <span class="hljs-keyword">in</span> <span class="hljs-number">0.317106</span> s</span><br><span class="line"></span><br><span class="line"><span class="hljs-meta">&gt;&gt;&gt; </span>accum.value</span><br><span class="line"><span class="hljs-number">10</span></span><br></pre></td></tr></table></figure><p>这段代码利用了累加器对 int 类型的内建支持，程序员可以通过继承 <a href="https://spark.apache.org/docs/latest/api/python/pyspark.accumulators.AccumulatorParam-class.html" target="_blank" rel="noopener">AccumulatorParam</a> 类来创建自己想要的类型支持。AccumulatorParam 的接口提供了两个方法：<code>zero</code> 用于为你的数据类型提供零值；<code>addInPlace</code>用于计算两个值得和。比如，假设我们有一个<code>Vector</code>类表示数学中的向量，我们可以这样写：</p><figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">VectorAccumulatorParam</span><span class="hljs-params">(AccumulatorParam)</span>:</span></span><br><span class="line">    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">zero</span><span class="hljs-params">(self, initialValue)</span>:</span></span><br><span class="line">        <span class="hljs-keyword">return</span> Vector.zeros(initialValue.size)</span><br><span class="line"></span><br><span class="line">    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">addInPlace</span><span class="hljs-params">(self, v1, v2)</span>:</span></span><br><span class="line">        v1 += v2</span><br><span class="line">        <span class="hljs-keyword">return</span> v1</span><br><span class="line"></span><br><span class="line"><span class="hljs-comment"># Then, create an Accumulator of this type:</span></span><br><span class="line">vecAccum = sc.accumulator(Vector(...), VectorAccumulatorParam())</span><br></pre></td></tr></table></figure><p>累加器的更新操作只会被<strong>运行一次</strong>，Spark 提供了保证，每个任务中对累加器的更新操作都只会被运行一次。比如，重启一个任务不会再次更新累加器。在转化过程中，用户应该留意每个任务的更新操作在任务或作业重新运算时是否被执行了超过一次。</p><p>累加器不会改变 Spark 的惰性求值模型。如果累加器在对 RDD 的操作中被更新了，它们的值只会在 action 操作中作为 RDD 计算过程中的一部分被更新。所以，在一个懒惰的转化操作中调用累加器的更新，并没法保证会被及时运行。下面的代码段展示了这一点：</p><figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">accum = sc.accumulator(<span class="hljs-number">0</span>)</span><br><span class="line"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">g</span><span class="hljs-params">(x)</span>:</span></span><br><span class="line">    accum.add(x)</span><br><span class="line">    <span class="hljs-keyword">return</span> f(x)</span><br><span class="line">data.map(g)</span><br><span class="line"><span class="hljs-comment"># Here, accum is still 0 because no actions have caused the `map` to be computed.</span></span><br></pre></td></tr></table></figure><h2 id="在集群上部署"><a href="#在集群上部署" class="headerlink" title="在集群上部署"></a>在集群上部署</h2><p>这个<a href="https://spark.apache.org/docs/latest/submitting-applications.html" target="_blank" rel="noopener">应用提交指南</a>描述了一个应用被提交到集群上的过程。简而言之，只要你把你的应用打成了 JAR 包（ Java/Scala 应用）或 .py 文件的集合或 .zip 压缩包( Python 应用)，bin/spark-submit 脚本会将应用提交到任意支持的集群管理器上。</p><h2 id="单元测试"><a href="#单元测试" class="headerlink" title="单元测试"></a>单元测试</h2><p>Spark 对单元测试是友好的，可以与任何流行的单元测试框架相容。你只需要在测试中创建一个 <code>SparkContext</code> ，并如前文所述将 maste r的 URL 设为 local，执行你的程序，最后调用 <code>SparkContext.stop()</code> 来终止运行。请确保你在 <code>finally</code> 块或测试框架的 <code>tearDown</code> 方法中终止了上下文，因为 Spark 不支持两个上下文在一个程序中同时运行。</p><h2 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h2><p>为了给你优化代码提供帮助，<a href="https://spark.apache.org/docs/latest/configuration.html" target="_blank" rel="noopener">配置指南</a>和<a href="https://spark.apache.org/docs/latest/tuning.html" target="_blank" rel="noopener">调优指南</a>提供了关于最佳实践的一些信息。确保你的数据储存在以高效的格式储存在内存中，这很重要。为了给你部署应用提供帮助，<a href="https://spark.apache.org/docs/latest/cluster-overview.html" target="_blank" rel="noopener">集群模式概览</a>描述了许多内容，包括分布式操作和支持的集群管理器。<br>最后，完整的API文档在这里。<a href="http://spark.apache.org/docs/latest/api/scala/#org.apache.spark.package" target="_blank" rel="noopener">Scala</a>, <a href="http://spark.apache.org/docs/latest/api/java/" target="_blank" rel="noopener">Java</a>, <a href="http://spark.apache.org/docs/latest/api/python/" target="_blank" rel="noopener">Python</a> 和 <a href="http://spark.apache.org/docs/latest/api/R/" target="_blank" rel="noopener">R</a>。</p><p><a style="background-color:black;color:white;text-decoration:none;padding:4px 6px;font-family:-apple-system, BlinkMacSystemFont, &quot;San Francisco&quot;, &quot;Helvetica Neue&quot;, Helvetica, Ubuntu, Roboto, Noto, &quot;Segoe UI&quot;, Arial, sans-serif;font-size:12px;font-weight:bold;line-height:1.2;display:inline-block;border-radius:3px" href="https://unsplash.com/@sixteenmilesout?utm_medium=referral&amp;utm_campaign=photographer-credit&amp;utm_content=creditBadge" target="_blank" rel="noopener noreferrer" title="Download free do whatever you want high-resolution photos from Carolyn V"><span style="display:inline-block;padding:2px 3px"><svg xmlns="http://www.w3.org/2000/svg" style="height:12px;width:auto;position:relative;vertical-align:middle;top:-2px;fill:white" viewbox="0 0 32 32"><title>unsplash-logo</title><path d="M10 9V0h12v9H10zm12 5h10v18H0V14h10v9h12v-9z"/></svg></span><span style="display:inline-block;padding:2px 3px">Carolyn V</span></a></p>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;RDD-Programming-Guide&quot;&gt;&lt;a href=&quot;#RDD-Programming-Guide&quot; class=&quot;headerlink&quot; title=&quot;RDD Programming Guide&quot;&gt;&lt;/a&gt;RDD Programming Guide&lt;/h1&gt;&lt;p&gt;翻译自&lt;a href=&quot;http://spark.apache.org/docs/latest/rdd-programming-guide.html&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;官方文档&lt;/a&gt;，本文值翻译了部分 Python 部分。&lt;/p&gt;
&lt;h2 id=&quot;概述&quot;&gt;&lt;a href=&quot;#概述&quot; class=&quot;headerlink&quot; title=&quot;概述&quot;&gt;&lt;/a&gt;概述&lt;/h2&gt;&lt;p&gt;从高层次看，每个 Spark 应用都包含一个驱动程序，用于执行用户的 main 函数以及在集群上进行各种并行操作。Spark 提供的重要抽象是弹性分布式数据集（ &lt;em&gt;resilient distributed dataset&lt;/em&gt;），这是一个包含诸多元素、被划分到不同节点上进行并行处理的数据集。RDDs 通过打开一个 HDFS 文件（或者其他任何 hadoop 支持的文件系统）、在驱动程序中打开一个已有的 Scala 数据集或者由其他 RDD 转换得到。用户可以要求 Spark 将 RDD 持久化到内存中，这样可以有效的在并行运算中复用。另外，RDDs 在节点发生错误时会自动恢复。&lt;/p&gt;
&lt;p&gt;Spark 的另一个抽象是在并行运算中使用的共享变量。在默认情况下，当 Spark 将一个函数转化成许多任务在不同节点上运行的时候，对于所有在函数中使用的变量，每一个任务都会得到一个副本。有时，一个变量需要在任务之间或者任务和驱动程序之间共享。Spark 支持两种共享变量：广播变量，用来将一个值缓存到所有节点的内存中；累加器，只能用于累加，比如计数器和求和。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Bigdata" scheme="http://gallonhu.github.io/categories/Bigdata/"/>
    
    
      <category term="Spark" scheme="http://gallonhu.github.io/tags/Spark/"/>
    
  </entry>
  
  <entry>
    <title>markdown基本操作</title>
    <link href="http://gallonhu.github.io/posts/5df87593/"/>
    <id>http://gallonhu.github.io/posts/5df87593/</id>
    <published>2019-12-16T02:38:51.000Z</published>
    <updated>2020-01-19T03:12:38.209Z</updated>
    
    <content type="html"><![CDATA[<p><em>Markdown</em>常用的一些语法集合。</p><h2 id="数学公式及希腊字母"><a href="#数学公式及希腊字母" class="headerlink" title="数学公式及希腊字母"></a>数学公式及希腊字母</h2><h3 id="行内与独行"><a href="#行内与独行" class="headerlink" title="行内与独行"></a>行内与独行</h3><ol><li>行内公式：将公式插入到本行内，符号：<code>$公式内容$</code>，如：$xyz$</li><li>独行公式：将公式插入到新的一行内，并且居中，符号：<code>$$公式内容$$</code>，如：$$xyz$$</li></ol><a id="more"></a><h3 id="上标、下标与组合"><a href="#上标、下标与组合" class="headerlink" title="上标、下标与组合"></a>上标、下标与组合</h3><ol><li>上标符号，符号：<code>^</code>，如：$x^4$</li><li>下标符号，符号：<code>_</code>，如：$x_1$</li><li>组合符号，符号：<code>{}</code>，如：${16}<em>{8}O{2+}</em>{2}$</li></ol><h3 id="汉字、字体与格式"><a href="#汉字、字体与格式" class="headerlink" title="汉字、字体与格式"></a>汉字、字体与格式</h3><ol><li>汉字形式，符号：<code>\mbox{}</code>，如：$V_{\mbox{初始}}$</li><li>字体控制，符号：<code>\displaystyle</code>，如：$\displaystyle \frac{x+y}{y+z}$</li><li>下划线符号，符号：<code>\underline</code>，如：$\underline{x+y}$</li><li>标签，符号<code>\tag{数字}</code>，如：$\tag{11}$</li><li>上大括号，符号：<code>\overbrace{算式}</code>，如：$\overbrace{a+b+c+d}^{2.0}$</li><li>下大括号，符号：<code>\underbrace{算式}</code>，如：$a+\underbrace{b+c}_{1.0}+d$</li><li>上位符号，符号：<code>\stacrel{上位符号}{基位符号}</code>，如：$\vec{x}\stackrel{\mathrm{def}}{=}{x_1,\dots,x_n}$</li></ol><h3 id="占位符"><a href="#占位符" class="headerlink" title="占位符"></a>占位符</h3><ol><li>两个quad空格，符号：<code>\qquad</code>，如：$x \qquad y$</li><li>quad空格，符号：<code>\quad</code>，如：$x \quad y$</li><li>大空格，符号<code>\</code>，如：$x \  y$</li><li>中空格，符号<code>\:</code>，如：$x : y$</li><li>小空格，符号<code>\,</code>，如：$x , y$</li><li>没有空格，符号``，如：$xy$</li><li>紧贴，符号<code>\!</code>，如：$x ! y$</li></ol><h3 id="定界符与组合"><a href="#定界符与组合" class="headerlink" title="定界符与组合"></a>定界符与组合</h3><ol><li>括号，符号：<code>（）\big(\big) \Big(\Big) \bigg(\bigg) \Bigg(\Bigg)</code>，如：$（）\big(\big) \Big(\Big) \bigg(\bigg) \Bigg(\Bigg)$</li><li>中括号，符号：<code>[]</code>，如：$[x+y]$</li><li>大括号，符号：<code>\{ \}</code>，如：${x+y}$</li><li>自适应括号，符号：<code>\left \right</code>，如：$\left(x\right)$，$\left(x{yz}\right)$</li><li>组合公式，符号：<code>{上位公式 \choose 下位公式}</code>，如：${n+1 \choose k}={n \choose k}+{n \choose k-1}$</li><li>组合公式，符号：<code>{上位公式 \atop 下位公式}</code>，如：$\sum_{k_0,k_1,\ldots&gt;0 \atop k_0+k_1+\cdots=n}A_{k_0}A_{k_1}\cdots$</li></ol><h3 id="四则运算"><a href="#四则运算" class="headerlink" title="四则运算"></a>四则运算</h3><ol><li>加法运算，符号：<code>+</code>，如：$x+y=z$</li><li>减法运算，符号：<code>-</code>，如：$x-y=z$</li><li>加减运算，符号：<code>\pm</code>，如：$x \pm y=z$</li><li>减甲运算，符号：<code>\mp</code>，如：$x \mp y=z$</li><li>乘法运算，符号：<code>\times</code>，如：$x \times y=z$</li><li>点乘运算，符号：<code>\cdot</code>，如：$x \cdot y=z$</li><li>星乘运算，符号：<code>\ast</code>，如：$x \ast y=z$</li><li>除法运算，符号：<code>\div</code>，如：$x \div y=z$</li><li>斜法运算，符号：<code>/</code>，如：$x/y=z$</li><li>分式表示，符号：<code>\frac{分子}{分母}</code>，如：$\frac{x+y}{y+z}$</li><li>分式表示，符号：<code>{分子} \voer {分母}</code>，如：${x+y} \over {y+z}$</li><li>绝对值表示，符号：<code>||</code>，如：$|x+y|$</li></ol><h3 id="高级运算"><a href="#高级运算" class="headerlink" title="高级运算"></a>高级运算</h3><ol><li>平均数运算，符号：<code>\overline{算式}</code>，如：$\overline{xyz}$</li><li>开二次方运算，符号：<code>\sqrt</code>，如：$\sqrt x$</li><li>开方运算，符号：<code>\sqrt[开方数]{被开方数}</code>，如：$\sqrt[3]{x+y}$</li><li>对数运算，符号：<code>\log</code>，如：$\log(x)$</li><li>极限运算，符号：<code>\lim</code>，如：$\lim^{x \to \infty}_{y \to 0}{\frac{x}{y}}$</li><li>极限运算，符号：<code>\displaystyle \lim</code>，如：$\displaystyle \lim^{x \to \infty}_{y \to 0}{\frac{x}{y}}$</li><li>求和运算，符号：<code>\sum</code>，如：$\sum^{x \to \infty}_{y \to 0}{\frac{x}{y}}$</li><li>求和运算，符号：<code>\displaystyle \sum</code>，如：$\displaystyle \sum^{x \to \infty}_{y \to 0}{\frac{x}{y}}$</li><li>积分运算，符号：<code>\int</code>，如：$\int^{\infty}_{0}{xdx}$</li><li>积分运算，符号：<code>\displaystyle \int</code>，如：$\displaystyle \int^{\infty}_{0}{xdx}$</li><li>微分运算，符号：<code>\partial</code>，如：$\frac{\partial x}{\partial y}$</li><li>矩阵表示，符号：<code>\begin{matrix} \end{matrix}</code>，如：$\left[ \begin{matrix} 1 &amp;2 &amp;\cdots &amp;4\5 &amp;6 &amp;\cdots &amp;8\vdots &amp;\vdots &amp;\ddots &amp;\vdots\13 &amp;14 &amp;\cdots &amp;16\end{matrix} \right]$</li></ol><h3 id="逻辑运算"><a href="#逻辑运算" class="headerlink" title="逻辑运算"></a>逻辑运算</h3><ol><li>等于运算，符号：<code>=</code>，如：$x+y=z$</li><li>大于运算，符号：<code>&gt;</code>，如：$x+y&gt;z$</li><li>小于运算，符号：<code>&lt;</code>，如：$x+y&lt;z$</li><li>大于等于运算，符号：<code>\geq</code>，如：$x+y \geq z$</li><li>小于等于运算，符号：<code>\leq</code>，如：$x+y \leq z$</li><li>不等于运算，符号：<code>\neq</code>，如：$x+y \neq z$</li><li>不大于等于运算，符号：<code>\ngeq</code>，如：$x+y \ngeq z$</li><li>不大于等于运算，符号：<code>\not\geq</code>，如：$x+y \not\geq z$</li><li>不小于等于运算，符号：<code>\nleq</code>，如：$x+y \nleq z$</li><li>不小于等于运算，符号：<code>\not\leq</code>，如：$x+y \not\leq z$</li><li>约等于运算，符号：<code>\approx</code>，如：$x+y \approx z$</li><li>恒定等于运算，符号：<code>\equiv</code>，如：$x+y \equiv z$</li></ol><h3 id="集合运算"><a href="#集合运算" class="headerlink" title="集合运算"></a>集合运算</h3><ol><li>属于运算，符号：<code>\in</code>，如：$x \in y$</li><li>不属于运算，符号：<code>\notin</code>，如：$x \notin y$</li><li>不属于运算，符号：<code>\not\in</code>，如：$x \not\in y$</li><li>子集运算，符号：<code>\subset</code>，如：$x \subset y$</li><li>子集运算，符号：<code>\supset</code>，如：$x \supset y$</li><li>真子集运算，符号：<code>\subseteq</code>，如：$x \subseteq y$</li><li>非真子集运算，符号：<code>\subsetneq</code>，如：$x \subsetneq y$</li><li>真子集运算，符号：<code>\supseteq</code>，如：$x \supseteq y$</li><li>非真子集运算，符号：<code>\supsetneq</code>，如：$x \supsetneq y$</li><li>非子集运算，符号：<code>\not\subset</code>，如：$x \not\subset y$</li><li>非子集运算，符号：<code>\not\supset</code>，如：$x \not\supset y$</li><li>并集运算，符号：<code>\cup</code>，如：$x \cup y$</li><li>交集运算，符号：<code>\cap</code>，如：$x \cap y$</li><li>差集运算，符号：<code>\setminus</code>，如：$x \setminus y$</li><li>同或运算，符号：<code>\bigodot</code>，如：$x \bigodot y$</li><li>同与运算，符号：<code>\bigotimes</code>，如：$x \bigotimes y$</li><li>实数集合，符号：<code>\mathbb{R}</code>，如：<code>\mathbb{R}</code> </li><li>自然数集合，符号：<code>\mathbb{Z}</code>，如：<code>\mathbb{Z}</code> </li><li>空集，符号：<code>\emptyset</code>，如：$\emptyset$</li></ol><h3 id="数学符号"><a href="#数学符号" class="headerlink" title="数学符号"></a>数学符号</h3><ol><li>无穷，符号：<code>\infty</code>，如：$\infty$</li><li>虚数，符号：<code>\imath</code>，如：$\imath$</li><li>虚数，符号：<code>\jmath</code>，如：$\jmath$</li><li>数学符号，符号<code>\hat{a}</code>，如：$\hat{a}$</li><li>数学符号，符号<code>\check{a}</code>，如：$\check{a}$</li><li>数学符号，符号<code>\breve{a}</code>，如：$\breve{a}$</li><li>数学符号，符号<code>\tilde{a}</code>，如：$\tilde{a}$</li><li>数学符号，符号<code>\bar{a}</code>，如：$\bar{a}$</li><li>矢量符号，符号<code>\vec{a}</code>，如：$\vec{a}$</li><li>数学符号，符号<code>\acute{a}</code>，如：$\acute{a}$</li><li>数学符号，符号<code>\grave{a}</code>，如：$\grave{a}$</li><li>数学符号，符号<code>\mathring{a}</code>，如：$\mathring{a}$</li><li>一阶导数符号，符号<code>\dot{a}</code>，如：$\dot{a}$</li><li>二阶导数符号，符号<code>\ddot{a}</code>，如：$\ddot{a}$</li><li>上箭头，符号：<code>\uparrow</code>，如：$\uparrow$</li><li>上箭头，符号：<code>\Uparrow</code>，如：$\Uparrow$</li><li>下箭头，符号：<code>\downarrow</code>，如：$\downarrow$</li><li>下箭头，符号：<code>\Downarrow</code>，如：$\Downarrow$</li><li>左箭头，符号：<code>\leftarrow</code>，如：$\leftarrow$</li><li>左箭头，符号：<code>\Leftarrow</code>，如：$\Leftarrow$</li><li>右箭头，符号：<code>\rightarrow</code>，如：$\rightarrow$</li><li>右箭头，符号：<code>\Rightarrow</code>，如：$\Rightarrow$</li><li>底端对齐的省略号，符号：<code>\ldots</code>，如：$1,2,\ldots,n$</li><li>中线对齐的省略号，符号：<code>\cdots</code>，如：$x_1^2 + x_2^2 + \cdots + x_n^2$</li><li>竖直对齐的省略号，符号：<code>\vdots</code>，如：$\vdots$</li><li>斜对齐的省略号，符号：<code>\ddots</code>，如：$\ddots$</li></ol><h3 id="希腊字母"><a href="#希腊字母" class="headerlink" title="希腊字母"></a>希腊字母</h3><table><thead><tr><th>字母</th><th>实现</th><th>字母</th><th>实现</th></tr></thead><tbody><tr><td>A</td><td><code>A</code></td><td>α</td><td><code>\alhpa</code></td></tr><tr><td>B</td><td><code>B</code></td><td>β</td><td><code>\beta</code></td></tr><tr><td>Γ</td><td><code>\Gamma</code></td><td>γ</td><td><code>\gamma</code></td></tr><tr><td>Δ</td><td><code>\Delta</code></td><td>δ</td><td><code>\delta</code></td></tr><tr><td>E</td><td><code>E</code></td><td>ϵ</td><td><code>\epsilon</code></td></tr><tr><td>Z</td><td><code>Z</code></td><td>ζ</td><td><code>\zeta</code></td></tr><tr><td>H</td><td><code>H</code></td><td>η</td><td><code>\eta</code></td></tr><tr><td>Θ</td><td><code>\Theta</code></td><td>θ</td><td><code>\theta</code></td></tr><tr><td>I</td><td><code>I</code></td><td>ι</td><td><code>\iota</code></td></tr><tr><td>K</td><td><code>K</code></td><td>κ</td><td><code>\kappa</code></td></tr><tr><td>Λ</td><td><code>\Lambda</code></td><td>λ</td><td><code>\lambda</code></td></tr><tr><td>M</td><td><code>M</code></td><td>μ</td><td><code>\mu</code></td></tr><tr><td>N</td><td><code>N</code></td><td>ν</td><td><code>\nu</code></td></tr><tr><td>Ξ</td><td><code>\Xi</code></td><td>ξ</td><td><code>\xi</code></td></tr><tr><td>O</td><td><code>O</code></td><td>ο</td><td><code>\omicron</code></td></tr><tr><td>Π</td><td><code>\Pi</code></td><td>π</td><td><code>\pi</code></td></tr><tr><td>P</td><td><code>P</code></td><td>ρ</td><td><code>\rho</code></td></tr><tr><td>Σ</td><td><code>\Sigma</code></td><td>σ</td><td><code>\sigma</code></td></tr><tr><td>T</td><td><code>T</code></td><td>τ</td><td><code>\tau</code></td></tr><tr><td>Υ</td><td><code>\Upsilon</code></td><td>υ</td><td><code>\upsilon</code></td></tr><tr><td>Φ</td><td><code>\Phi</code></td><td>ϕ</td><td><code>\phi</code></td></tr><tr><td>X</td><td><code>X</code></td><td>χ</td><td><code>\chi</code></td></tr><tr><td>Ψ</td><td><code>\Psi</code></td><td>ψ</td><td><code>\psi</code></td></tr><tr><td>Ω</td><td><code>\v</code></td><td>ω</td><td><code>\omega</code></td></tr></tbody></table><h2 id="流程图"><a href="#流程图" class="headerlink" title="流程图"></a>流程图</h2><h3 id="横向流程图源码格式"><a href="#横向流程图源码格式" class="headerlink" title="横向流程图源码格式:"></a>横向流程图源码格式:</h3><figure class="highlight plain hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">graph LR</span><br><span class="line">A[方形] --&gt; B(圆角)</span><br><span class="line">    B --&gt; C&#123;条件a&#125;</span><br><span class="line">    C --&gt; |a&#x3D;1| D[结果1]</span><br><span class="line">    C --&gt; |a&#x3D;2| E[结果2]</span><br><span class="line">    F[横向流程图]</span><br></pre></td></tr></table></figure><figure class="highlight plain hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">graph LR</span><br><span class="line">A[方形] --&gt; B(圆角)</span><br><span class="line">    B --&gt; C&#123;条件a&#125;</span><br><span class="line">    C --&gt; |a&#x3D;1| D[结果1]</span><br><span class="line">    C --&gt; |a&#x3D;2| E[结果2]</span><br><span class="line">    F[横向流程图]</span><br></pre></td></tr></table></figure><h3 id="竖向流程图源码格式"><a href="#竖向流程图源码格式" class="headerlink" title="竖向流程图源码格式:"></a>竖向流程图源码格式:</h3><figure class="highlight plain hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">graph TD</span><br><span class="line">A[方形] --&gt; B(圆角)</span><br><span class="line">    B --&gt; C&#123;条件a&#125;</span><br><span class="line">    C --&gt; |a&#x3D;1| D[结果1]</span><br><span class="line">    C --&gt; |a&#x3D;2| E[结果2]</span><br><span class="line">    F[竖向流程图]</span><br></pre></td></tr></table></figure><figure class="highlight plain hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">graph TD</span><br><span class="line">A[方形] --&gt; B(圆角)</span><br><span class="line">    B --&gt; C&#123;条件a&#125;</span><br><span class="line">    C --&gt; |a&#x3D;1| D[结果1]</span><br><span class="line">    C --&gt; |a&#x3D;2| E[结果2]</span><br><span class="line">    F[竖向流程图]</span><br></pre></td></tr></table></figure><h3 id="标准流程图源码格式"><a href="#标准流程图源码格式" class="headerlink" title="标准流程图源码格式:"></a>标准流程图源码格式:</h3><figure class="highlight plain hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">graph TD</span><br><span class="line">A[方形] --&gt; B(圆角)</span><br><span class="line">    B --&gt; C&#123;条件a&#125;</span><br><span class="line">    C --&gt; |a&#x3D;1| D[结果1]</span><br><span class="line">    C --&gt; |a&#x3D;2| E[结果2]</span><br><span class="line">    F[竖向流程图]</span><br></pre></td></tr></table></figure><figure class="highlight plain hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">st&#x3D;&gt;start: 开始框</span><br><span class="line">op&#x3D;&gt;operation: 处理框</span><br><span class="line">cond&#x3D;&gt;condition: 判断框</span><br><span class="line">sub1&#x3D;&gt;subroutine: 子流程</span><br><span class="line">io&#x3D;&gt;inputoutput: 输入输出框</span><br><span class="line">e&#x3D;&gt;end: 结束框</span><br><span class="line">st-&gt;op-&gt;cond</span><br><span class="line">cond(yes)-&gt;io-&gt;e</span><br><span class="line">cond(no)-&gt;sub1(right)-&gt;op</span><br></pre></td></tr></table></figure><h3 id="标准流程图源码格式-横向"><a href="#标准流程图源码格式-横向" class="headerlink" title="标准流程图源码格式(横向):"></a>标准流程图源码格式(横向):</h3><figure class="highlight plain hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">st&#x3D;&gt;start: 开始框</span><br><span class="line">op&#x3D;&gt;operation: 处理框</span><br><span class="line">cond&#x3D;&gt;condition: 判断框(是或否?)</span><br><span class="line">sub1&#x3D;&gt;subroutine: 子流程</span><br><span class="line">io&#x3D;&gt;inputoutput: 输入输出框</span><br><span class="line">e&#x3D;&gt;end: 结束框</span><br><span class="line">st(right)-&gt;op(right)-&gt;cond</span><br><span class="line">cond(yes)-&gt;io(bottom)-&gt;e</span><br><span class="line">cond(no)-&gt;sub1(right)-&gt;op</span><br></pre></td></tr></table></figure><figure class="highlight plain hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">st&#x3D;&gt;start: 开始框</span><br><span class="line">op&#x3D;&gt;operation: 处理框</span><br><span class="line">cond&#x3D;&gt;condition: 判断框(是或否?)</span><br><span class="line">sub1&#x3D;&gt;subroutine: 子流程</span><br><span class="line">io&#x3D;&gt;inputoutput: 输入输出框</span><br><span class="line">e&#x3D;&gt;end: 结束框</span><br><span class="line">st(right)-&gt;op(right)-&gt;cond</span><br><span class="line">cond(yes)-&gt;io(bottom)-&gt;e</span><br><span class="line">cond(no)-&gt;sub1(right)-&gt;op</span><br></pre></td></tr></table></figure><h3 id="UML时序图源码样例"><a href="#UML时序图源码样例" class="headerlink" title="UML时序图源码样例:"></a>UML时序图源码样例:</h3><figure class="highlight plain hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">对象A-&gt;对象B: 对象B你好吗? (请求)</span><br><span class="line">Note right of 对象B: 对象B的描述</span><br><span class="line">Note left of 对象A: 对象A的描述(提示)</span><br><span class="line">对象B --&gt; 对象A: 我很好(响应)</span><br><span class="line">对象A --&gt; 对象B: 你真的好吗?</span><br></pre></td></tr></table></figure><figure class="highlight plain hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">对象A-&gt;对象B: 对象B你好吗? (请求)</span><br><span class="line">Note right of 对象B: 对象B的描述</span><br><span class="line">Note left of 对象A: 对象A的描述(提示)</span><br><span class="line">对象B --&gt; 对象A: 我很好(响应)</span><br><span class="line">对象A --&gt; 对象B: 你真的好吗?</span><br></pre></td></tr></table></figure><h3 id="UML时序图源码复杂样例"><a href="#UML时序图源码复杂样例" class="headerlink" title="UML时序图源码复杂样例:"></a>UML时序图源码复杂样例:</h3><figure class="highlight plain hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">Title: 标题: 复杂使用</span><br><span class="line">对象A -&gt; 对象B: 对象B你好吗? (请求)</span><br><span class="line">Note right of 对象B: 对象B的描述</span><br><span class="line">Note right of 对象A: 对象A的描述(提示)</span><br><span class="line">对象B --&gt; 对象A: 我很好(响应)</span><br><span class="line">对象B --&gt; 小三: 你好吗?</span><br><span class="line">小三 -&gt; 对象A: 对象B找我了</span><br><span class="line">对象A --&gt; 对象B: 你真的好吗?</span><br><span class="line">Note over 小三, 对象B: 我们是朋友</span><br><span class="line">participant C</span><br><span class="line">Note right of C: 没人陪我玩</span><br></pre></td></tr></table></figure><figure class="highlight plain hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">Title: 标题: 复杂使用</span><br><span class="line">对象A -&gt; 对象B: 对象B你好吗? (请求)</span><br><span class="line">Note right of 对象B: 对象B的描述</span><br><span class="line">Note right of 对象A: 对象A的描述(提示)</span><br><span class="line">对象B --&gt; 对象A: 我很好(响应)</span><br><span class="line">对象B --&gt; 小三: 你好吗?</span><br><span class="line">小三 -&gt; 对象A: 对象B找我了</span><br><span class="line">对象A --&gt; 对象B: 你真的好吗?</span><br><span class="line">Note over 小三, 对象B: 我们是朋友</span><br><span class="line">participant C</span><br><span class="line">Note right of C: 没人陪我玩</span><br></pre></td></tr></table></figure><h3 id="UML标准时序图样例"><a href="#UML标准时序图样例" class="headerlink" title="UML标准时序图样例:"></a>UML标准时序图样例:</h3><figure class="highlight plain hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">%%时序图例子, -&gt; 实线, --&gt; 虚线, -&gt;&gt; 实线箭头</span><br><span class="line">    sequenceDiagram</span><br><span class="line">        participant 张三</span><br><span class="line">        participant 李四</span><br><span class="line">        张三 -&gt; 王五: 王五你好吗?</span><br><span class="line">        loop 健康检查</span><br><span class="line">            王五 -&gt; 王五: 与疾病战斗</span><br><span class="line">        end</span><br><span class="line">        Note right of 王五: 合理饮食 &lt;br&#x2F;&gt;看医生...</span><br><span class="line">        李四 -&gt;&gt; 张三: 很好!</span><br><span class="line">        王五 -&gt; 李四: 你怎么样?</span><br><span class="line">        李四 --&gt; 王五: 很好!</span><br></pre></td></tr></table></figure><figure class="highlight plain hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">%%时序图例子, -&gt; 实线, --&gt; 虚线, -&gt;&gt; 实线箭头</span><br><span class="line">    sequenceDiagram</span><br><span class="line">        participant 张三</span><br><span class="line">        participant 李四</span><br><span class="line">        张三 -&gt; 王五: 王五你好吗?</span><br><span class="line">        loop 健康检查</span><br><span class="line">            王五 -&gt; 王五: 与疾病战斗</span><br><span class="line">        end</span><br><span class="line">        Note right of 王五: 合理饮食 &lt;br&#x2F;&gt;看医生...</span><br><span class="line">        李四 -&gt;&gt; 张三: 很好!</span><br><span class="line">        王五 -&gt; 李四: 你怎么样?</span><br><span class="line">        李四 --&gt; 王五: 很好!</span><br></pre></td></tr></table></figure><h3 id="甘特图样例"><a href="#甘特图样例" class="headerlink" title="甘特图样例:"></a>甘特图样例:</h3><figure class="highlight plain hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">%%语法示例</span><br><span class="line">    gantt</span><br><span class="line">    dateFormat YYYY-MM-DD</span><br><span class="line">    title 软件开发甘特图</span><br><span class="line">    </span><br><span class="line">    section 设计</span><br><span class="line">    需求  :done, des1, 2014-01-06, 2014-01-08</span><br><span class="line">    原型  :active, des2, 2014-01-09, 3d</span><br><span class="line">    UI设计    :des3, after des2, 5d</span><br><span class="line">    未来任务:   :des4, after des3, 5d</span><br><span class="line">    </span><br><span class="line">    section 开发</span><br><span class="line">    学习准备理解需求    :crit, done, 2014-01-06, 24h</span><br><span class="line">    设计框架    :crit, done, after des2, 2d</span><br><span class="line">    开发  :crit, active, 3d</span><br><span class="line">    未来任务    :crit, 5d</span><br><span class="line">    耍   :2d</span><br><span class="line">    </span><br><span class="line">    section 测试</span><br><span class="line">    功能测试    :active, a1, after des3, 3d</span><br><span class="line">    压力测试    :after a1, 20h</span><br><span class="line">    测试报告    :48h</span><br></pre></td></tr></table></figure><figure class="highlight plain hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">%%语法示例</span><br><span class="line">    gantt</span><br><span class="line">    dateFormat YYYY-MM-DD</span><br><span class="line">    title 软件开发甘特图</span><br><span class="line">    </span><br><span class="line">    section 设计</span><br><span class="line">    需求  :done, des1, 2014-01-06, 2014-01-08</span><br><span class="line">    原型  :active, des2, 2014-01-09, 3d</span><br><span class="line">    UI设计    :des3, after des2, 5d</span><br><span class="line">    未来任务:   :des4, after des3, 5d</span><br><span class="line">    </span><br><span class="line">    section 开发</span><br><span class="line">    学习准备理解需求    :crit, done, 2014-01-06, 24h</span><br><span class="line">    设计框架    :crit, done, after des2, 2d</span><br><span class="line">    开发  :crit, active, 3d</span><br><span class="line">    未来任务    :crit, 5d</span><br><span class="line">    耍   :2d</span><br><span class="line">    </span><br><span class="line">    section 测试</span><br><span class="line">    功能测试    :active, a1, after des3, 3d</span><br><span class="line">    压力测试    :after a1, 20h</span><br><span class="line">    测试报告    :48h</span><br></pre></td></tr></table></figure><h2 id="typora-快捷键"><a href="#typora-快捷键" class="headerlink" title="typora 快捷键"></a>typora 快捷键</h2><img src="https://cdn.jsdelivr.net/gh/GallonHu/pic@master/screenshot/markdown-keyboard.png" style="zoom:80%;"><img src="https://cdn.jsdelivr.net/gh/GallonHu/pic@master/screenshot/markdown-keyboard1.png" style="zoom:80%;"><p><a style="background-color:black;color:white;text-decoration:none;padding:4px 6px;font-family:-apple-system, BlinkMacSystemFont, &quot;San Francisco&quot;, &quot;Helvetica Neue&quot;, Helvetica, Ubuntu, Roboto, Noto, &quot;Segoe UI&quot;, Arial, sans-serif;font-size:12px;font-weight:bold;line-height:1.2;display:inline-block;border-radius:3px" href="https://unsplash.com/@kevinmueller?utm_medium=referral&amp;utm_campaign=photographer-credit&amp;utm_content=creditBadge" target="_blank" rel="noopener noreferrer" title="Download free do whatever you want high-resolution photos from Kevin Mueller"><span style="display:inline-block;padding:2px 3px"><svg xmlns="http://www.w3.org/2000/svg" style="height:12px;width:auto;position:relative;vertical-align:middle;top:-2px;fill:white" viewbox="0 0 32 32"><title>unsplash-logo</title><path d="M10 9V0h12v9H10zm12 5h10v18H0V14h10v9h12v-9z"/></svg></span><span style="display:inline-block;padding:2px 3px">Kevin Mueller</span></a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;em&gt;Markdown&lt;/em&gt;常用的一些语法集合。&lt;/p&gt;
&lt;h2 id=&quot;数学公式及希腊字母&quot;&gt;&lt;a href=&quot;#数学公式及希腊字母&quot; class=&quot;headerlink&quot; title=&quot;数学公式及希腊字母&quot;&gt;&lt;/a&gt;数学公式及希腊字母&lt;/h2&gt;&lt;h3 id=&quot;行内与独行&quot;&gt;&lt;a href=&quot;#行内与独行&quot; class=&quot;headerlink&quot; title=&quot;行内与独行&quot;&gt;&lt;/a&gt;行内与独行&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;行内公式：将公式插入到本行内，符号：&lt;code&gt;$公式内容$&lt;/code&gt;，如：$xyz$&lt;/li&gt;
&lt;li&gt;独行公式：将公式插入到新的一行内，并且居中，符号：&lt;code&gt;$$公式内容$$&lt;/code&gt;，如：$$xyz$$&lt;/li&gt;
&lt;/ol&gt;
    
    </summary>
    
    
      <category term="Tutorials" scheme="http://gallonhu.github.io/categories/Tutorials/"/>
    
    
      <category term="Markdown" scheme="http://gallonhu.github.io/tags/Markdown/"/>
    
  </entry>
  
  <entry>
    <title>python配置</title>
    <link href="http://gallonhu.github.io/posts/8b7d2b6d/"/>
    <id>http://gallonhu.github.io/posts/8b7d2b6d/</id>
    <published>2019-12-16T02:33:49.000Z</published>
    <updated>2019-12-16T03:23:10.413Z</updated>
    
    <content type="html"><![CDATA[<p>记录 python 的一些基本常用配置，方便以后使用。</p><a id="more"></a><h2 id="pip"><a href="#pip" class="headerlink" title="pip"></a>pip</h2><h3 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h3><figure class="highlight bash hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo apt install python3-pip</span><br></pre></td></tr></table></figure><h3 id="升级"><a href="#升级" class="headerlink" title="升级"></a>升级</h3><figure class="highlight bash hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ python -m pip install -U pip</span><br></pre></td></tr></table></figure><h3 id="错误处理"><a href="#错误处理" class="headerlink" title="错误处理"></a>错误处理</h3><p>报错1</p><figure class="highlight plain hljs"><figcaption><span>pip has no attribute 'main'</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">module pip has no attribute &#39;main&#39;</span><br></pre></td></tr></table></figure><p>解决</p><figure class="highlight plain hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">修改 &#x2F;usr&#x2F;bin&#x2F;pip下 import pip 为 import pip._internal</span><br></pre></td></tr></table></figure><p>报错2</p><figure class="highlight plain hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">locale.Error: unsupported locale setting</span><br></pre></td></tr></table></figure><p>解决</p><figure class="highlight bash hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="hljs-built_in">export</span> LC_ALL=<span class="hljs-string">"en_US.UTF-8"</span></span><br><span class="line">$ <span class="hljs-built_in">export</span> LC_CTYPE=<span class="hljs-string">"en_US.UTF-8"</span></span><br><span class="line">$ sudo dpkg-reconfigure locales</span><br></pre></td></tr></table></figure><h3 id="换源"><a href="#换源" class="headerlink" title="换源"></a>换源</h3><figure class="highlight bash hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">$ pip3 config <span class="hljs-built_in">set</span> global.index-url https://mirrors.aliyun.com/pypi/simple/</span><br><span class="line"></span><br><span class="line">常用源</span><br><span class="line">豆瓣 https://pypi.doubanio.com/simple/</span><br><span class="line">网易 https://mirrors.163.com/pypi/simple/</span><br><span class="line">阿里云 https://mirrors.aliyun.com/pypi/simple/</span><br><span class="line">清华大学 https://pypi.tuna.tsinghua.edu.cn/simple/</span><br></pre></td></tr></table></figure><h2 id="virtualenv-amp-virtualenvwrapper"><a href="#virtualenv-amp-virtualenvwrapper" class="headerlink" title="virtualenv &amp; virtualenvwrapper"></a>virtualenv &amp; virtualenvwrapper</h2><h3 id="安装-1"><a href="#安装-1" class="headerlink" title="安装"></a>安装</h3><figure class="highlight bash hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ pip3 install virtualenv</span><br><span class="line">$ pip3 install virtualenvwrapper <span class="hljs-comment"># linux &amp; mac</span></span><br><span class="line">$ pip3 install virtualenvwrapper-win <span class="hljs-comment"># win</span></span><br></pre></td></tr></table></figure><h3 id="添加环境变量"><a href="#添加环境变量" class="headerlink" title="添加环境变量"></a>添加环境变量</h3><p>linux&amp;mac下默认编辑.bashrc，若使用zsh，则编辑.zshrc，添加</p><figure class="highlight zsh hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-built_in">export</span> WORKON_HOME=<span class="hljs-variable">$HOME</span>/.virtualenvs <span class="hljs-comment"># 虚拟环境的安装位置</span></span><br><span class="line"><span class="hljs-built_in">export</span> VIRTUALENVWRAPPER_PYTHON=/usr/bin/python3 <span class="hljs-comment"># 默认创建python的版本位置</span></span><br><span class="line"><span class="hljs-built_in">source</span> /usr/<span class="hljs-built_in">local</span>/bin/virtualenvwrapper.sh <span class="hljs-comment"># virtualenvwrapper的位置，可用which命令查找</span></span><br><span class="line">(或者~/.<span class="hljs-built_in">local</span>/bin/virtualenvwrapper.sh)</span><br></pre></td></tr></table></figure><p>最后soucre文件生效</p><figure class="highlight bash hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="hljs-built_in">source</span> .bashrc &amp;</span><br><span class="line">$ <span class="hljs-built_in">source</span> .zshrc</span><br></pre></td></tr></table></figure><p>win下直接添加环境变量</p><p>WORKON_HOME</p><h3 id="常用的管理命令"><a href="#常用的管理命令" class="headerlink" title="常用的管理命令"></a>常用的管理命令</h3><figure class="highlight bash hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">创建虚拟环境：mkvirtualenv new_env</span><br><span class="line">使用虚拟环境：workon new_env</span><br><span class="line">退出虚拟环境：deactivate</span><br><span class="line">删除虚拟环境: rmvirtualenv new_env</span><br><span class="line">查看所有虚拟环境：lsvirtualenv</span><br></pre></td></tr></table></figure><h2 id="jupyter"><a href="#jupyter" class="headerlink" title="jupyter"></a>jupyter</h2><h3 id="服务器远程访问配置"><a href="#服务器远程访问配置" class="headerlink" title="服务器远程访问配置"></a>服务器远程访问配置</h3><h4 id="生成配置文件"><a href="#生成配置文件" class="headerlink" title="生成配置文件"></a>生成配置文件</h4><figure class="highlight bash hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ jupyter notebook --generate-config 生成/查看配置文件路径</span><br></pre></td></tr></table></figure><h4 id="生成密码"><a href="#生成密码" class="headerlink" title="生成密码"></a>生成密码</h4><p>打开<code>ipython</code>，创建一个密文的密码：</p><figure class="highlight plain hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">In [1]: from notebook.auth import passwd</span><br><span class="line">In [2]: passwd()</span><br><span class="line">Enter password: </span><br><span class="line">Verify password: </span><br><span class="line">Out[2]: &#39;sha1:ce23d945972f:34769685a7ccd3d08c84a18c63968a41f1140274&#39;</span><br></pre></td></tr></table></figure><h4 id="修改默认配置文件"><a href="#修改默认配置文件" class="headerlink" title="修改默认配置文件"></a>修改默认配置文件</h4><figure class="highlight bash hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ vim ~/.jupyter/jupyter_notebook_config.py</span><br></pre></td></tr></table></figure><p>进行如下修改：</p><figure class="highlight plain hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">c.NotebookApp.ip&#x3D;&#39;*&#39;</span><br><span class="line">c.NotebookApp.password &#x3D; u&#39;sha:ce...刚才复制的那个密文&#39;</span><br><span class="line">c.NotebookApp.open_browser &#x3D; False</span><br><span class="line">c.NotebookApp.port &#x3D;8888 #随便指定一个端口</span><br></pre></td></tr></table></figure><h3 id="添加-kernel"><a href="#添加-kernel" class="headerlink" title="添加 kernel"></a>添加 kernel</h3><figure class="highlight shell hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> 在想要添加的 python 虚拟环境下</span></span><br><span class="line">pip3 install ipykernel</span><br><span class="line">python -m ipykernel install --name kernelname</span><br><span class="line"></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> 查看所有 kernel</span></span><br><span class="line">jupyter kernelspec list</span><br><span class="line"></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> 删除 kernel</span></span><br><span class="line">jupyter kernelspec remove kernelname</span><br></pre></td></tr></table></figure><h3 id="后台运行"><a href="#后台运行" class="headerlink" title="后台运行"></a>后台运行</h3><figure class="highlight shell hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> 入门级</span></span><br><span class="line">jupyter notebook --allow-root &gt; jupyter.log 2&gt;&amp;1 &amp;</span><br><span class="line"></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> 进阶版</span></span><br><span class="line">nohup jupyter notebook --allow-root &gt; jupyter.log 2&gt;&amp;1 &amp;</span><br><span class="line"></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> 用 &amp; 让命令后台运行, 并把标准输出写入 jupyter.log 中</span></span><br><span class="line"><span class="hljs-meta">#</span><span class="hljs-bash"> nohup 表示 no hang up, 就是不挂起, 于是这个命令执行后即使终端退出, 也不会停止运行.</span></span><br></pre></td></tr></table></figure><p><strong>终止进程</strong></p><p>执行上面第 2 条命令, 可以发现关闭终端重新打开后, 用 jobs 找不到 jupyter 这个进程了, 于是要用 ps -a, 可以显示这个进程的 pid.<br>kill -9 pid 终止进程</p><h3 id="扩展插件"><a href="#扩展插件" class="headerlink" title="扩展插件"></a>扩展插件</h3><figure class="highlight bash hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ pip3 install jupyter_contrib_nbextensions</span><br></pre></td></tr></table></figure><p>设置自动计算每个cell运行时间</p><figure class="highlight bash hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ jupyter contrib nbextension install --user</span><br><span class="line">$ jupyter nbextension <span class="hljs-built_in">enable</span> execute_time/ExecuteTime</span><br></pre></td></tr></table></figure><h3 id="更换主题"><a href="#更换主题" class="headerlink" title="更换主题"></a>更换主题</h3><figure class="highlight bash hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ pip3 install jupyterthemes</span><br></pre></td></tr></table></figure><p>查看可选主题</p><figure class="highlight bash hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ jt<span class="hljs-_">-l</span></span><br></pre></td></tr></table></figure><p>设置主题</p><figure class="highlight bash hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ jt-t</span><br></pre></td></tr></table></figure><h3 id="其他奇技"><a href="#其他奇技" class="headerlink" title="其他奇技"></a>其他奇技</h3><p>参考<a href="https://www.zhihu.com/question/266988943" target="_blank" rel="noopener">知乎回答</a></p><p><a style="background-color:black;color:white;text-decoration:none;padding:4px 6px;font-family:-apple-system, BlinkMacSystemFont, &quot;San Francisco&quot;, &quot;Helvetica Neue&quot;, Helvetica, Ubuntu, Roboto, Noto, &quot;Segoe UI&quot;, Arial, sans-serif;font-size:12px;font-weight:bold;line-height:1.2;display:inline-block;border-radius:3px" href="https://unsplash.com/@zacwolff?utm_medium=referral&amp;utm_campaign=photographer-credit&amp;utm_content=creditBadge" target="_blank" rel="noopener noreferrer" title="Download free do whatever you want high-resolution photos from Zac Wolff"><span style="display:inline-block;padding:2px 3px"><svg xmlns="http://www.w3.org/2000/svg" style="height:12px;width:auto;position:relative;vertical-align:middle;top:-2px;fill:white" viewbox="0 0 32 32"><title>unsplash-logo</title><path d="M10 9V0h12v9H10zm12 5h10v18H0V14h10v9h12v-9z"/></svg></span><span style="display:inline-block;padding:2px 3px">Zac Wolff</span></a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;记录 python 的一些基本常用配置，方便以后使用。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Tutorials" scheme="http://gallonhu.github.io/categories/Tutorials/"/>
    
    
      <category term="Python" scheme="http://gallonhu.github.io/tags/Python/"/>
    
      <category term="Jupyter" scheme="http://gallonhu.github.io/tags/Jupyter/"/>
    
      <category term="Virtualenv" scheme="http://gallonhu.github.io/tags/Virtualenv/"/>
    
  </entry>
  
  <entry>
    <title>hexo&amp;icuras配置指南</title>
    <link href="http://gallonhu.github.io/posts/684e7cbb/"/>
    <id>http://gallonhu.github.io/posts/684e7cbb/</id>
    <published>2019-12-11T03:46:54.000Z</published>
    <updated>2020-01-19T02:42:25.689Z</updated>
    
    <content type="html"><![CDATA[<p>使用 <em>hexo</em> 写了大概一年左右的博客，期间参考网上各种教程给博客来了个大装修。但就像是做衣服，使用不同的布料，缝缝补补给生硬凑出来的一样，最终成了四不像。非但如此，因为各种插件和没用的渲染，博客的打开速度简直惨不忍睹。</p><p>所以，打算翻新一下，从头开始再搭一个。这次的原则就是简洁，不再搞那些没用的花里胡哨的东西。配置过程记录如下。所有的配置文件在 <a href="https://github.com/GallonHu/blog-config" target="_blank" rel="noopener">github仓库</a>。</p><a id="more"></a><h2 id="基础篇"><a href="#基础篇" class="headerlink" title="基础篇"></a>基础篇</h2><p><a href="https://hexo.io/" target="_blank" rel="noopener">hexo</a> 是一个开源的静态博客框架，基本开箱即用。安装见官网。</p><p>站点的配置文件在博客的根目录下的 <code>_config.yml</code> 文件中，具体各个字段的意义以及配置方法参见 <a href="https://hexo.io/docs/configuration" target="_blank" rel="noopener">hexo官网</a></p><h3 id="主题配置"><a href="#主题配置" class="headerlink" title="主题配置"></a>主题配置</h3><p>体验了蛮多的 <em>hexo</em> 主题，最终挑选了 <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">icarus</a>。</p><p>主要的原因是：</p><ol><li>界面简洁，适配各个终端</li><li>集成度高，内置的插件基本满足日常使用</li><li>开发团队较为活跃，目前还在持续更新</li></ol><p>主题的配置基本都在 <code>themes/icarus/_config.yml</code> 文件中。</p><p>默认的主题配置包含以下内容：</p><ul><li>站点首选项和页面元数据</li><li>顶部导航栏链接</li><li>底部页脚链接</li><li>文章显示设置</li><li>评论、分享和搜索插件设置</li><li>侧边小部件设置</li><li>其他显示和分析插件</li><li>CDN 设置</li></ul><p>参见各字段的含义进行配置即可。</p><h3 id="使用技巧"><a href="#使用技巧" class="headerlink" title="使用技巧"></a>使用技巧</h3><h4 id="阅读更多"><a href="#阅读更多" class="headerlink" title="阅读更多"></a>阅读更多</h4><p>在你的文章中添加 <code>&lt;!-- more --&gt;</code> 标签。该标签之前的帖子内容将被标记为摘录，而该标签之后的内容将不会显示在索引页面上。</p><p><strong>效果</strong></p><div align="center"><img src=" https://cdn.jsdelivr.net/gh/GallonHu/pic@master/screenshot/Screen-Shot-2019-12-13-at-9.57.09-AM.jpg" style="zoom:33%;"></div>#### 添加缩略图<p>在配置文件中启用缩略图（默认启用）</p><figure class="highlight yaml hljs"><figcaption><span>_config.yml</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-attr">article:</span></span><br><span class="line">    <span class="hljs-attr">thumbnail:</span> <span class="hljs-literal">true</span></span><br></pre></td></tr></table></figure><p>然后，在文章的开头提供URL或图像文件的路径</p><figure class="highlight markdown hljs"><figcaption><span>post.md</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">title: your title</span><br><span class="line">thumbnail: /gallery/thumbnails/desert.jpg</span><br><span class="line">---</span><br><span class="line">Post content...</span><br></pre></td></tr></table></figure><p><strong>图片路径</strong></p><p>图片的路径应该是相对于站点目录的相对路径。举例来说，如果你想用下面的图片来当作缩略图</p><figure class="highlight plain hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&lt;your blog&gt;&#x2F;source&#x2F;gallery&#x2F;image.jpg</span><br></pre></td></tr></table></figure><p>你需要使用如下的图片路径</p><figure class="highlight plain hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;gallery&#x2F;image.jpg</span><br></pre></td></tr></table></figure><p>另外，建议你将所有图片放在 <code>_posts</code> 文件夹中的 <code>asset</code> 文件夹下。</p><p><strong>效果图</strong></p><div align="center"><img src="  https://cdn.jsdelivr.net/gh/GallonHu/pic@master/screenshot/Screen-Shot-2019-12-13-at-10.52.32-AM.png" style="zoom:33%;"></div>#### 添加目录<p>在配置文件中启用目录（默认启用）</p><figure class="highlight yaml hljs"><figcaption><span>_config.yml</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-attr">widgets:</span></span><br><span class="line">    <span class="hljs-bullet">-</span></span><br><span class="line">        <span class="hljs-attr">type:</span> <span class="hljs-string">toc</span></span><br><span class="line">        <span class="hljs-attr">position:</span> <span class="hljs-string">left</span></span><br></pre></td></tr></table></figure><p>然后，在文章的开头添加<code>toc: true</code></p><figure class="highlight markdown hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">title: Table of Contents Example</span><br><span class="line">toc: true</span><br><span class="line">---</span><br><span class="line">Post content...</span><br></pre></td></tr></table></figure><p><strong>效果</strong></p><div align="center"><img src="  https://cdn.jsdelivr.net/gh/GallonHu/pic@master/screenshot/Screen-Shot-2019-12-13-at-11.01.24-AM.png" style="zoom:33%;"></div>## 插件篇<h3 id="主题内置插件"><a href="#主题内置插件" class="headerlink" title="主题内置插件"></a>主题内置插件</h3><h4 id="评论"><a href="#评论" class="headerlink" title="评论"></a>评论</h4><p><a href="https://blog.zhangruipeng.me/hexo-theme-icarus/categories/Plugins/Comment/" target="_blank" rel="noopener">内置评论插件</a> 官方配置文档，我使用的是 <code>valine</code></p><p>效果</p><div align="center"><img src="  https://cdn.jsdelivr.net/gh/GallonHu/pic@master/screenshot/Screen-Shot-2019-12-13-at-3.46.21-PM.png" style="zoom:33%;"></div>#### 打赏<p><a href="https://blog.zhangruipeng.me/hexo-theme-icarus/Plugins/Donation/making-money-off-your-blog-with-donation-buttons/#more" target="_blank" rel="noopener">官方配置文档</a></p><p><strong>效果</strong></p><div align="center"><img src="  https://cdn.jsdelivr.net/gh/GallonHu/pic@master/screenshot/Screen-Shot-2019-12-13-at-4.44.39-PM.png" style="zoom:33%;"></div>### 其他插件<p>在博客的站点目录下安装插件。</p><h4 id="hexo-abbrlink"><a href="#hexo-abbrlink" class="headerlink" title="hexo-abbrlink"></a><a href="https://github.com/Rozbo/hexo-abbrlink" target="_blank" rel="noopener">hexo-abbrlink</a></h4><p><em>hexo</em> 默认的永久链接生成方案是 <code>年/月/日/标题</code>。这样一来，链接不但很长，而且，如果你是中文用户，生成的链接中还将包含中文，这无疑会留下很多麻烦。</p><p><strong>安装</strong></p><figure class="highlight shell hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm install hexo-abbrlink --save</span><br></pre></td></tr></table></figure><p><strong>配置</strong></p><p>修改站点 <code>_config.yml</code></p><figure class="highlight yaml hljs"><figcaption><span>_config.yml</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-attr">permalink:</span> <span class="hljs-string">posts/:abbrlink/</span></span><br></pre></td></tr></table></figure><p>还需要设置两个参数</p><figure class="highlight yaml hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-string">alg</span> <span class="hljs-string">--</span> <span class="hljs-string">Algorithm</span> <span class="hljs-string">(currently</span> <span class="hljs-string">support</span> <span class="hljs-string">crc16</span> <span class="hljs-string">and</span> <span class="hljs-string">crc32,</span> <span class="hljs-string">which</span> <span class="hljs-string">crc16</span> <span class="hljs-string">is</span> <span class="hljs-string">default)</span></span><br><span class="line"><span class="hljs-string">rep</span> <span class="hljs-string">--</span> <span class="hljs-string">Represent</span> <span class="hljs-string">(the</span> <span class="hljs-string">generated</span> <span class="hljs-string">link</span> <span class="hljs-string">could</span> <span class="hljs-string">be</span> <span class="hljs-string">presented</span> <span class="hljs-string">in</span> <span class="hljs-string">hex</span> <span class="hljs-string">or</span> <span class="hljs-string">dec</span> <span class="hljs-string">value)</span></span><br></pre></td></tr></table></figure><p>如果你不想用默认的参数，需要在站点 <code>_config.yml</code> 中添加</p><figure class="highlight yaml hljs"><figcaption><span>_config.yml</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-comment"># abbrlink config</span></span><br><span class="line"></span><br><span class="line"><span class="hljs-attr">abbrlink:</span></span><br><span class="line">  <span class="hljs-attr">alg:</span> <span class="hljs-string">crc32</span>  <span class="hljs-comment">#support crc16(default) and crc32</span></span><br><span class="line">  <span class="hljs-attr">rep:</span> <span class="hljs-string">hex</span>    <span class="hljs-comment">#support dec(default) and hex</span></span><br></pre></td></tr></table></figure><h4 id="hexo-generator-feed"><a href="#hexo-generator-feed" class="headerlink" title="hexo-generator-feed"></a><a href="https://github.com/hexojs/hexo-generator-feed" target="_blank" rel="noopener">hexo-generator-feed</a></h4><p>生成 <em>Atom 1.0</em> 或者 <em>RSS 2.0</em> 为自己的博客提供订阅功能。</p><p><strong>安装</strong></p><figure class="highlight shell hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm install hexo-generator-feed --save</span><br></pre></td></tr></table></figure><p><strong>配置站点目录<code>_config.yml</code></strong></p> <figure class="highlight yaml hljs"><figcaption><span>_config.yml</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-attr">feed:</span></span><br><span class="line">    <span class="hljs-attr">type:</span> <span class="hljs-string">atom</span></span><br><span class="line">    <span class="hljs-attr">path:</span> <span class="hljs-string">atom.xml</span></span><br><span class="line">    <span class="hljs-attr">limit:</span> <span class="hljs-number">20</span></span><br><span class="line">    <span class="hljs-attr">hub:</span></span><br><span class="line">    <span class="hljs-attr">content:</span></span><br><span class="line">    <span class="hljs-attr">content_limit:</span> <span class="hljs-number">140</span></span><br><span class="line">    <span class="hljs-attr">content_limit_delim:</span> <span class="hljs-string">' '</span></span><br><span class="line">    <span class="hljs-attr">order_by:</span> <span class="hljs-string">-date</span></span><br><span class="line">    <span class="hljs-attr">icon:</span> <span class="hljs-string">icon.png</span></span><br><span class="line">    <span class="hljs-attr">autodiscovery:</span> <span class="hljs-literal">true</span></span><br><span class="line">    <span class="hljs-attr">template:</span></span><br></pre></td></tr></table></figure><p>参数的具体含义见官方仓库。</p><p><strong>验证配置是否成功</strong></p><p>执行 <code>hexo g</code>，查看一下 <em>public</em> 目录，如果有 <code>atom.xml</code> 文件，则表明配置成功。 </p><p><strong>配置RSS</strong></p><p>这里以 <code>icarus</code> 主题为例，给<em>rss</em>添加链接，修改 <code>_config.yaml</code></p><figure class="highlight yaml hljs"><figcaption><span>_config.yml </span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-attr">RSS:</span></span><br><span class="line"><span class="hljs-attr">icon:</span> <span class="hljs-string">fas</span> <span class="hljs-string">fa-rss</span></span><br><span class="line"><span class="hljs-attr">url:</span> <span class="hljs-string">/atom.xml</span></span><br></pre></td></tr></table></figure><p><strong>效果</strong></p><div align="center"><img src=" https://cdn.jsdelivr.net/gh/GallonHu/pic@master/screenshot/Screen-Shot-2019-12-11-at-8.05.40-PM.png" style="zoom:33%;"></div>#### [hexo-deployer-git](https://github.com/hexojs/hexo-deployer-git)<p>如果你使用 <code>git</code> 部署博客的话，需要安装此插件。</p><p><strong>安装</strong></p><figure class="highlight shell hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm install hexo-deployer-git --save</span><br></pre></td></tr></table></figure><p><strong>配置</strong></p><p>编辑站点配置文件</p><figure class="highlight yaml hljs"><figcaption><span>_config.yml</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-attr">deploy:</span></span><br><span class="line">  <span class="hljs-bullet">-</span> <span class="hljs-attr">type:</span> <span class="hljs-string">git</span></span><br><span class="line">    <span class="hljs-attr">repo:</span> <span class="hljs-string">git@github.com:&lt;username&gt;/&lt;username&gt;.github.io.git</span></span><br><span class="line">    <span class="hljs-attr">branch:</span> <span class="hljs-string">master</span></span><br><span class="line">  <span class="hljs-bullet">-</span> <span class="hljs-attr">type:</span> <span class="hljs-string">git</span></span><br><span class="line">    <span class="hljs-attr">repo:</span> <span class="hljs-string">git@github.com:&lt;username&gt;/&lt;username&gt;.github.io.git</span></span><br><span class="line">    <span class="hljs-attr">branch:</span> <span class="hljs-string">src</span></span><br><span class="line">    <span class="hljs-attr">extend_dirs:</span> <span class="hljs-string">/</span></span><br><span class="line">    <span class="hljs-attr">ignore_hidden:</span> <span class="hljs-literal">false</span></span><br><span class="line">    <span class="hljs-attr">ignore_pattern:</span></span><br><span class="line">        <span class="hljs-attr">public:</span> <span class="hljs-string">.</span></span><br></pre></td></tr></table></figure><p>具体的参数请参考官方说明。</p><h4 id="sharejs"><a href="#sharejs" class="headerlink" title="sharejs"></a><a href="https://github.com/overtrue/share.js" target="_blank" rel="noopener">sharejs</a></h4><p>一键分享到微博、QQ空间、QQ好友、微信、腾讯微博、豆瓣、Facebook、Twitter、Linkedin、Google+、点点等</p><p><strong>安装</strong></p><figure class="highlight shell hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm install social-share.js</span><br></pre></td></tr></table></figure><p>编辑主题配置文件</p><figure class="highlight yaml hljs"><figcaption><span>_config.yml</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-attr">share:</span></span><br><span class="line">    <span class="hljs-attr">type:</span> <span class="hljs-string">sharejs</span></span><br></pre></td></tr></table></figure><p><strong>效果</strong></p><div align="center"><img src="  https://cdn.jsdelivr.net/gh/GallonHu/pic@master/screenshot/Screen-Shot-2019-12-13-at-8.11.34-PM.png" style="zoom:33%;"></div>## 脚本篇<p>在博客站点目录下新建文件夹 <code>scripts</code>，所有的脚本都放在此目录下。</p><h3 id="新建博客自动打开"><a href="#新建博客自动打开" class="headerlink" title="新建博客自动打开"></a>新建博客自动打开</h3><p>当你使用 <code>hexo new</code> 新建一篇博客时将自动打开<em>markdown</em>编辑器</p><p>新建 <code>trigger.js</code> 脚本，内容如下</p><figure class="highlight javascript hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">var</span> exec = <span class="hljs-built_in">require</span>(<span class="hljs-string">'child_process'</span>).exec;</span><br><span class="line">hexo.on(<span class="hljs-string">'new'</span>, <span class="hljs-function"><span class="hljs-keyword">function</span>(<span class="hljs-params">data</span>)</span>&#123;</span><br><span class="line">    exec(<span class="hljs-string">'open -a "your/app/path" '</span> + data.path);</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure><p>把脚本中 <code>your/app/path</code> 替换成你的 <em>markdown</em> 编辑器。</p><p><a style="background-color:black;color:white;text-decoration:none;padding:4px 6px;font-family:-apple-system, BlinkMacSystemFont, &quot;San Francisco&quot;, &quot;Helvetica Neue&quot;, Helvetica, Ubuntu, Roboto, Noto, &quot;Segoe UI&quot;, Arial, sans-serif;font-size:12px;font-weight:bold;line-height:1.2;display:inline-block;border-radius:3px" href="https://unsplash.com/@malcoo?utm_medium=referral&amp;utm_campaign=photographer-credit&amp;utm_content=creditBadge" target="_blank" rel="noopener noreferrer" title="Download free do whatever you want high-resolution photos from Tomáš Malík"><span style="display:inline-block;padding:2px 3px"><svg xmlns="http://www.w3.org/2000/svg" style="height:12px;width:auto;position:relative;vertical-align:middle;top:-2px;fill:white" viewbox="0 0 32 32"><title>unsplash-logo</title><path d="M10 9V0h12v9H10zm12 5h10v18H0V14h10v9h12v-9z"/></svg></span><span style="display:inline-block;padding:2px 3px">Tomáš Malík</span></a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;使用 &lt;em&gt;hexo&lt;/em&gt; 写了大概一年左右的博客，期间参考网上各种教程给博客来了个大装修。但就像是做衣服，使用不同的布料，缝缝补补给生硬凑出来的一样，最终成了四不像。非但如此，因为各种插件和没用的渲染，博客的打开速度简直惨不忍睹。&lt;/p&gt;
&lt;p&gt;所以，打算翻新一下，从头开始再搭一个。这次的原则就是简洁，不再搞那些没用的花里胡哨的东西。配置过程记录如下。所有的配置文件在 &lt;a href=&quot;https://github.com/GallonHu/blog-config&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;github仓库&lt;/a&gt;。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Tutorials" scheme="http://gallonhu.github.io/categories/Tutorials/"/>
    
    
      <category term="Hexo" scheme="http://gallonhu.github.io/tags/Hexo/"/>
    
      <category term="Blog" scheme="http://gallonhu.github.io/tags/Blog/"/>
    
  </entry>
  
</feed>
